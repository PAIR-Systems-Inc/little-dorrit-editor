{
  "model_name": "or_deepseek_r1",
  "date": "2025-04-08T22:18:07.578861",
  "annotator": "DeepSeek R1",
  "annotation_date": "2025-04-07T19:31:00.515079",
  "details": [
    {
      "observed_edit_num": 0,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "punctuation",
      "original_text": "dark blue",
      "corrected_text": "dark-blue",
      "observed_line_number": 7,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": 1,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "capitalization",
      "original_text": "english Channel",
      "corrected_text": "English Channel",
      "observed_line_number": 9,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": 2,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "punctuation",
      "original_text": "however when",
      "corrected_text": "however, when",
      "observed_line_number": 15,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": 3,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "capitalization",
      "original_text": "santos dumont",
      "corrected_text": "Santos Dumont",
      "observed_line_number": 20,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": 4,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "punctuation",
      "original_text": "Santos Dumont",
      "corrected_text": "Santos-Dumont",
      "observed_line_number": 20,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": 5,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "punctuation",
      "original_text": "head ache",
      "corrected_text": "headache",
      "observed_line_number": 5,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": 6,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "punctuation",
      "original_text": "its",
      "corrected_text": "it's",
      "observed_line_number": 25,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": null,
      "expected_edit_num": 0,
      "tp": 0.0,
      "fp": 0.0,
      "fn": 1.0,
      "type": "punctuation",
      "original_text": "high road",
      "corrected_text": "high-road",
      "observed_line_number": null,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False negative: ground truth edit not found in prediction"
    },
    {
      "observed_edit_num": null,
      "expected_edit_num": 1,
      "tp": 0.0,
      "fp": 0.0,
      "fn": 1.0,
      "type": "punctuation",
      "original_text": "materials costing",
      "corrected_text": "materials, costing",
      "observed_line_number": null,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False negative: ground truth edit not found in prediction"
    },
    {
      "observed_edit_num": null,
      "expected_edit_num": 2,
      "tp": 0.0,
      "fp": 0.0,
      "fn": 1.0,
      "type": "punctuation",
      "original_text": "about and",
      "corrected_text": "about, and",
      "observed_line_number": null,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False negative: ground truth edit not found in prediction"
    },
    {
      "observed_edit_num": null,
      "expected_edit_num": 3,
      "tp": 0.0,
      "fp": 0.0,
      "fn": 1.0,
      "type": "punctuation",
      "original_text": "association, did",
      "corrected_text": "association did",
      "observed_line_number": null,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False negative: ground truth edit not found in prediction"
    },
    {
      "observed_edit_num": null,
      "expected_edit_num": 4,
      "tp": 0.0,
      "fp": 0.0,
      "fn": 1.0,
      "type": "punctuation",
      "original_text": "earnestly telling",
      "corrected_text": "earnestly, telling",
      "observed_line_number": null,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False negative: ground truth edit not found in prediction"
    },
    {
      "observed_edit_num": null,
      "expected_edit_num": 5,
      "tp": 0.0,
      "fp": 0.0,
      "fn": 1.0,
      "type": "punctuation",
      "original_text": "said when",
      "corrected_text": "said, when",
      "observed_line_number": null,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False negative: ground truth edit not found in prediction"
    },
    {
      "observed_edit_num": null,
      "expected_edit_num": 6,
      "tp": 0.0,
      "fp": 0.0,
      "fn": 1.0,
      "type": "punctuation",
      "original_text": "said",
      "corrected_text": "said,",
      "observed_line_number": null,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False negative: ground truth edit not found in prediction"
    },
    {
      "observed_edit_num": null,
      "expected_edit_num": 7,
      "tp": 0.0,
      "fp": 0.0,
      "fn": 1.0,
      "type": "punctuation",
      "original_text": "Clennam in",
      "corrected_text": "Clennam, in",
      "observed_line_number": null,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False negative: ground truth edit not found in prediction"
    }
  ]
}
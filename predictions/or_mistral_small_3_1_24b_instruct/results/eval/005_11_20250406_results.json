{
  "model_name": "or_mistral_small_3_1_24b_instruct",
  "date": "2025-04-07T01:29:22.755150",
  "annotator": "Mistral Small 3.1 24B",
  "annotation_date": "2025-04-06T01:06:16.283054",
  "details": [
    {
      "observed_edit_num": 0,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "capitalization",
      "original_text": "said",
      "corrected_text": "Said",
      "observed_line_number": 24,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": 1,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "capitalization",
      "original_text": "asked",
      "corrected_text": "Asked",
      "observed_line_number": 26,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": null,
      "expected_edit_num": 0,
      "tp": 0.0,
      "fp": 0.0,
      "fn": 1.0,
      "type": "capitalization",
      "original_text": "if he",
      "corrected_text": "If he",
      "observed_line_number": null,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False negative: ground truth edit not found in prediction"
    },
    {
      "observed_edit_num": null,
      "expected_edit_num": 1,
      "tp": 0.0,
      "fp": 0.0,
      "fn": 1.0,
      "type": "replacement",
      "original_text": "said Clennam",
      "corrected_text": "asked Clennam",
      "observed_line_number": null,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False negative: ground truth edit not found in prediction"
    }
  ]
}
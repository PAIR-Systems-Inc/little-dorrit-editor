{
  "model_name": "gpt-4.5-preview",
  "date": "2025-04-08T22:34:45.378164",
  "annotator": "GPT-4.5 Preview",
  "annotation_date": "2025-04-07T20:08:19.268198",
  "details": [
    {
      "observed_edit_num": 0,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "insertion",
      "original_text": "tion",
      "corrected_text": "tion;",
      "observed_line_number": 15,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": 1,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "deletion",
      "original_text": "n",
      "corrected_text": "Clennam",
      "observed_line_number": 32,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": 2,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "insertion",
      "original_text": "Clennam",
      "corrected_text": "Clennam,",
      "observed_line_number": 32,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": 3,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "replacement",
      "original_text": "high-road",
      "corrected_text": "high-road",
      "observed_line_number": 2,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": 4,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "insertion",
      "original_text": "materials",
      "corrected_text": "materials,",
      "observed_line_number": 4,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": 5,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "insertion",
      "original_text": "about",
      "corrected_text": "about,",
      "observed_line_number": 13,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": 6,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "deletion",
      "original_text": "tion,",
      "corrected_text": "",
      "observed_line_number": 15,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": 7,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "insertion",
      "original_text": "earnestly",
      "corrected_text": "earnestly,",
      "observed_line_number": 19,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": 8,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "insertion",
      "original_text": "said",
      "corrected_text": "said,",
      "observed_line_number": 27,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": 9,
      "expected_edit_num": null,
      "tp": 0.0,
      "fp": 1.0,
      "fn": 0.0,
      "type": "replacement",
      "original_text": "comma?",
      "corrected_text": ",",
      "observed_line_number": 27,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False positive: no matching ground truth edit found"
    },
    {
      "observed_edit_num": null,
      "expected_edit_num": 0,
      "tp": 0.0,
      "fp": 0.0,
      "fn": 1.0,
      "type": "punctuation",
      "original_text": "said when",
      "corrected_text": "said, when",
      "observed_line_number": null,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False negative: ground truth edit not found in prediction"
    },
    {
      "observed_edit_num": null,
      "expected_edit_num": 1,
      "tp": 0.0,
      "fp": 0.0,
      "fn": 1.0,
      "type": "punctuation",
      "original_text": "high road",
      "corrected_text": "high-road",
      "observed_line_number": null,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False negative: ground truth edit not found in prediction"
    },
    {
      "observed_edit_num": null,
      "expected_edit_num": 2,
      "tp": 0.0,
      "fp": 0.0,
      "fn": 1.0,
      "type": "punctuation",
      "original_text": "materials costing",
      "corrected_text": "materials, costing",
      "observed_line_number": null,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False negative: ground truth edit not found in prediction"
    },
    {
      "observed_edit_num": null,
      "expected_edit_num": 3,
      "tp": 0.0,
      "fp": 0.0,
      "fn": 1.0,
      "type": "punctuation",
      "original_text": "about and",
      "corrected_text": "about, and",
      "observed_line_number": null,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False negative: ground truth edit not found in prediction"
    },
    {
      "observed_edit_num": null,
      "expected_edit_num": 4,
      "tp": 0.0,
      "fp": 0.0,
      "fn": 1.0,
      "type": "punctuation",
      "original_text": "association, did",
      "corrected_text": "association did",
      "observed_line_number": null,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False negative: ground truth edit not found in prediction"
    },
    {
      "observed_edit_num": null,
      "expected_edit_num": 5,
      "tp": 0.0,
      "fp": 0.0,
      "fn": 1.0,
      "type": "punctuation",
      "original_text": "earnestly telling",
      "corrected_text": "earnestly, telling",
      "observed_line_number": null,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False negative: ground truth edit not found in prediction"
    },
    {
      "observed_edit_num": null,
      "expected_edit_num": 6,
      "tp": 0.0,
      "fp": 0.0,
      "fn": 1.0,
      "type": "punctuation",
      "original_text": "said",
      "corrected_text": "said,",
      "observed_line_number": null,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False negative: ground truth edit not found in prediction"
    },
    {
      "observed_edit_num": null,
      "expected_edit_num": 7,
      "tp": 0.0,
      "fp": 0.0,
      "fn": 1.0,
      "type": "punctuation",
      "original_text": "Clennam in",
      "corrected_text": "Clennam, in",
      "observed_line_number": null,
      "line_diff": null,
      "line_number_penalty": 0.0,
      "judgement": "False negative: ground truth edit not found in prediction"
    }
  ]
}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Little Dorrit Editor Benchmark Leaderboard</title>
    <style>
        :root {
            --primary-color: #3a5a78;
            --secondary-color: #f5f5f5;
            --accent-color: #e76f51;
            --text-color: #333;
            --bg-color: #fff;
            --border-color: #ddd;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--bg-color);
            max-width: 1100px;
            margin: 0 auto;
            padding: 20px;
        }
        
        header {
            margin-bottom: 40px;
            text-align: center;
            position: relative;
        }
        
        h1 {
            color: var(--primary-color);
            border-bottom: 2px solid var(--border-color);
            padding-bottom: 15px;
            font-size: 2.2em;
            margin-bottom: 0.3em;
        }
        
        .subtitle {
            font-style: italic;
            color: #666;
            font-size: 1.1em;
            margin-bottom: 30px;
        }
        
        .description {
            max-width: 800px;
            margin: 0 auto 40px;
            text-align: left;
            padding: 20px;
            background-color: var(--secondary-color);
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        
        .description h2 {
            color: var(--primary-color);
            margin-top: 0;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
            font-size: 0.95em;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.15);
            border-radius: 5px;
            overflow: hidden;
        }
        
        thead tr {
            background-color: var(--primary-color);
            color: #ffffff;
            text-align: left;
        }
        
        th, td {
            padding: 12px 15px;
        }
        
        tbody tr {
            border-bottom: 1px solid var(--border-color);
        }
        
        tbody tr:nth-of-type(even) {
            background-color: var(--secondary-color);
        }
        
        tbody tr:last-of-type {
            border-bottom: 2px solid var(--primary-color);
        }
        
        tbody tr:hover {
            background-color: rgba(58, 90, 120, 0.1);
        }
        
        .medal {
            display: inline-block;
            width: 22px;
            height: 22px;
            line-height: 22px;
            text-align: center;
            border-radius: 50%;
            color: white;
            font-weight: bold;
            margin-right: 8px;
        }
        
        .gold {
            background-color: #FFD700;
            box-shadow: 0 0 5px rgba(255, 215, 0, 0.5);
        }
        
        .silver {
            background-color: #C0C0C0;
            box-shadow: 0 0 5px rgba(192, 192, 192, 0.5);
        }
        
        .bronze {
            background-color: #CD7F32;
            box-shadow: 0 0 5px rgba(205, 127, 50, 0.5);
        }
        
        .metrics {
            display: flex;
            justify-content: space-between;
            gap: 20px;
            margin-bottom: 40px;
        }
        
        .metric-card {
            flex: 1;
            background-color: var(--secondary-color);
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            text-align: center;
        }
        
        .metric-title {
            font-size: 1.1em;
            font-weight: bold;
            margin-bottom: 10px;
            color: var(--primary-color);
        }
        
        .metric-value {
            font-size: 2em;
            font-weight: bold;
            color: var(--accent-color);
        }
        
        footer {
            margin-top: 40px;
            text-align: center;
            font-size: 0.9em;
            color: #7f8c8d;
            padding-top: 20px;
            border-top: 1px solid var(--border-color);
        }
        
        .updated {
            text-align: right;
            font-style: italic;
            color: #7f8c8d;
            font-size: 0.85em;
            margin-top: 30px;
        }
        
        @media (max-width: 768px) {
            .metrics {
                flex-direction: column;
            }
            
            table {
                font-size: 0.8em;
            }
            
            th, td {
                padding: 8px 10px;
            }
        }
    </style>
</head>
<body>
    <header>
        <h1>Little Dorrit Editor Benchmark</h1>
        <div class="subtitle">
            150 years after her quiet rebellion in the Marshalsea, Little Dorrit returns—with red pen in hand—to help evaluate the judgment of modern language models.
        </div>
    </header>
    
    <div class="description">
        <h2>About the Benchmark</h2>
        <p>
            This benchmark evaluates the ability of multimodal language models to interpret handwritten editorial corrections in printed text. 
            Using annotated scans from Charles Dickens' "Little Dorrit," we challenge models to accurately capture human editing intentions.
        </p>
        <p>
            Models are assessed on their ability to detect and interpret various types of editorial marks including insertions, deletions,
            replacements, punctuation changes, capitalization corrections, and text reordering.
        </p>
    </div>
    
    <div class="metrics">
        <div class="metric-card">
            <div class="metric-title">Top Model</div>
            <div class="metric-value">Loading...</div>
        </div>
        <div class="metric-card">
            <div class="metric-title">Best F1 Score</div>
            <div class="metric-value">Loading...</div>
        </div>
        <div class="metric-card">
            <div class="metric-title">Models Evaluated</div>
            <div class="metric-value">Loading...</div>
        </div>
        <div class="metric-card">
            <div class="metric-title">Most Challenging Edit</div>
            <div class="metric-value">Loading...</div>
        </div>
    </div>
    
    <table>
        <thead>
            <tr>
                <th>Rank</th>
                <th>Model</th>
                <th>F1 Score</th>
                <th>Precision</th>
                <th>Recall</th>
                <th>Date</th>
            </tr>
        </thead>
        <tbody>
            <!-- Table content will be populated by JavaScript -->
        </tbody>
    </table>
    
    <p class="updated" id="updated-date">Last updated: Loading...</p>
    
    <footer>
        <p>
            For more information, visit the 
            <a href="https://github.com/yourusername/little-dorrit-editor">Little Dorrit Editor repository</a>.
            The dataset is available on <a href="https://huggingface.co/datasets/yourusername/little-dorrit-editor">Hugging Face</a>.
        </p>
    </footer>

    <script>
        // Calculate F-beta score (F1 when beta=1)
        function fBetaScore(precision, recall, beta = 1) {
            if (precision === 0 && recall === 0) return 0;

            const betaSquared = beta * beta;
            return (1 + betaSquared) * (precision * recall) /
                   (betaSquared * precision + recall);
        }

        // Process model results and compute metrics
        function processModelResults(data) {
            const processedModels = [];
            let mostChallengingEdit = { type: "Unknown", f1: 1.0 };
            const editTypeStats = {};

            // Process each model's results
            data.forEach(model => {
                const fileResults = model.file_results || [];
                
                // Collect all edit matches from all files
                const allEditMatches = [];
                fileResults.forEach(fileResult => {
                    // Handle both the new format (details is a list of EditMatch objects)
                    // and the older format (details.edit_matches)
                    const details = fileResult.details;
                    if (Array.isArray(details)) {
                        allEditMatches.push(...details);
                    } else if (details && details.edit_matches) {
                        allEditMatches.push(...details.edit_matches);
                    }
                });

                if (allEditMatches.length === 0) {
                    return; // Skip models with no edit matches
                }

                // Calculate overall metrics
                let totalTp = 0;
                let totalFp = 0;
                let totalFn = 0;
                
                // Calculate metrics by edit type
                const editTypes = {};
                
                // Process each edit match
                allEditMatches.forEach(edit => {
                    // Add TP/FP/FN values to totals
                    totalTp += edit.tp || 0;
                    totalFp += edit.fp || 0;
                    totalFn += edit.fn || 0;
                    
                    // Process by edit type
                    let editType = edit.type;
                    if (editType) {
                        // Handle different formats of edit type
                        if (typeof editType !== 'string' && editType.__root__) {
                            editType = editType.__root__;
                        }
                        
                        if (!editTypes[editType]) {
                            editTypes[editType] = { tp: 0, fp: 0, fn: 0, count: 0 };
                        }
                        
                        editTypes[editType].tp += edit.tp || 0;
                        editTypes[editType].fp += edit.fp || 0;
                        editTypes[editType].fn += edit.fn || 0;
                        
                        // Count if it's a match or false negative (expected_edit_num is set)
                        if (edit.expected_edit_num !== undefined && edit.expected_edit_num !== null) {
                            editTypes[editType].count += 1;
                        }
                        
                        // Update global edit type stats for "most challenging" calculation
                        if (!editTypeStats[editType]) {
                            editTypeStats[editType] = { 
                                totalTp: 0, totalFp: 0, totalFn: 0, 
                                count: 0, models: 0 
                            };
                        }
                        editTypeStats[editType].totalTp += edit.tp || 0;
                        editTypeStats[editType].totalFp += edit.fp || 0;
                        editTypeStats[editType].totalFn += edit.fn || 0;
                        editTypeStats[editType].count += 1;
                    }
                });
                
                // Calculate the overall precision, recall, and F1
                const precision = totalTp / (totalTp + totalFp) || 0;
                const recall = totalTp / (totalTp + totalFn) || 0;
                const f1 = fBetaScore(precision, recall, 1);
                
                // Calculate per-type metrics
                for (const [type, metrics] of Object.entries(editTypes)) {
                    const typePrecision = metrics.tp / (metrics.tp + metrics.fp) || 0;
                    const typeRecall = metrics.tp / (metrics.tp + metrics.fn) || 0;
                    const typeF1 = fBetaScore(typePrecision, typeRecall, 1);
                    
                    editTypes[type] = {
                        ...metrics,
                        precision: typePrecision,
                        recall: typeRecall,
                        f1: typeF1
                    };
                }
                
                // Record the processed model with computed metrics
                processedModels.push({
                    name: model.model_name,
                    precision: precision,
                    recall: recall,
                    f1: f1,
                    date: model.date,
                    shots: model.shots || 2,
                    editTypes: editTypes
                });
                
                // Update edit type stats
                for (const [type, metrics] of Object.entries(editTypes)) {
                    editTypeStats[type].models += 1;
                }
            });
            
            // Sort models by F1 score (descending)
            processedModels.sort((a, b) => b.f1 - a.f1);
            
            // Find most challenging edit type (lowest average F1 across models)
            for (const [type, stats] of Object.entries(editTypeStats)) {
                // Only consider edit types that appear in multiple models
                if (stats.models >= 2 && stats.count >= 5) {  
                    const typePrecision = stats.totalTp / (stats.totalTp + stats.totalFp) || 0;
                    const typeRecall = stats.totalTp / (stats.totalTp + stats.totalFn) || 0;
                    const typeF1 = fBetaScore(typePrecision, typeRecall, 1);
                    
                    if (typeF1 < mostChallengingEdit.f1) {
                        mostChallengingEdit = { type: type, f1: typeF1 };
                    }
                }
            }
            
            return {
                models: processedModels,
                mostChallengingEdit: mostChallengingEdit.type,
                totalModels: processedModels.length
            };
        }

        // Update the UI with the computed data
        function updateUI(results) {
            // Update metrics cards
            if (results.models.length > 0) {
                document.querySelector('.metrics .metric-card:nth-child(1) .metric-value').textContent = 
                    results.models[0].name;
                
                document.querySelector('.metrics .metric-card:nth-child(2) .metric-value').textContent = 
                    results.models[0].f1.toFixed(3);
            }
            
            document.querySelector('.metrics .metric-card:nth-child(3) .metric-value').textContent = 
                results.totalModels;
            
            document.querySelector('.metrics .metric-card:nth-child(4) .metric-value').textContent = 
                results.mostChallengingEdit;
            
            // Clear and update the table
            const tableBody = document.querySelector('tbody');
            tableBody.innerHTML = '';
            
            results.models.forEach((model, index) => {
                const row = document.createElement('tr');
                
                // Add medal for top 3
                let medalClass = '';
                if (index === 0) medalClass = 'gold';
                else if (index === 1) medalClass = 'silver';
                else if (index === 2) medalClass = 'bronze';
                
                const medalSpan = medalClass ? 
                    `<span class="medal ${medalClass}">${index + 1}</span>` : '';
                
                // Format date
                let displayDate = model.date;
                try {
                    const date = new Date(model.date);
                    if (!isNaN(date)) {
                        displayDate = date.toISOString().split('T')[0];
                    }
                } catch (e) {
                    console.error('Error parsing date:', e);
                }
                
                // Create row HTML
                row.innerHTML = `
                    <td>${index + 1}</td>
                    <td>${medalSpan}${model.name}</td>
                    <td>${model.f1.toFixed(4)}</td>
                    <td>${model.precision.toFixed(4)}</td>
                    <td>${model.recall.toFixed(4)}</td>
                    <td>${displayDate}</td>
                `;
                
                tableBody.appendChild(row);
            });
            
            // Update the "last updated" text
            const now = new Date();
            document.getElementById('updated-date').textContent = 
                `Last updated: ${now.toISOString().split('T')[0]}`;
        }

        // Fetch and process the results
        window.addEventListener('DOMContentLoaded', async () => {
            try {
                const response = await fetch('../docs/results.json');
                if (!response.ok) {
                    throw new Error(`Failed to fetch results: ${response.status} ${response.statusText}`);
                }
                
                const data = await response.json();
                const results = processModelResults(data);
                updateUI(results);
            } catch (error) {
                console.error('Error loading results:', error);
                document.getElementById('updated-date').textContent = 
                    `Error loading results: ${error.message}`;
            }
        });
    </script>
</body>
</html>
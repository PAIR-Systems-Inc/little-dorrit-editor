<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Little Dorrit Editor Benchmark Leaderboard</title>

    <!-- Tabulator CSS and JS from CDN -->
    <link href="https://unpkg.com/tabulator-tables@6.3.1/dist/css/tabulator.min.css" rel="stylesheet">
    <script type="text/javascript" src="https://unpkg.com/tabulator-tables@6.3.1/dist/js/tabulator.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>
    <header>
        <h1>Little Dorrit Editor Benchmark</h1>
        <div class="subtitle centered-container fixed-width-container">
            More than 150 years after her quiet rebellion in the Marshalsea,
            Little Dorrit returns—with red pen in hand—to help evaluate the
            judgment of modern language models.
        </div>
        <div class="badges-container">
            <a href="/technical-report.pdf" target="_blank" rel="noopener noreferrer" class="badge badge-technical">
              <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                <path d="M14.5 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7.5L14.5 2z"/>
                <polyline points="14 2 14 8 20 8"/>
                <line x1="16" y1="13" x2="8" y2="13"/>
                <line x1="16" y1="17" x2="8" y2="17"/>
                <line x1="10" y1="9" x2="8" y2="9"/>
              </svg>
              <span>Technical Report</span>
            </a>

            <a href="https://github.com/PAIR-Systems-Inc/little-dorrit-editor" target="_blank" rel="noopener noreferrer" class="badge badge-github">
              <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                <path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"/>
                <path d="M9 18c-4.51 2-5-2-7-2"/>
              </svg>
              <span>GitHub Repository</span>
            </a>
        </div>
    </header>

    <div class="metrics" id="metrics">
        <div class="metric-card">
            <div class="metric-title">Top Model</div>
            <div class="metric-value" id="top-model">Loading...</div>
            <div class="metric-model" id="top-model-name">-</div>
        </div>
        <div class="metric-card">
            <div class="metric-title">Best F1 Score</div>
            <div class="metric-value" id="best-f1-score">Loading...</div>
            <div class="metric-model" id="best-f1-model">-</div>
        </div>
        <div class="metric-card">
            <div class="metric-title">Best Precision</div>
            <div class="metric-value" id="best-precision">Loading...</div>
            <div class="metric-model" id="best-precision-model">-</div>
        </div>
        <div class="metric-card">
            <div class="metric-title">Best Recall</div>
            <div class="metric-value" id="best-recall">Loading...</div>
            <div class="metric-model" id="best-recall-model">-</div>
        </div>
    </div>

    <h2 class="section-title" id="leaderboard">Performance Leaderboard</h2>
    <p>
        All models listed below were tested through <a href="https://openrouter.ai/">OpenRouter</a>,
        a unified interface for LLMs.
    </p>
    <div id="leaderboard-table"></div>

    <h2 class="section-title" id="detailed">Detailed Model Performance</h2>
    <div id="model-performance-table"></div>

    <!-- Table of Contents -->
    <div class="toc centered-container fixed-width-container">
        <h2>Further Contents</h2>
        <ul>
            <li><a href="#about">About the Benchmark</a></li>
            <li><a href="#how-it-works">How It Works</a>
                <ul>
                    <li><a href="#the-task">The Task</a></li>
                    <li><a href="#example-input">Example Input</a></li>
                    <li><a href="#expected-output">Expected Output</a></li>
                </ul>
            </li>
        </ul>
    </div>

    <div class="content-wrapper  centered-container fixed-width-container" id="about">
        <div class="description">
            <h2>About the Benchmark</h2>
            <div class="portrait-container">
                <div class="portrait-crop">
                  <img src="/dorrit.png" alt="Portrait of Little Dorrit" class="portrait" title="Little Dorrit, from Charles Dickens' novel">
                </div>
            </div>
            <p>
                This benchmark evaluates the ability of multimodal language models to interpret handwritten editorial corrections in printed text.
                Using annotated scans from Charles Dickens' "Little Dorrit," we challenge models to accurately capture human editing intentions.
            </p>
            <p>
                Models are assessed on their ability to detect and interpret various types of editorial marks including insertions, deletions,
                replacements, punctuation changes, capitalization corrections, and text reordering.
            </p>
            <p>
                The benchmark consists of several document pages containing Dickens' original manuscript with editorial marks and corrections.
                These documents represent the kind of annotations an editor might make when reviewing a text for publication, providing
                a realistic test of how well AI models can understand human editing practices.
            </p>
        </div>
    </div>

    <div class="post-content centered-container fixed-width-container">
    <h2 class="section-title" id="how-it-works">How It Works</h2>
    <p>
        Models are presented with scanned pages containing handwritten editorial
        marks and are asked to identify each edit, its type, location, and the
        text before and after the edit.
    </p>

    <h3 id="the-task">The Task</h3>

    <p>
      Each page in the benchmark consists of printed text overlaid with
      handwritten editorial annotations. Models are tasked with detecting and
      interpreting all such editorial corrections and outputting them in
      structured <code>JSON</code> format.
    </p>

    <p>
      For each correction, the model must identify:
    </p>

    <ul class="task-details">
      <li><strong>Type of edit:</strong> One of <code>insertion</code>, <code>deletion</code>, <code>replacement</code>, <code>punctuation</code>, <code>capitalization</code>, or <code>reordering</code></li>
      <li><strong>Original text:</strong> The text as it appeared before the edit</li>
      <li><strong>Corrected text:</strong> The intended version after applying the edit</li>
      <li><strong>Line number:</strong> The line on which the edit occurs. Use <strong>line 0</strong> for titles or headings, and start counting full lines of body text from <strong>line 1</strong></li>
      <li><strong>Page:</strong> A known identifier for the image (e.g., <code>"001.png"</code>), provided alongside the input and not extracted by the model</li>
    </ul>

    <p>
      Models should infer the intent behind handwritten annotations using both
      visual and textual cues. Common markup conventions include:
    </p>

    <ul class="task-markers">
      <li><strong>Insertions:</strong> Indicated by caret marks (<code>^</code>) or added words between lines</li>
      <li><strong>Deletions:</strong> Shown using strikethroughs or crossed-out text</li>
      <li><strong>Replacements:</strong> Circled, underlined, or bracketed text with substitutions nearby</li>
      <li><strong>Punctuation edits:</strong> Handwritten punctuation added, removed, or modified</li>
      <li><strong>Capitalization:</strong> Case changes marked explicitly or via notation</li>
      <li><strong>Reordering:</strong> Text rearranged using arrows, numbering, or caret repositions</li>
    </ul>

    <p>
      This task combines fine-grained visual recognition with natural language
      understanding and domain knowledge of editorial conventions. The goal is
      not just OCR or layout detection, but true interpretation of handwritten
      edits in context.
    </p>

    <div class="example-container">
        <h3 id="example-input">Example Input</h3>

        <div class="example-image centered-container">
            <img src="/001.png" alt="Sample page from Little Dorrit with editorial marks" class="benchmark-example">
            <div class="example-caption">Sample page from Little Dorrit with editorial marks.</div>
        </div>

        <div class="example-results">
            <h3 id="expected-output">Expected Output</h3>
            <p>For the example above, models should identify all ten editorial corrections, producing output like:</p>
            <div class="code-window">
                <div class="code-header"></div>
                <pre><code class="language-json">{
    "image": "001.png",
    "page_number": 5,
    "source": "Little Dorrit",
    "annotator": "pairsys",
    "annotation_date": "2025-04-04",
    "verified": true,
    "edits": [
        {
            "type": "punctuation",
            "original_text": "church bells",
            "corrected_text": "church bells,",
            "line_number": 2,
            "page": "001.png"
        },
        {
            "type": "punctuation",
            "original_text": "wine bottles",
            "corrected_text": "wine-bottles",
            "line_number": 11,
            "page": "001.png"
        },
        {
            "type": "punctuation",
            "original_text": "got through",
            "corrected_text": "got, through",
            "line_number": 14,
            "page": "001.png"
        },
        {
            "type": "punctuation",
            "original_text": "iron bars fashioned",
            "corrected_text": "iron bars, fashioned",
            "line_number": 14,
            "page": "001.png"
        },
        {
            "type": "punctuation",
            "original_text": "grating where",
            "corrected_text": "grating, where",
            "line_number": 17,
            "page": "001.png"
        },
        {
            "type": "punctuation",
            "original_text": "outside and",
            "corrected_text": "outside; and",
            "line_number": 29,
            "page": "001.png"
        },
        {
            "type": "punctuation",
            "original_text": "intact in",
            "corrected_text": "intact, in",
            "line_number": 30,
            "page": "001.png"
        },
        {
            "type": "capitalization",
            "original_text": "indian ocean",
            "corrected_text": "Indian Ocean",
            "line_number": 31,
            "page": "001.png"
        },
        {
            "type": "punctuation",
            "original_text": "was waiting to be fed looking",
            "corrected_text": "was waiting to be fed; looking",
            "line_number": 36,
            "page": "001.png"
        },
        {
            "type": "punctuation",
            "original_text": "bars that",
            "corrected_text": "bars, that",
            "line_number": 36,
            "page": "001.png"
        }
    ]
}</code></pre>
            </div>
        </div>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/json.min.js"></script>
        <script>
            hljs.highlightAll();
        </script>
    </div>

    <p class="updated">Last updated: <span id="last-updated">2025-04-04</span></p>
    </div>

    <footer>
        <p>
            For more information, visit the
            <a href="https://github.com/pairsys/little-dorrit-editor">Little Dorrit Editor repository</a>.
            The dataset is available on <a href="https://huggingface.co/datasets/pairsys/little-dorrit-editor">Hugging Face</a>.
        </p>
    </footer>

    <!-- External JavaScript -->
    <script src="js/leaderboard.js"></script>
</body>
</html>
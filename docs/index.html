<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Little Dorrit Editor Benchmark Leaderboard</title>

    <!-- Tabulator CSS and JS from CDN -->
    <link href="https://unpkg.com/tabulator-tables@6.3.1/dist/css/tabulator.min.css" rel="stylesheet">
    <script type="text/javascript" src="https://unpkg.com/tabulator-tables@6.3.1/dist/js/tabulator.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">

    <style>
        :root {
            --primary-color: #3a5a78;
            --secondary-color: #f5f5f5;
            --accent-color: #e76f51;
            --text-color: #333;
            --bg-color: #fff;
            --border-color: #ddd;
        }

        .content-wrapper {
            display: flex;
            flex-direction: column;
        }

        .portrait-container {
            text-align: center;
            margin: 0 auto 40px;
            position: relative;
            width: 100%;
            max-width: 280px;
        }

        .portrait-crop {
            width: 180px;
            height: 180px;
            border-radius: 50%;
            overflow: hidden;
            position: relative;
            margin: 0 auto;
            box-shadow: 0 0 5px rgba(0,0,0,0.2);
        }

        .portrait {
            position: absolute;
            width: 200px;     /* zoom level */
            top: -10px;       /* tweak to center face vertically */
            left: -10px;      /* tweak to center face horizontally */
        }

        @media (min-width: 768px) {
            .content-wrapper {
                flex-direction: row;
                align-items: flex-start;
                gap: 40px;
                margin-bottom: 40px;
            }

            .description {
                flex: 1;
                margin: 0;
                order: 1;
            }

            .portrait-container {
                width: 210px;
                margin: 0 0 20px 20px;
                order: 2;
                float: right;
                shape-outside: ellipse(50% 50%);
            }
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--bg-color);
            max-width: 1100px;
            margin: 0 auto;
            padding: 20px;
            scroll-behavior: smooth;
        }

        header {
            margin-bottom: 20px;
            text-align: center;
            position: relative;
        }

        h1 {
            color: var(--primary-color);
            border-bottom: 2px solid var(--border-color);
            padding-bottom: 15px;
            font-size: 2.2em;
            margin-bottom: 0.3em;
        }

        .subtitle {
            font-style: italic;
            color: #666;
            font-size: 1.1em;
            margin-bottom: 30px;
        }

        .description {
            max-width: 800px;
            margin: 0 auto 40px;
            text-align: left;
            padding: 20px;
            background-color: var(--secondary-color);
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        .description h2 {
            color: var(--primary-color);
            margin-top: 0;
        }

        .tabulator {
            margin: 25px 0;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.15);
            border-radius: 5px;
            overflow: hidden;
        }

        .medal {
            display: inline-block;
            width: 22px;
            height: 22px;
            line-height: 22px;
            text-align: center;
            border-radius: 50%;
            color: white;
            font-weight: bold;
            margin-right: 8px;
        }

        .gold {
            background-color: #FFD700;
            box-shadow: 0 0 5px rgba(255, 215, 0, 0.5);
        }

        .silver {
            background-color: #C0C0C0;
            box-shadow: 0 0 5px rgba(192, 192, 192, 0.5);
        }

        .bronze {
            background-color: #CD7F32;
            box-shadow: 0 0 5px rgba(205, 127, 50, 0.5);
        }

        .metrics {
            display: flex;
            justify-content: space-between;
            gap: 20px;
            margin-bottom: 40px;
        }

        .metric-card {
            flex: 1;
            background-color: var(--secondary-color);
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            text-align: center;
        }

        .metric-title {
            font-size: 1.1em;
            font-weight: bold;
            margin-bottom: 10px;
            color: var(--primary-color);
        }

        .metric-value {
            font-size: 2em;
            font-weight: bold;
            color: var(--accent-color);
        }

        footer {
            margin-top: 40px;
            text-align: center;
            font-size: 0.9em;
            color: #7f8c8d;
            padding-top: 20px;
            border-top: 1px solid var(--border-color);
        }

        .updated {
            text-align: right;
            font-style: italic;
            color: #7f8c8d;
            font-size: 0.85em;
            margin-top: 30px;
        }

        .section-title {
            color: var(--primary-color);
            margin-top: 40px;
            margin-bottom: 20px;
            font-size: 1.5em;
        }

        .performance-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 6px;
        }

        .perfect-score {
            background-color: #4CAF50;
        }

        .good-score {
            background-color: #FFC107;
        }

        .low-score {
            background-color: #F44336;
        }

        .file-summary {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 20px;
        }

        .file-summary-chart {
            width: 65%;
            height: 300px;
        }

        .file-summary-stats {
            width: 30%;
        }

        .example-image {
            margin: 0 auto 20px;
            text-align: center;
            max-width: 360px;
            display: block;
        }

        .example-image img {
            width: 100%;
            max-width: 360px;
        }

        .example-caption {
            text-align: center;
            margin-top: 8px;
            font-style: italic;
            color: #666;
        }

        .code-window {
            background-color: #282C34;
            border-radius: 10px;
            padding: 1rem;
            margin: 2rem 0;
            font-family: 'Fira Code', monospace;
            position: relative;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
        }

        .code-header {
            font-weight: bold;
            font-size: 1.1rem;
            margin-bottom: 0.5rem;
            display: flex;
            align-items: center;
        }

        .code-header::before {
            content: "Ground truth output";
            font-family:'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            color: #ccc;
            font-weight: 600;
            font-size: 0.95rem;
        }

        pre {
            margin: 0;
            overflow: auto;
        }

        code {
            font-size: 0.9rem;
            line-height: 1.5;
        }

        .toc {
            background-color: var(--secondary-color);
            border-radius: 5px;
            padding: 15px 25px;
            margin-bottom: 30px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        .toc h2 {
            margin-top: 0;
            margin-bottom: 15px;
            color: var(--primary-color);
            font-size: 1.2em;
        }

        .toc ul {
            padding-left: 20px;
            margin-bottom: 0;
        }

        .toc li {
            margin-bottom: 8px;
        }

        .toc a {
            color: var(--primary-color);
            text-decoration: none;
        }

        .toc a:hover {
            text-decoration: underline;
        }

        @media (max-width: 768px) {
            .metrics {
                flex-direction: column;
            }

            .file-summary {
                flex-direction: column;
            }

            .file-summary-chart, .file-summary-stats {
                width: 100%;
            }
        }
    </style>
</head>
<body>
    <header>
        <h1>Little Dorrit Editor Benchmark</h1>
        <div class="subtitle">
            150 years after her quiet rebellion in the Marshalsea, Little Dorrit returns—with red pen in hand—to help evaluate the judgment of modern language models.
        </div>
    </header>

    <!-- Table of Contents -->
    <div class="toc">
        <h2>Table of Contents</h2>
        <ul>
            <li><a href="#about">About the Benchmark</a></li>
            <li><a href="#metrics">Key Metrics</a></li>
            <li><a href="#leaderboard">Performance Leaderboard</a></li>
            <li><a href="#detailed">Detailed Model Performance</a></li>
            <li><a href="#how-it-works">How It Works</a></li>
        </ul>
    </div>

    <div class="content-wrapper" id="about">
        <div class="description">
            <h2>About the Benchmark</h2>
            <div class="portrait-container">
                <div class="portrait-crop">
                  <img src="/dorrit.png" alt="Portrait of Little Dorrit" class="portrait" title="Little Dorrit, from Charles Dickens' novel">
                </div>
            </div>
            <p>
                This benchmark evaluates the ability of multimodal language models to interpret handwritten editorial corrections in printed text.
                Using annotated scans from Charles Dickens' "Little Dorrit," we challenge models to accurately capture human editing intentions.
            </p>
            <p>
                Models are assessed on their ability to detect and interpret various types of editorial marks including insertions, deletions,
                replacements, punctuation changes, capitalization corrections, and text reordering.
            </p>
            <p>
                The benchmark consists of several document pages containing Dickens' original manuscript with editorial marks and corrections.
                These documents represent the kind of annotations an editor might make when reviewing a text for publication, providing
                a realistic test of how well AI models can understand human editing practices.
            </p>

            <h3>The Task</h3>
            <p>
                Models are instructed to identify all handwritten markups and corrections, including:
            </p>
            <ul class="task-types">
                <li><strong>Insertions:</strong> Adding new text (marked with carets or other indicators)</li>
                <li><strong>Deletions:</strong> Removing text (often shown with strikethroughs)</li>
                <li><strong>Replacements:</strong> Substituting text with alternatives</li>
                <li><strong>Punctuation:</strong> Modifying or adding punctuation marks</li>
                <li><strong>Capitalization:</strong> Changing case (upper/lower)</li>
                <li><strong>Reordering:</strong> Rearranging text sequence with arrows or numbers</li>
            </ul>
            <p>
                This requires models to understand context, recognize handwritten annotations, and correctly interpret editorial intentions—skills
                that combine visual understanding, textual comprehension, and domain knowledge of editing practices.
            </p>
        </div>
    </div>

    <div class="metrics" id="metrics">
        <div class="metric-card">
            <div class="metric-title">Top Model</div>
            <div class="metric-value">GPT-4o</div>
        </div>
        <div class="metric-card">
            <div class="metric-title">Best F1 Score</div>
            <div class="metric-value" id="best-f1-score">0.904</div>
        </div>
        <div class="metric-card">
            <div class="metric-title">Models Evaluated</div>
            <div class="metric-value">3</div>
        </div>
        <div class="metric-card">
            <div class="metric-title">Most Challenging Edit</div>
            <div class="metric-value">Reordering</div>
        </div>
    </div>

    <h2 class="section-title" id="leaderboard">Performance Leaderboard</h2>
    <div id="leaderboard-table"></div>

    <h2 class="section-title" id="detailed">Detailed Model Performance</h2>
    <div id="model-performance-table"></div>

    <h2 class="section-title" id="how-it-works">How It Works</h2>
    <p>
        Models are presented with scanned pages containing handwritten editorial marks and are asked to identify each edit,
        its type, location, and the text before and after the edit. Below is an example from our benchmark:
    </p>

    <div class="example-container">
        <div class="example-image">
            <img src="/001.png" alt="Sample page from Little Dorrit with editorial marks" class="benchmark-example">
            <div class="example-caption">Sample page from Little Dorrit with editorial marks.</div>
        </div>

        <div class="example-results">
            <h4>Expected Output</h4>
            <p>For the example above, models should identify all ten editorial corrections, producing output like:</p>
            <div class="code-window">
                <div class="code-header"></div>
                <pre><code class="language-json">{
    "image": "001.png",
    "page_number": 5,
    "source": "Little Dorrit",
    "annotator": "pairsys",
    "annotation_date": "2025-04-04",
    "verified": true,
    "edits": [
        {
            "type": "punctuation",
            "original_text": "church bells",
            "corrected_text": "church bells,",
            "line_number": 2,
            "page": "001.png"
        },
        {
            "type": "punctuation",
            "original_text": "wine bottles",
            "corrected_text": "wine-bottles",
            "line_number": 11,
            "page": "001.png"
        },
        {
            "type": "punctuation",
            "original_text": "got through",
            "corrected_text": "got, through",
            "line_number": 14,
            "page": "001.png"
        },
        {
            "type": "punctuation",
            "original_text": "iron bars fashioned",
            "corrected_text": "iron bars, fashioned",
            "line_number": 14,
            "page": "001.png"
        },
        {
            "type": "punctuation",
            "original_text": "grating where",
            "corrected_text": "grating, where",
            "line_number": 17,
            "page": "001.png"
        },
        {
            "type": "punctuation",
            "original_text": "outside and",
            "corrected_text": "outside; and",
            "line_number": 29,
            "page": "001.png"
        },
        {
            "type": "punctuation",
            "original_text": "intact in",
            "corrected_text": "intact, in",
            "line_number": 30,
            "page": "001.png"
        },
        {
            "type": "capitalization",
            "original_text": "indian ocean",
            "corrected_text": "Indian Ocean",
            "line_number": 31,
            "page": "001.png"
        },
        {
            "type": "punctuation",
            "original_text": "was waiting to be fed looking",
            "corrected_text": "was waiting to be fed; looking",
            "line_number": 36,
            "page": "001.png"
        },
        {
            "type": "punctuation",
            "original_text": "bars that",
            "corrected_text": "bars, that",
            "line_number": 36,
            "page": "001.png"
        }
    ]
}</code></pre>
            </div>
        </div>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/json.min.js"></script>
        <script>
            hljs.highlightAll();
        </script>
    </div>

    <p class="updated">Last updated: <span id="last-updated">2025-04-04</span></p>

    <footer>
        <p>
            For more information, visit the
            <a href="https://github.com/pairsys/little-dorrit-editor">Little Dorrit Editor repository</a>.
            The dataset is available on <a href="https://huggingface.co/datasets/pairsys/little-dorrit-editor">Hugging Face</a>.
        </p>
    </footer>

    <script>
        // Load data from results.json
        let leaderboardData = [];

        // Create and configure the leaderboard table
        const leaderboardTable = new Tabulator("#leaderboard-table", {
            data: leaderboardData,
            layout: "fitColumns",
            headerSort: true,
            initialSort: [{ column: "rank", dir: "asc" }],
            columns: [
                { title: "Rank", field: "rank", sorter: "number", width: 80, headerSort: false },
                {
                    title: "Model",
                    field: "model",
                    formatter: function(cell) {
                        const value = cell.getValue();
                        const row = cell.getRow().getData();
                        let medalClass = "";
                        let medalText = "";

                        if (row.rank === 1) {
                            medalClass = "gold";
                            medalText = "1";
                        } else if (row.rank === 2) {
                            medalClass = "silver";
                            medalText = "2";
                        } else if (row.rank === 3) {
                            medalClass = "bronze";
                            medalText = "3";
                        }

                        const shots = row.shots || 2;
                        const modelWithShots = `${value} (${shots}-shot)`;
                        
                        if (medalClass) {
                            return `<span class="medal ${medalClass}">${medalText}</span>${modelWithShots}`;
                        }
                        return modelWithShots;
                    }
                },
                {
                    title: "F1 Score",
                    field: "f1Score",
                    sorter: "number",
                    hozAlign: "center",
                    formatter: function(cell) {
                        return cell.getValue().toFixed(4);
                    }
                },
                {
                    title: "Precision",
                    field: "precision",
                    sorter: "number",
                    hozAlign: "center",
                    formatter: function(cell) {
                        return cell.getValue().toFixed(4);
                    }
                },
                {
                    title: "Recall",
                    field: "recall",
                    sorter: "number",
                    hozAlign: "center",
                    formatter: function(cell) {
                        return cell.getValue().toFixed(4);
                    }
                },
                { title: "Date", field: "date", sorter: "date", hozAlign: "center" }
            ]
        });

        // Function to load JSON data from results.json
        async function loadResults() {
            try {
                const response = await fetch('results.json');
                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }
                return await response.json();
            } catch (error) {
                console.error('Error loading results:', error);
                return [];
            }
        }
        
        // Function to find a model in the results data
        function findModel(results, modelName) {
            return results.find(model => model.model_name === modelName);
        }

        // Function to prepare data for the detailed model performance table
        async function prepareModelPerformanceData() {
            const results = await loadResults();
            const performanceData = [];

            for (const modelData of results) {
                if (!modelData) continue;

                // Add model summary row
                const modelRow = {
                    id: modelData.model_name,
                    model: modelData.model_name,
                    precision: modelData.precision,
                    recall: modelData.recall,
                    f1_score: modelData.f1_score,
                    true_positives: modelData.details.correct_count,
                    false_positives: modelData.details.total_predicted - modelData.details.correct_count,
                    false_negatives: modelData.details.total_ground_truth - modelData.details.correct_count,
                    _children: []
                };

                // Add file-specific rows as children
                if (modelData.details.file_results) {
                    for (const file of modelData.details.file_results) {
                        modelRow._children.push({
                            id: `${modelData.model_name}-${file.file_id}`,
                            model: `File ${file.file_id}`,
                            precision: file.precision,
                            recall: file.recall,
                            f1_score: file.f1_score,
                            true_positives: file.details.correct_count,
                            false_positives: file.details.total_predicted - file.details.correct_count,
                            false_negatives: file.details.total_ground_truth - file.details.correct_count
                        });
                    }
                }

                performanceData.push(modelRow);
            }

            return performanceData;
        }

        // Function to create and configure the model performance table
        async function createModelPerformanceTable() {
            const performanceData = await prepareModelPerformanceData();

            const performanceTable = new Tabulator("#model-performance-table", {
                data: performanceData,
                layout: "fitColumns",
                dataTree: true,
                dataTreeStartExpanded: false,
                dataTreeChildIndent: 20,
                columns: [
                    {
                        title: "Model / File",
                        field: "model",
                        width: 200,
                        resizable: true
                    },
                    {
                        title: "F1 Score",
                        field: "f1_score",
                        hozAlign: "center",
                        formatter: function(cell) {
                            const value = cell.getValue();
                            const formattedValue = value.toFixed(4);

                            let colorClass = "";
                            if (value >= 0.8) {
                                colorClass = "perfect-score";
                            } else if (value >= 0.5) {
                                colorClass = "good-score";
                            } else {
                                colorClass = "low-score";
                            }

                            return `<span><span class="performance-indicator ${colorClass}"></span>${formattedValue}</span>`;
                        }
                    },
                    {
                        title: "Precision",
                        field: "precision",
                        hozAlign: "center",
                        formatter: function(cell) {
                            return cell.getValue().toFixed(4);
                        }
                    },
                    {
                        title: "Recall",
                        field: "recall",
                        hozAlign: "center",
                        formatter: function(cell) {
                            return cell.getValue().toFixed(4);
                        }
                    },
                    {
                        title: "True Positives",
                        field: "true_positives",
                        hozAlign: "center"
                    },
                    {
                        title: "False Positives",
                        field: "false_positives",
                        hozAlign: "center"
                    },
                    {
                        title: "False Negatives",
                        field: "false_negatives",
                        hozAlign: "center"
                    }
                ]
            });

            return performanceTable;
        }

        // Initialize everything
        document.addEventListener("DOMContentLoaded", async function() {
            // Load data from results.json
            const results = await loadResults();
            
            // Format the data for the leaderboard table
            if (results && results.length > 0) {
                leaderboardData = results.map((model, index) => ({
                    rank: index + 1,
                    model: model.model_name,
                    shots: model.shots || 2,
                    f1Score: model.f1_score,
                    precision: model.precision,
                    recall: model.recall,
                    date: model.date ? model.date.split('T')[0] : 'Unknown'
                }));
                
                // Update the leaderboard table with real data
                leaderboardTable.setData(leaderboardData);
                
                // Update metrics
                if (results.length > 0) {
                    // Find best F1 score
                    const bestF1 = Math.max(...results.map(model => model.f1_score));
                    document.getElementById("best-f1-score").textContent = bestF1.toFixed(4);
                    
                    // Update model count
                    document.querySelector('.metrics .metric-card:nth-child(3) .metric-value').textContent = results.length;
                    
                    // Update top model
                    document.querySelector('.metrics .metric-card:nth-child(1) .metric-value').textContent = results[0].model_name;
                    
                    // Find most challenging edit type
                    let mostChallengingType = null;
                    let lowestF1 = 1.0;
                    
                    results.forEach(model => {
                        const byType = model.details?.by_type || {};
                        Object.entries(byType).forEach(([type, metrics]) => {
                            if (metrics.f1 < lowestF1 && metrics.count > 0) {
                                lowestF1 = metrics.f1;
                                mostChallengingType = type;
                            }
                        });
                    });
                    
                    if (mostChallengingType) {
                        const displayType = mostChallengingType.charAt(0).toUpperCase() + mostChallengingType.slice(1);
                        document.querySelector('.metrics .metric-card:nth-child(4) .metric-value').textContent = displayType;
                    }
                }
            }
            
            // Create detailed performance table
            createModelPerformanceTable();

            // Update the last updated date
            const lastDate = results.length > 0 ? new Date(results[0].date) : new Date();
            document.getElementById("last-updated").textContent = lastDate.toISOString().split('T')[0];
        });
    </script>
</body>
</html>
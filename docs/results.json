[
  {
    "model_name": "ChatGPT-4o",
    "model_id": "or_chatgpt_4o_latest",
    "date": "2025-04-07T00:18:05.148460",
    "shots": 2,
    "config": {
      "model_id": "or_chatgpt_4o_latest",
      "display_name": "ChatGPT-4o",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-05",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "ChatGPT-4o",
    "annotation_date": "2025-04-05T23:10:01.436660",
    "file_results": [
      {
        "model_name": "or_chatgpt_4o_latest",
        "date": "2025-04-07T00:09:56.117375",
        "annotator": "ChatGPT-4o",
        "annotation_date": "2025-04-05T23:10:01.436660",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "howling over yonder to-day, Sir",
            "corrected_text": "howling, over yonder to-day, sir",
            "observed_line_number": 1,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The predicted edit correctly matches the edit type in both cases as 'punctuation'. The core textual correction, introducing a comma after 'howling', is accurately captured. Although the prediction includes additional surrounding context ('yonder to-day, Sir') and slightly differs in capitalization in another part ('Sir' vs. 'sir'), these additional elements are beyond the essential change identified by the ground truth edit ('howling over' \u2192 'howling, over'). Since the core intention\u2014to insert a comma after 'howling'\u2014is correctly identified and implemented in the prediction, and since extra context provided by the prediction is acceptable, this predicted edit is considered correct according to the evaluation criteria provided."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": 1,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The predicted edit precisely matches the ground truth edit in both criteria. Firstly, the edit type ('capitalization') is identical between the ground truth and the prediction, satisfying the edit type accuracy criterion. Secondly, the text content change demonstrated by converting 'Sir' to 'sir' is accurately captured by the predicted edit, thus satisfying the text content accuracy criterion. The discrepancy in the page identifier ('003.png' vs. 'page_19') is not relevant to the criteria specified and does not affect the correctness of capturing the intended edit."
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "pockets and rattling",
            "corrected_text": "pockets, and rattling",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_chatgpt_4o_latest",
        "date": "2025-04-07T00:10:42.580301",
        "annotator": "ChatGPT-4o",
        "annotation_date": "2025-04-05T23:40:08.388510",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": 1,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The predicted edit matches exactly the ground truth edit type ('punctuation'), correctly identifies the original text ('howling over'), and accurately applies the necessary punctuation ('howling, over'). The difference in 'page' naming ('003.png' vs 'page_19') is irrelevant as per instructions, and the line number is explicitly ignored. Thus, both the edit type and the text content are accurately captured, satisfying the evaluation criteria."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": 1,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The predicted edit type ('punctuation') exactly matches the ground truth type. The text content ('yonder to-day' \u2192 'yonder, to-day') also matches exactly, capturing the essential punctuation edit as intended by the ground truth. The differences in the page identifier (ground truth '003.png' versus prediction 'page_19') and the line numbers were instructed to be ignored, thus these variations do not impact accuracy. Overall, both criteria\u2014edit type and text content accuracy\u2014are fully met."
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sir",
            "corrected_text": "sir,",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_chatgpt_4o_latest",
        "date": "2025-04-07T00:11:14.635457",
        "annotator": "ChatGPT-4o",
        "annotation_date": "2025-04-05T23:10:52.921168",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "capitalization",
            "original_text": "why",
            "corrected_text": "Why",
            "observed_line_number": 27,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The edit type matches exactly ('capitalization'). Although the ground truth correction applies to a full phrase ('why did he dine') and the prediction mentions only the first word ('why'), the core intended correction\u2014capitalizing the first word 'why' to 'Why'\u2014is accurately captured. Thus, the essential editing intention is correctly identified."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stones\u201d",
            "corrected_text": "stones?\u201d",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_chatgpt_4o_latest",
        "date": "2025-04-07T00:11:52.368506",
        "annotator": "ChatGPT-4o",
        "annotation_date": "2025-04-05T23:41:09.189509",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "capitalization",
            "original_text": "why",
            "corrected_text": "Why",
            "observed_line_number": 27,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The predicted edit has the correct edit type, 'capitalization', matching exactly with the ground truth type. Although the predicted edit provides a shorter original and corrected text ('why' \u2192 'Why'), it accurately captures the essential text change intended by the ground truth edit ('why did he dine' \u2192 'Why did he dine'). According to the given instructions, additional context or fewer words are acceptable, provided the core editorial intention is accurately identified and corrected. Therefore, this prediction correctly captures the ground truth's intended capitalization change."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stones\u201d",
            "corrected_text": "stones?\u201d",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_chatgpt_4o_latest",
        "date": "2025-04-07T00:12:45.726689",
        "annotator": "ChatGPT-4o",
        "annotation_date": "2025-04-05T23:11:44.358943",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.09999999999999998,
            "fp": 0.45,
            "fn": 0.45,
            "type": "capitalization",
            "original_text": "if",
            "corrected_text": "If",
            "observed_line_number": 33,
            "line_diff": 3,
            "line_number_penalty": 0.9,
            "judgement": "The predicted edit correctly matches the edit type: both ground truth and prediction are 'capitalization'. The text content accuracy criterion is also satisfied; the essential capitalization edit from 'if' to 'If' is precisely reflected. Although the ground truth includes an adjacent word ('he'), the core correction\u2014capitalizing 'if'\u2014is correctly captured in the prediction. Therefore, the prediction accurately represents the ground truth's intended edit."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 0.09999999999999998,
            "fp": 0.45,
            "fn": 0.45,
            "type": "replacement",
            "original_text": "said",
            "corrected_text": "asked",
            "observed_line_number": 36,
            "line_diff": 3,
            "line_number_penalty": 0.9,
            "judgement": "The predicted edit matches the ground truth edit accurately in two key aspects: First, the edit type 'replacement' exactly matches. Second, the predicted replacement ('said' \u2192 'asked') faithfully captures the core textual change shown in the ground truth ('said Clennam' \u2192 'asked Clennam'). Although the predicted content omits the name 'Clennam', the core correction ('said' changed to 'asked') remains clearly and accurately represented, fulfilling the criteria defined for text content accuracy."
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_chatgpt_4o_latest",
        "date": "2025-04-07T00:13:21.233679",
        "annotator": "ChatGPT-4o",
        "annotation_date": "2025-04-05T23:42:11.229625",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.09999999999999998,
            "fp": 0.45,
            "fn": 0.45,
            "type": "replacement",
            "original_text": "said",
            "corrected_text": "asked",
            "observed_line_number": 36,
            "line_diff": 3,
            "line_number_penalty": 0.9,
            "judgement": "The predicted edit correctly matches the edit type as a 'replacement', identical to the ground truth edit type. Regarding text content, the predicted edit accurately captures the core textual change from 'said' to 'asked'. Although the predicted edit omits 'Clennam', this is acceptable based on provided instructions, which allow omission of context as long as the essential edit (the actual word replacement 'said' to 'asked') is accurately represented. Hence, both criteria (edit type accuracy and essential text content accuracy) are correctly fulfilled."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "If",
            "corrected_text": "if",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_chatgpt_4o_latest",
        "date": "2025-04-07T00:14:23.195148",
        "annotator": "ChatGPT-4o",
        "annotation_date": "2025-04-05T23:12:47.364791",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.09999999999999998,
            "fp": 0.45,
            "fn": 0.45,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": 10,
            "line_diff": 3,
            "line_number_penalty": 0.9,
            "judgement": "The edit type 'punctuation' perfectly matches the ground truth edit type. The textual edit from 'about and' to 'about, and' is also accurately captured in both the predicted and ground truth corrections. Additional context differences (such as page number) are irrelevant based on evaluation criteria provided. Thus, the essential correction and edit type are correctly and fully captured."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": 28,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The prediction correctly identifies the edit type as 'punctuation', matching the ground truth exactly. Additionally, the prediction correctly captures the core change from 'Clennam in' to 'Clennam, in', accurately matching the text content edit from the ground truth. The differing page and line numbers are explicitly ignored according to the instructions, so overall, the prediction correctly captures the intended edit."
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "high-road",
            "corrected_text": "highroad",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_chatgpt_4o_latest",
        "date": "2025-04-07T00:15:15.519925",
        "annotator": "ChatGPT-4o",
        "annotation_date": "2025-04-05T23:43:13.290681",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": 24,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The prediction correctly matches the edit type ('punctuation'), exactly as indicated by the ground truth. In terms of text content, the ground truth indicates the punctuation addition ('said when' \u2192 'said, when'), highlighting the insertion of a comma after 'said'. The predicted edit correctly captures this exact punctuation addition ('said' \u2192 'said,'). Although the prediction omits the subsequent context ('when'), it clearly identifies the CORE punctuation change\u2014the insertion of the comma after the word 'said'. Since additional context is allowed and the main intended punctuation correction has been accurately identified, the predicted edit correctly reflects the intention of the ground truth."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": 28,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The edit type ('punctuation') exactly matches between the ground truth and the prediction. The text content is also accurately captured\u2014the predicted edit correctly identifies the essential punctuation change ('Clennam in' \u2192 'Clennam, in') that is detailed in the ground truth. The differences in page numbering and line numbers were explicitly ignored as per the evaluation criteria. Therefore, the predicted edit correctly captures the intention of the ground truth edit."
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "high-road",
            "corrected_text": "highroad",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_chatgpt_4o_latest",
        "date": "2025-04-07T00:15:47.753710",
        "annotator": "ChatGPT-4o",
        "annotation_date": "2025-04-05T23:13:37.748795",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow,",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_chatgpt_4o_latest",
        "date": "2025-04-07T00:16:22.837429",
        "annotator": "ChatGPT-4o",
        "annotation_date": "2025-04-05T23:44:03.356108",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow,",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_chatgpt_4o_latest",
        "date": "2025-04-07T00:17:18.810929",
        "annotator": "ChatGPT-4o",
        "annotation_date": "2025-04-05T23:14:34.217719",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.6,
            "fp": 0.2,
            "fn": 0.2,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": 7,
            "line_diff": 2,
            "line_number_penalty": 0.4,
            "judgement": "The predicted edit correctly identifies the edit type: both the ground truth and the predicted edit are classified as 'punctuation'. Additionally, it correctly captures the core textual change by inserting a comma after 'man', changing 'man slowly' to 'man, slowly'. Despite differences in line numbers and page references\u2014which were explicitly instructed to ignore\u2014the essential punctuation correction matches exactly. Therefore, the predicted edit accurately reflects the intention behind the ground truth edit."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "stream",
            "corrected_text": "stream,",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "Saone",
            "corrected_text": "Saone,",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "soddenwith",
            "corrected_text": "soddened with",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "trees",
            "corrected_text": "trees\u2014",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_chatgpt_4o_latest",
        "date": "2025-04-07T00:18:05.148460",
        "annotator": "ChatGPT-4o",
        "annotation_date": "2025-04-05T23:44:58.254001",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.09999999999999998,
            "fp": 0.45,
            "fn": 0.45,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": 6,
            "line_diff": 3,
            "line_number_penalty": 0.9,
            "judgement": "The predicted edit correctly matches the edit type ('punctuation') provided in the ground truth. Additionally, the predicted text content ('man slowly' to 'man, slowly') precisely matches the core punctuation correction specified in the ground truth. Since line numbers and page identifiers are explicitly ignored, no discrepancies affect the evaluation. Therefore, the prediction accurately captures the intention of the ground truth edit."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "Saone.",
            "corrected_text": "Saone. The",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "Saone it",
            "corrected_text": "Saone it was,",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sodden with",
            "corrected_text": "sodden, with",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  },
  {
    "model_name": "DeepSeek R1",
    "model_id": "or_deepseek_r1",
    "date": "2025-04-07T00:22:17.593078",
    "shots": 2,
    "config": {
      "model_id": "or_deepseek_r1",
      "display_name": "DeepSeek R1",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-06",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "DeepSeek R1",
    "annotation_date": "2025-04-06T09:29:50.621110",
    "file_results": [
      {
        "model_name": "or_deepseek_r1",
        "date": "2025-04-07T00:20:31.132263",
        "annotator": "DeepSeek R1",
        "annotation_date": "2025-04-06T09:29:50.621110",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "the adventures of sherlock holmes",
            "corrected_text": "The Adventures of Sherlock Holmes",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "door way",
            "corrected_text": "door-way",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "mr",
            "corrected_text": "Mr.",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "well known",
            "corrected_text": "well-known",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "end",
            "corrected_text": "end,",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_deepseek_r1",
        "date": "2025-04-07T00:20:52.133882",
        "annotator": "DeepSeek R1",
        "annotation_date": "2025-04-06T09:33:13.148476",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun light",
            "corrected_text": "sun-light",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "english channel",
            "corrected_text": "English Channel",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "however when",
            "corrected_text": "however, when",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "however",
            "corrected_text": "However",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_deepseek_r1",
        "date": "2025-04-07T00:21:13.704292",
        "annotator": "DeepSeek R1",
        "annotation_date": "2025-04-06T09:39:03.832099",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "chapter three",
            "corrected_text": "CHAPTER THREE",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sunset,and",
            "corrected_text": "sunset, and",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "captain's log",
            "corrected_text": "Captain's Log",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "twenty three",
            "corrected_text": "twenty-three",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sea creatures",
            "corrected_text": "sea-creatures",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "theyre",
            "corrected_text": "they're",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "sailers",
            "corrected_text": "sailors",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_deepseek_r1",
        "date": "2025-04-07T00:21:34.555642",
        "annotator": "DeepSeek R1",
        "annotation_date": "2025-04-06T09:45:52.789570",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "darkness fell",
            "corrected_text": "darkness fell,",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "atlantic ocean",
            "corrected_text": "Atlantic Ocean",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "post war",
            "corrected_text": "post-war",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "however when",
            "corrected_text": "however, when",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "roman empire",
            "corrected_text": "Roman Empire",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "well being",
            "corrected_text": "well-being",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_deepseek_r1",
        "date": "2025-04-07T00:21:57.176857",
        "annotator": "DeepSeek R1",
        "annotation_date": "2025-04-06T09:49:34.938568",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "eyes by",
            "corrected_text": "eyes, by",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "white but",
            "corrected_text": "white, but",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles harbour",
            "corrected_text": "Marseilles Harbour",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "terrace gardens",
            "corrected_text": "terrace-gardens",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Civita Vecchia so",
            "corrected_text": "Civita Vecchia. So",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_deepseek_r1",
        "date": "2025-04-07T00:22:17.593078",
        "annotator": "DeepSeek R1",
        "annotation_date": "2025-04-06T09:50:14.528551",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "eyes by",
            "corrected_text": "eyes, by",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "white but",
            "corrected_text": "white, but",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles harbour",
            "corrected_text": "Marseilles Harbour",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "terrace gardens",
            "corrected_text": "terrace-gardens",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Civita Vecchia so",
            "corrected_text": "Civita Vecchia. So",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  },
  {
    "model_name": "DeepSeek V3 0324",
    "model_id": "or_deepseek_chat_v3_0324",
    "date": "2025-04-07T00:20:11.952184",
    "shots": 2,
    "config": {
      "model_id": "or_deepseek_chat_v3_0324",
      "display_name": "DeepSeek V3 0324",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-06",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "DeepSeek V3 0324",
    "annotation_date": "2025-04-06T09:15:42.042190",
    "file_results": [
      {
        "model_name": "or_deepseek_chat_v3_0324",
        "date": "2025-04-07T00:18:27.586981",
        "annotator": "DeepSeek V3 0324",
        "annotation_date": "2025-04-06T09:15:42.042190",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun rose",
            "corrected_text": "sun, rose",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "english",
            "corrected_text": "English",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "big",
            "corrected_text": "large",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "ship however",
            "corrected_text": "ship, however",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "very",
            "corrected_text": "",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "quite",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "deck and",
            "corrected_text": "deck, and",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_deepseek_chat_v3_0324",
        "date": "2025-04-07T00:18:46.235360",
        "annotator": "DeepSeek V3 0324",
        "annotation_date": "2025-04-06T09:16:22.802984",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "morning and",
            "corrected_text": "morning, and",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "english",
            "corrected_text": "English",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "big",
            "corrected_text": "large",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "very",
            "corrected_text": "",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "extremely",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "however he",
            "corrected_text": "however, he",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_deepseek_chat_v3_0324",
        "date": "2025-04-07T00:19:08.267311",
        "annotator": "DeepSeek V3 0324",
        "annotation_date": "2025-04-06T09:16:47.591721",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_deepseek_chat_v3_0324",
        "date": "2025-04-07T00:19:30.023493",
        "annotator": "DeepSeek V3 0324",
        "annotation_date": "2025-04-06T09:17:35.697621",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "church bells",
            "corrected_text": "church bells,",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "wine bottles",
            "corrected_text": "wine-bottles",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "got through",
            "corrected_text": "got, through",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "iron bars fashioned",
            "corrected_text": "iron bars, fashioned",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "grating where",
            "corrected_text": "grating, where",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "outside and",
            "corrected_text": "outside; and",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "intact in",
            "corrected_text": "intact, in",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "indian ocean",
            "corrected_text": "Indian Ocean",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "was waiting to be fed looking",
            "corrected_text": "was waiting to be fed; looking",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "bars that",
            "corrected_text": "bars, that",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_deepseek_chat_v3_0324",
        "date": "2025-04-07T00:19:49.304593",
        "annotator": "DeepSeek V3 0324",
        "annotation_date": "2025-04-06T09:18:25.867056",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "church bells",
            "corrected_text": "church bells,",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "wine bottles",
            "corrected_text": "wine-bottles",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "got through",
            "corrected_text": "got, through",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "iron bars fashioned",
            "corrected_text": "iron bars, fashioned",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "grating where",
            "corrected_text": "grating, where",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "outside and",
            "corrected_text": "outside; and",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "intact in",
            "corrected_text": "intact, in",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "indian ocean",
            "corrected_text": "Indian Ocean",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "was waiting to be fed looking",
            "corrected_text": "was waiting to be fed; looking",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "bars that",
            "corrected_text": "bars, that",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "eyes by",
            "corrected_text": "eyes, by",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "white but",
            "corrected_text": "white, but",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles harbour",
            "corrected_text": "Marseilles Harbour",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "terrace gardens",
            "corrected_text": "terrace-gardens",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Civita Vecchia so",
            "corrected_text": "Civita Vecchia. So",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_deepseek_chat_v3_0324",
        "date": "2025-04-07T00:20:11.952184",
        "annotator": "DeepSeek V3 0324",
        "annotation_date": "2025-04-06T09:20:39.225748",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Dantes",
            "corrected_text": "Dantes,",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Dantes who",
            "corrected_text": "Dantes, who",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Dantes and",
            "corrected_text": "Dantes, and",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Dantes with",
            "corrected_text": "Dantes, with",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Dantes though",
            "corrected_text": "Dantes, though",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Dantes as",
            "corrected_text": "Dantes, as",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Dantes that",
            "corrected_text": "Dantes, that",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Dantes when",
            "corrected_text": "Dantes, when",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Dantes after",
            "corrected_text": "Dantes, after",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Dantes before",
            "corrected_text": "Dantes, before",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  },
  {
    "model_name": "GPT-4 Turbo",
    "model_id": "or_gpt_4_turbo",
    "date": "2025-04-07T00:47:33.555548",
    "shots": 2,
    "config": {
      "model_id": "or_gpt_4_turbo",
      "display_name": "GPT-4 Turbo",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-05",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "GPT-4o",
    "annotation_date": "2025-04-05T22:55:17.722887",
    "file_results": [
      {
        "model_name": "or_gpt_4_turbo",
        "date": "2025-04-07T00:41:59.207485",
        "annotator": "GPT-4o",
        "annotation_date": "2025-04-05T22:55:17.722887",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "to-day, Sir,",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "howling,over",
            "corrected_text": "howling, over",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_gpt_4_turbo",
        "date": "2025-04-07T00:42:19.958912",
        "annotator": "GPT-4o",
        "annotation_date": "2025-04-05T23:25:31.990978",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "to-day, Sir,",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_gpt_4_turbo",
        "date": "2025-04-07T00:42:42.608277",
        "annotator": "GPT-4o",
        "annotation_date": "2025-04-05T22:56:15.811371",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "cap",
            "corrected_text": "Cap",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "why did he dine to",
            "corrected_text": "why did he deign to",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_gpt_4_turbo",
        "date": "2025-04-07T00:43:03.450841",
        "annotator": "GPT-4o",
        "annotation_date": "2025-04-05T23:26:25.422866",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "cap",
            "corrected_text": "Cap",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "why did he dine to",
            "corrected_text": "why did he deign to",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_gpt_4_turbo",
        "date": "2025-04-07T00:43:43.257025",
        "annotator": "GPT-4o",
        "annotation_date": "2025-04-05T22:57:08.649014",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.09999999999999998,
            "fp": 0.45,
            "fn": 0.45,
            "type": "capitalization",
            "original_text": "if",
            "corrected_text": "If",
            "observed_line_number": 33,
            "line_diff": 3,
            "line_number_penalty": 0.9,
            "judgement": "The predicted edit has an exact match in edit type ('capitalization'), correctly changing lowercase 'if' to uppercase 'If'. Despite the ground truth including additional context ('if he' \u2192 'If he'), the core capitalization edit (the lowercase 'i' in 'if' corrected to uppercase 'I') has been accurately captured in the predicted edit ('if' \u2192 'If'). Therefore, both the edit type and the key textual correction effectively match the ground truth's intention."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "said",
            "corrected_text": "asked",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_gpt_4_turbo",
        "date": "2025-04-07T00:44:03.263241",
        "annotator": "GPT-4o",
        "annotation_date": "2025-04-05T23:27:17.134652",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "said",
            "corrected_text": "asked",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "if",
            "corrected_text": "If",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_gpt_4_turbo",
        "date": "2025-04-07T00:44:43.323652",
        "annotator": "GPT-4o",
        "annotation_date": "2025-04-05T22:58:01.314179",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.6,
            "fp": 0.2,
            "fn": 0.2,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": 25,
            "line_diff": 2,
            "line_number_penalty": 0.4,
            "judgement": "The predicted edit correctly identifies the edit type as \"punctuation,\" matching the ground truth exactly. Regarding text content accuracy, the ground truth edit changes \"said when\" to \"said, when,\" explicitly indicating the addition of a comma immediately after \"said.\" The prediction similarly captures the core punctuation change by indicating \"said\" corrected to \"said,\" explicitly pinpointing the same comma insertion. Although the predicted edit includes slightly less context (\"said\" instead of \"said when\"), it accurately captures the essential punctuation change intended by the ground truth. Therefore, both criteria\u2014edit type and essential punctuation change\u2014are correctly satisfied by the predicted edit."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "high-road",
            "corrected_text": "high-road",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_gpt_4_turbo",
        "date": "2025-04-07T00:45:12.891994",
        "annotator": "GPT-4o",
        "annotation_date": "2025-04-05T23:28:15.294492",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": 23,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The predicted edit correctly matches the ground truth in terms of edit type (punctuation). The core punctuation change from 'said' to 'said,' is accurately captured. Although the predicted edit omits the following word 'when', this omission does not affect the essential correction's core intention, which was specifically adding a comma after 'said'. Thus, the prediction is correct."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "high-road",
            "corrected_text": "high-road",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_gpt_4_turbo",
        "date": "2025-04-07T00:45:46.322402",
        "annotator": "GPT-4o",
        "annotation_date": "2025-04-05T22:58:58.515530",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": 1,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The predicted edit correctly matches the ground truth in the specified criteria. First, the 'type' field matches exactly ('punctuation' in both cases). Secondly, the textual correction accurately captures the intentional punctuation addition; both the original and the corrected text provided in the prediction ('Sun and Shadow' \u2192 'Sun and Shadow.') exactly match the core punctuation addition from the ground truth. Although the page and line number differ, according to the evaluation instruction, line numbers (and therefore implicitly page numbers as well) should be ignored. Thus, the prediction is considered correct."
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_gpt_4_turbo",
        "date": "2025-04-07T00:46:19.500251",
        "annotator": "GPT-4o",
        "annotation_date": "2025-04-05T23:29:06.063177",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": 1,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The edit type matches exactly as 'punctuation.' The predicted edit correctly captures the essential core change, adding a period at the end of 'Sun and Shadow.' Since the instruction explicitly states to ignore line number differences, the discrepancy in page numbers and line numbers is irrelevant for this evaluation. Thus, the edit type and text content both precisely match the ground truth's intention."
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_gpt_4_turbo",
        "date": "2025-04-07T00:46:56.225196",
        "annotator": "GPT-4o",
        "annotation_date": "2025-04-05T22:59:54.162193",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "gloomy place, reflected",
            "corrected_text": "gloomy place, reflected",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Saone it",
            "corrected_text": "Saone it",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sodden with",
            "corrected_text": "sodden with",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_gpt_4_turbo",
        "date": "2025-04-07T00:47:33.555548",
        "annotator": "GPT-4o",
        "annotation_date": "2025-04-05T23:30:02.174560",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "looking-glass in",
            "corrected_text": "looking-glass, in",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Saone it",
            "corrected_text": "Saone, it",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sodden with",
            "corrected_text": "sodden, with",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  },
  {
    "model_name": "GPT-4.5 Preview",
    "model_id": "or_gpt_4_5_preview",
    "date": "2025-04-07T00:41:40.035600",
    "shots": 2,
    "config": {
      "model_id": "or_gpt_4_5_preview",
      "display_name": "GPT-4.5 Preview",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-05",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "GPT-4.5 Preview (OpenRouter)",
    "annotation_date": "2025-04-05T21:29:54.853218",
    "file_results": [
      {
        "model_name": "or_gpt_4_5_preview",
        "date": "2025-04-07T00:34:21.960138",
        "annotator": "GPT-4.5 Preview (OpenRouter)",
        "annotation_date": "2025-04-05T21:29:54.853218",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.09999999999999998,
            "fp": 0.45,
            "fn": 0.45,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": 20,
            "line_diff": 3,
            "line_number_penalty": 0.9,
            "judgement": "The predicted edit type ('punctuation') matches exactly with the ground truth. The text content correction ('pockets and' \u2192 'pockets, and') also exactly matches the ground truth. Although line numbers differ, they were explicitly ignored, so this does not affect accuracy. Both criteria\u2014edit type and text content\u2014are correctly fulfilled, making this prediction correct."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "day sir",
            "corrected_text": "day, sir",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_gpt_4_5_preview",
        "date": "2025-04-07T00:34:57.358382",
        "annotator": "GPT-4.5 Preview (OpenRouter)",
        "annotation_date": "2025-04-05T22:29:48.516659",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.6,
            "fp": 0.2,
            "fn": 0.2,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": 19,
            "line_diff": 2,
            "line_number_penalty": 0.4,
            "judgement": "The prediction correctly matches the edit type (punctuation) exactly with the ground truth. In terms of text content, it accurately captures the edit by identifying the insertion of the comma in 'pockets and' \u2192 'pockets, and'. Since we're explicitly instructed to ignore line numbers, the slight discrepancy there does not matter. Both key criteria (edit type accuracy and core text content accuracy) are fully met by the prediction."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "day sir",
            "corrected_text": "day, sir",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_gpt_4_5_preview",
        "date": "2025-04-07T00:35:57.914008",
        "annotator": "GPT-4.5 Preview (OpenRouter)",
        "annotation_date": "2025-04-05T21:30:45.397802",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "think why",
            "corrected_text": "think, why",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "he",
            "corrected_text": "He",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stones!",
            "corrected_text": "stones!\"",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_gpt_4_5_preview",
        "date": "2025-04-07T00:36:55.460846",
        "annotator": "GPT-4.5 Preview (OpenRouter)",
        "annotation_date": "2025-04-05T22:30:39.597868",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "think why",
            "corrected_text": "think, why",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "he",
            "corrected_text": "He",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stones",
            "corrected_text": "stones?",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_gpt_4_5_preview",
        "date": "2025-04-07T00:37:15.984486",
        "annotator": "GPT-4.5 Preview (OpenRouter)",
        "annotation_date": "2025-04-05T21:31:36.868210",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "he",
            "corrected_text": "He",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "said",
            "corrected_text": "",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "asked",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_gpt_4_5_preview",
        "date": "2025-04-07T00:37:53.668225",
        "annotator": "GPT-4.5 Preview (OpenRouter)",
        "annotation_date": "2025-04-05T22:31:38.397235",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "said",
            "corrected_text": "",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "asked",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "he",
            "corrected_text": "He",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_gpt_4_5_preview",
        "date": "2025-04-07T00:38:17.877399",
        "annotator": "GPT-4.5 Preview (OpenRouter)",
        "annotation_date": "2025-04-05T21:32:42.331099",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "high-road",
            "corrected_text": "high road",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "materials",
            "corrected_text": "materials,",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "tion,",
            "corrected_text": "",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "did",
            "corrected_text": ", did",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "telling",
            "corrected_text": ", telling",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "for what",
            "corrected_text": ", for what,",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "said",
            "corrected_text": "comma?",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "in",
            "corrected_text": "",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_gpt_4_5_preview",
        "date": "2025-04-07T00:38:41.397375",
        "annotator": "GPT-4.5 Preview (OpenRouter)",
        "annotation_date": "2025-04-05T22:32:35.138304",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "high-road",
            "corrected_text": "high-road",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "materials",
            "corrected_text": "materials,",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "about",
            "corrected_text": "about,",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "tion,",
            "corrected_text": "",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "telling",
            "corrected_text": ", telling",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "for what",
            "corrected_text": ", for what,",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "said",
            "corrected_text": "said (comma?)",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "Clennam,",
            "corrected_text": "Clennam",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "amazement",
            "corrected_text": "amazement,",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_gpt_4_5_preview",
        "date": "2025-04-07T00:39:16.688575",
        "annotator": "GPT-4.5 Preview (OpenRouter)",
        "annotation_date": "2025-04-05T21:33:34.283640",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Chapter 1",
            "corrected_text": "Chapter 1.",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow,",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_gpt_4_5_preview",
        "date": "2025-04-07T00:39:35.718311",
        "annotator": "GPT-4.5 Preview (OpenRouter)",
        "annotation_date": "2025-04-05T22:33:26.145066",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Chapter 1",
            "corrected_text": "Chapter 1.",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_gpt_4_5_preview",
        "date": "2025-04-07T00:40:41.460498",
        "annotator": "GPT-4.5 Preview (OpenRouter)",
        "annotation_date": "2025-04-05T21:34:33.529007",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": 8,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The predicted edit matches exactly the edit type ('punctuation') specified by the ground truth. The core textual change\u2014adding a comma after 'man' resulting in 'man, slowly'\u2014is entirely consistent with the ground truth. Since line numbers and page references are explicitly ignored according to the evaluation criteria, these discrepancies do not impact assessment accuracy. Thus, the prediction accurately captures both the edit type and the text content intended by the ground truth edit."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": 8,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The edit type matches exactly ('punctuation'). Additionally, the text content 'Chalons was' \u2192 'Chalons, was' precisely captures the ground truth edit. Both the original and corrected texts match exactly, correctly reflecting the addition of a comma after 'Chalons'. Ignoring line number differences, as instructed, the predicted edit accurately captures the intention of the ground truth edit."
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "late dull",
            "corrected_text": "late, dull",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "like a sullied looking-glass",
            "corrected_text": "like a sullied looking-glass,",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "river Saone",
            "corrected_text": "river Saone,",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "sodden with",
            "corrected_text": "soddened with",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_gpt_4_5_preview",
        "date": "2025-04-07T00:41:40.035600",
        "annotator": "GPT-4.5 Preview (OpenRouter)",
        "annotation_date": "2025-04-05T22:34:26.204698",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.09999999999999998,
            "fp": 0.45,
            "fn": 0.45,
            "type": "replacement",
            "original_text": "sodden with",
            "corrected_text": "soddened with",
            "observed_line_number": 11,
            "line_diff": 3,
            "line_number_penalty": 0.9,
            "judgement": "The predicted edit correctly identifies the edit type ('replacement'), which exactly matches the ground truth's edit type. Regarding text content accuracy, the ground truth edit changes 'sodden' to 'soddened'. Similarly, the predicted edit makes precisely the same core change ('sodden' \u2192 'soddened') and differs only by including additional context ('with'). Additional context is explicitly allowed. Thus, the essential core correction is correctly captured, meeting both edit type accuracy and text content accuracy requirements."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "late dull autumn",
            "corrected_text": "late, dull autumn",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "stream like",
            "corrected_text": "stream, like",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "river Saone",
            "corrected_text": "river Saone,",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  },
  {
    "model_name": "GPT-4o (2024-11-20)",
    "model_id": "or_gpt_4o_2024_11_20",
    "date": "2025-04-07T00:56:15.617845",
    "shots": 2,
    "config": {
      "model_id": "or_gpt_4o_2024_11_20",
      "display_name": "GPT-4o (2024-11-20)",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-05",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "GPT-4o (2024-11-20)",
    "annotation_date": "2025-04-05T23:02:41.177868",
    "file_results": [
      {
        "model_name": "or_gpt_4o_2024_11_20",
        "date": "2025-04-07T00:48:32.975695",
        "annotator": "GPT-4o (2024-11-20)",
        "annotation_date": "2025-04-05T23:02:41.177868",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": 0,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The predicted edit matches the ground truth exactly in both edit type ('punctuation') and text content ('Fellow Travellers' to 'Fellow Travellers.'). Differences in page identification ('003.png' vs '19') are not part of the evaluation criteria and are thus ignored. Therefore, this predicted edit correctly captures the intention of the ground truth edit."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "howling over yonder to-day, sir",
            "corrected_text": "howling, over yonder, to-day, sir",
            "observed_line_number": 1,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The predicted edit's 'type' is 'punctuation,' exactly matching the ground truth edit type. The essential punctuation change from 'howling over' to 'howling, over' is accurately captured within the predicted correction 'howling, over yonder, to-day, sir.' The predicted edit correctly reflects the core change identified by the ground truth, and the additional context ('yonder, to-day, sir') does not impede or alter the essential correction. Therefore, the edit type and core text correction are completely accurate with regard to the ground truth."
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": 2,
            "tp": 0.6,
            "fp": 0.2,
            "fn": 0.2,
            "type": "punctuation",
            "original_text": "pockets and rattling",
            "corrected_text": "pockets, and rattling",
            "observed_line_number": 15,
            "line_diff": 2,
            "line_number_penalty": 0.4,
            "judgement": "The predicted edit accurately matches the ground truth in both criteria. Firstly, the edit type ('punctuation') exactly matches the ground truth. Secondly, although the predicted edit includes additional surrounding words ('rattling'), the essential punctuation correction ('pockets and' \u2192 'pockets, and') is correctly captured. Extra surrounding context is allowed as per instructions, as long as the core change is correct, which it is in this case. Therefore, the prediction is correct."
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_gpt_4o_2024_11_20",
        "date": "2025-04-07T00:49:16.206551",
        "annotator": "GPT-4o (2024-11-20)",
        "annotation_date": "2025-04-05T23:32:45.287165",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": 1,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The predicted edit type ('punctuation') exactly matches the ground truth edit type ('punctuation'). The predicted text content ('yonder to-day' \u2192 'yonder, to-day') exactly matches the ground truth edit as well. The predicted edit correctly captures the intended punctuation insertion (comma after 'yonder'). The difference in the page identifier ('003.png' vs '19') is irrelevant to this evaluation based on the stated criteria. Therefore, both essential criteria (edit type and text content accuracy) are fully satisfied."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 0.09999999999999998,
            "fp": 0.45,
            "fn": 0.45,
            "type": "punctuation",
            "original_text": "pockets and rattling",
            "corrected_text": "pockets, and rattling",
            "observed_line_number": 14,
            "line_diff": 3,
            "line_number_penalty": 0.9,
            "judgement": "The predicted edit correctly matches the ground truth in terms of edit type, as both specify punctuation. The core change identified by the ground truth\u2014adding a comma after 'pockets'\u2014is accurately captured despite the extra word 'rattling' included in the prediction for additional context. By the criteria provided, extra context is allowed as long as the essential edit is accurately preserved. Therefore, the prediction is considered correct."
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day, sir",
            "corrected_text": "to-day, Sir",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Marseilles people",
            "corrected_text": "Marseilles' people",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_gpt_4o_2024_11_20",
        "date": "2025-04-07T00:49:51.594634",
        "annotator": "GPT-4o (2024-11-20)",
        "annotation_date": "2025-04-05T23:03:35.445250",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "capitalization",
            "original_text": "why",
            "corrected_text": "Why",
            "observed_line_number": 27,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The predicted edit type ('capitalization') matches exactly with the ground truth edit type. Additionally, the predicted change 'why' \u2192 'Why' correctly captures the essential capitalization edit identified by the ground truth ('why did he dine' \u2192 'Why did he dine'). Although the prediction presents only one word ('why') rather than the entire phrase ('why did he dine'), this still successfully captures the core edit intention (capitalizing the first word). Thus, both edit type and the essential text content change are accurately represented, and the prediction is correct according to the evaluation criteria."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stones\"",
            "corrected_text": "stones.\"",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_gpt_4o_2024_11_20",
        "date": "2025-04-07T00:50:28.978263",
        "annotator": "GPT-4o (2024-11-20)",
        "annotation_date": "2025-04-05T23:33:39.760204",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.6,
            "fp": 0.2,
            "fn": 0.2,
            "type": "capitalization",
            "original_text": "why",
            "corrected_text": "Why",
            "observed_line_number": 26,
            "line_diff": 2,
            "line_number_penalty": 0.4,
            "judgement": "The predicted edit's type 'capitalization' exactly matches the ground truth edit type. Regarding the text content, the ground truth capitalizes 'why' at the beginning of a phrase: 'why did he dine' to 'Why did he dine'. The predicted edit also focuses correctly on capitalizing the initial word 'why' to 'Why'. Even though the ground truth includes additional context ('did he dine') and the prediction focuses solely on the initial word 'why', the key core edit (capitalizing 'why') is accurately captured. Therefore, both type and essential text content match the ground truth's intention."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stones\"",
            "corrected_text": "stones.\"",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_gpt_4o_2024_11_20",
        "date": "2025-04-07T00:51:14.286895",
        "annotator": "GPT-4o (2024-11-20)",
        "annotation_date": "2025-04-05T23:04:25.821278",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.6,
            "fp": 0.2,
            "fn": 0.2,
            "type": "capitalization",
            "original_text": "if",
            "corrected_text": "If",
            "observed_line_number": 38,
            "line_diff": 2,
            "line_number_penalty": 0.4,
            "judgement": "The predicted edit correctly matches the ground truth's edit type as 'capitalization.' Both the predicted and ground truth edits involve changing lowercase 'if' to uppercase 'If.' Even though the ground truth includes an additional word 'he,' the core essential edit\u2014capitalizing 'if'\u2014is correctly identified. Extra context (the additional word 'he') in the original text of the ground truth does not affect the correctness, as the prediction correctly captures the intended capitalization edit."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "replacement",
            "original_text": "said",
            "corrected_text": "asked",
            "observed_line_number": 40,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The predicted edit correctly matches the edit type ('replacement') of the ground truth. It accurately captures the core textual change of the ground truth edit from 'said' to 'asked'. Although the ground truth specifically includes additional context ('Clennam'), the essential edit intended is clearly changing 'said' to 'asked'. Including or excluding surrounding words ('Clennam') does not affect the correctness, as per instructions. Thus, the prediction successfully matches both conditions: exact edit type and accurately capturing the core textual revision intended."
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_gpt_4o_2024_11_20",
        "date": "2025-04-07T00:52:03.726102",
        "annotator": "GPT-4o (2024-11-20)",
        "annotation_date": "2025-04-05T23:34:33.914579",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "if",
            "corrected_text": "If",
            "observed_line_number": 36,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The predicted edit matches the edit type ('capitalization') exactly. It accurately captures the core textual change intended by the ground truth edit, capitalizing the word 'if' to 'If'. Although the ground truth includes the phrase 'if he' and the prediction only explicitly mentions the word 'if', the essential core correction\u2014capitalizing 'if'\u2014is correctly captured. Additional contextual words before or after are not required as per the evaluation criteria. Therefore, both edit type and text content accurately reflect the ground truth intention."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "replacement",
            "original_text": "said",
            "corrected_text": "asked",
            "observed_line_number": 38,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The predicted edit type 'replacement' exactly matches the ground truth type. The predicted correction changes 'said' to 'asked', reflecting the exact edit intended by the ground truth edit ('said Clennam' \u2192 'asked Clennam'). Although the predicted version omits 'Clennam', it directly captures the essential edit 'said' \u2192 'asked'. The instructions explicitly state that the prediction may include additional context or slightly differ in scope, as long as the core textual alteration is correctly identified. Therefore, ignoring the difference in included context and completely disregarding line numbers as instructed, the prediction correctly captures the core intended textual change."
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_gpt_4o_2024_11_20",
        "date": "2025-04-07T00:52:59.947463",
        "annotator": "GPT-4o (2024-11-20)",
        "annotation_date": "2025-04-05T23:05:26.025759",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": 1,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The edit type in both ground truth and prediction is 'punctuation', matching exactly. The predicted edit changes 'high road' to 'high-road', accurately capturing the punctuation correction specified by the ground truth. Differences in page numbering are irrelevant according to evaluation guidance. Thus, the predicted edit accurately reflects the intended punctuation correction identified in the ground truth."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": 12,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The predicted edit type 'punctuation' matches exactly the ground truth edit type 'punctuation'. The text content accuracy criterion is also satisfied, as both ground truth and predicted edits correctly capture the core change from 'about and' to 'about, and'. Differences in line number and page are explicitly ignored according to the provided evaluation criteria. Therefore, the predicted edit correctly captures the intent of the ground truth edit."
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": 2,
            "tp": 0.09999999999999998,
            "fp": 0.45,
            "fn": 0.45,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": 28,
            "line_diff": 3,
            "line_number_penalty": 0.9,
            "judgement": "The predicted edit correctly matches the ground truth edit. First, the edit type \"punctuation\" exactly corresponds with the ground truth edit type. Second, the essential textual change also matches precisely: both indicate that the original text \"said\" is being corrected to \"said,\". Differences in line numbers and page identifiers have been explicitly ignored based on evaluation instructions. Thus, the edit is considered correctly captured in terms of both type and actual textual content."
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_gpt_4o_2024_11_20",
        "date": "2025-04-07T00:54:12.608006",
        "annotator": "GPT-4o (2024-11-20)",
        "annotation_date": "2025-04-05T23:35:35.056079",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": 12,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The predicted edit matches exactly the ground truth edit type ('punctuation'). The text content accuracy also matches perfectly, as both the ground truth and the prediction correctly identify and perform the essential punctuation change from 'about and' to 'about, and'. Thus, ignoring line number discrepancies as instructed, the predicted edit accurately captures the intention of the ground truth."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 0.6,
            "fp": 0.2,
            "fn": 0.2,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": 27,
            "line_diff": 2,
            "line_number_penalty": 0.4,
            "judgement": "The edit type in the prediction ('punctuation') exactly matches the ground truth edit type ('punctuation'). Additionally, the predicted text content correctly captures the core change specified by the ground truth: changing 'said' to 'said,'. Both ground truth and predicted edits have the exact same original and corrected text, directly matching the intention of the ground truth edit. Since line numbers and page numbers are explicitly ignored for this evaluation, and the essential change is faithfully captured, this prediction is correct."
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": 2,
            "tp": 0.6,
            "fp": 0.2,
            "fn": 0.2,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": 31,
            "line_diff": 2,
            "line_number_penalty": 0.4,
            "judgement": "The predicted edit matches the ground truth exactly in edit type ('punctuation') and text content ('Clennam in' corrected to 'Clennam, in'). Both the original and corrected texts align perfectly, clearly indicating the same punctuation correction was captured. Although the predicted edit references a different page and line number, such details must be ignored as per evaluation instructions. Therefore, since both edit type and textual edit accuracy are fully consistent with the ground truth, the predicted edit is correctly capturing the intended correction."
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "highroad",
            "corrected_text": "high-road",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_gpt_4o_2024_11_20",
        "date": "2025-04-07T00:54:58.993404",
        "annotator": "GPT-4o (2024-11-20)",
        "annotation_date": "2025-04-05T23:06:19.009644",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "punctuation",
            "original_text": "Sun and Shadow,",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": 1,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The predicted edit's type 'punctuation' exactly matches the ground truth edit type. Regarding text content accuracy, the essential punctuation edit is identical ('Sun and Shadow' changed to 'Sun and Shadow.'). The only additional detail provided in the predicted edit ('Sun and Shadow,') indicates the original punctuation differently from the ground truth (comma versus missing punctuation). However, the core intended correction that the punctuation should become a period is correctly captured. As per instructions, inclusion of additional context or slight difference in original punctuation does not negatively affect correctness so long as the primary intended edit (changing or adding correct punctuation) is precisely captured. Thus, the predicted edit meets the stated criteria for correctness."
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_gpt_4o_2024_11_20",
        "date": "2025-04-07T00:55:33.389431",
        "annotator": "GPT-4o (2024-11-20)",
        "annotation_date": "2025-04-05T23:36:22.187010",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow,",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_gpt_4o_2024_11_20",
        "date": "2025-04-07T00:55:52.609819",
        "annotator": "GPT-4o (2024-11-20)",
        "annotation_date": "2025-04-05T23:07:15.999081",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Chalons",
            "corrected_text": "Ch\u00e2lons",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "sodden with",
            "corrected_text": "soddened with",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_gpt_4o_2024_11_20",
        "date": "2025-04-07T00:56:15.617845",
        "annotator": "GPT-4o (2024-11-20)",
        "annotation_date": "2025-04-05T23:37:21.892320",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "Chalons",
            "corrected_text": "Ch\u00e2lons",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "sodden with",
            "corrected_text": "soddened with",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  },
  {
    "model_name": "GPT-4o-mini",
    "model_id": "or_gpt_4o_mini",
    "date": "2025-04-07T01:03:05.234839",
    "shots": 2,
    "config": {
      "model_id": "or_gpt_4o_mini",
      "display_name": "GPT-4o-mini",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-05",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "GPT-4o-mini",
    "annotation_date": "2025-04-05T22:47:33.233484",
    "file_results": [
      {
        "model_name": "or_gpt_4o_mini",
        "date": "2025-04-07T00:57:02.240536",
        "annotator": "GPT-4o-mini",
        "annotation_date": "2025-04-05T22:47:33.233484",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day.",
            "corrected_text": "to-day.",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day.",
            "corrected_text": "to-day.",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day.",
            "corrected_text": "to-day.",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day.",
            "corrected_text": "to-day.",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "yonder to-day, Sir,",
            "corrected_text": "yonder to-day, sir,",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_gpt_4o_mini",
        "date": "2025-04-07T00:57:25.231778",
        "annotator": "GPT-4o-mini",
        "annotation_date": "2025-04-05T23:17:40.163311",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "over yonder,",
            "corrected_text": "over yonder",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day, Sir,",
            "corrected_text": "to-day, sir,",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "is none.",
            "corrected_text": "is none.",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "happy other",
            "corrected_text": "happy otherwise.",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "Marseilles,",
            "corrected_text": "Marseilles.",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "and marshong",
            "corrected_text": "and marshong,",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day!",
            "corrected_text": "to-day.",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day!",
            "corrected_text": "to-day.",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "in for?",
            "corrected_text": "in for?",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_gpt_4o_mini",
        "date": "2025-04-07T00:57:47.622523",
        "annotator": "GPT-4o-mini",
        "annotation_date": "2025-04-05T22:48:35.431131",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "my child",
            "corrected_text": "my child.",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "the cold stones",
            "corrected_text": "the cold stones?",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "I tell you something, sir",
            "corrected_text": "I tell you something, sir?",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "little dorrit",
            "corrected_text": "Little Dorrit",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_gpt_4o_mini",
        "date": "2025-04-07T00:58:27.853443",
        "annotator": "GPT-4o-mini",
        "annotation_date": "2025-04-05T23:18:42.466040",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "my poor child",
            "corrected_text": "my poor child,",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "the warmth",
            "corrected_text": "the warmth;",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "why did he dine",
            "corrected_text": "why did he dine to",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to tell you something, sir",
            "corrected_text": "to tell you something, sir?",
            "observed_line_number": 39,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "the cold stones",
            "corrected_text": "the cold stones?",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_gpt_4o_mini",
        "date": "2025-04-07T00:59:02.657927",
        "annotator": "GPT-4o-mini",
        "annotation_date": "2025-04-05T22:49:35.543145",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.6,
            "fp": 0.2,
            "fn": 0.2,
            "type": "capitalization",
            "original_text": "if",
            "corrected_text": "If",
            "observed_line_number": 38,
            "line_diff": 2,
            "line_number_penalty": 0.4,
            "judgement": "The predicted edit correctly identifies the edit type as 'capitalization', matching exactly with the ground truth. The textual content in the predicted edit ('if' \u2192 'If') also accurately captures the core intended correction, which is the capitalization of the word 'if'. Although the ground truth includes the additional word 'he' ('if he' \u2192 'If he'), the essential correction is the capitalization of 'if', which the predicted edit correctly captures. Since additional context or words are permissible and the predicted edit accurately represents the fundamental change ('if' \u2192 'If'), the predicted edit is considered correct."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "said Clennam.",
            "corrected_text": "said Clennam?",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_gpt_4o_mini",
        "date": "2025-04-07T00:59:37.376260",
        "annotator": "GPT-4o-mini",
        "annotation_date": "2025-04-05T23:19:44.453781",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "said",
            "corrected_text": "said",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "if",
            "corrected_text": "If",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_gpt_4o_mini",
        "date": "2025-04-07T01:00:14.910341",
        "annotator": "GPT-4o-mini",
        "annotation_date": "2025-04-05T22:50:34.931115",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "punctuation",
            "original_text": "said (comma)",
            "corrected_text": "said,",
            "observed_line_number": 22,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The edit type matches exactly ('punctuation'). The essential punctuation fix from 'said when' to 'said, when' is accurately captured in the predicted edit, even though the prediction describes the corrected punctuation differently ('said (comma)' \u2192 'said,'). Ignoring line numbers and page references as instructed, the core textual change\u2014adding the comma after 'said'\u2014matches the ground truth intention precisely."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "high-road",
            "corrected_text": "high road",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_gpt_4o_mini",
        "date": "2025-04-07T01:00:35.346430",
        "annotator": "GPT-4o-mini",
        "annotation_date": "2025-04-05T23:20:44.775548",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "high-road",
            "corrected_text": "high road",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "said (comma)",
            "corrected_text": "said,",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "Clennam, in",
            "corrected_text": "Clennam in",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_gpt_4o_mini",
        "date": "2025-04-07T01:01:08.305619",
        "annotator": "GPT-4o-mini",
        "annotation_date": "2025-04-05T22:51:36.009333",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow,",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_gpt_4o_mini",
        "date": "2025-04-07T01:01:49.938929",
        "annotator": "GPT-4o-mini",
        "annotation_date": "2025-04-05T23:21:47.361103",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "punctuation",
            "original_text": "Sun and Shadow,",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": 1,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The edit type ('punctuation') matches exactly between the ground truth and prediction. The core intended modification ('Sun and Shadow' \u2192 'Sun and Shadow.') is accurately captured by the predicted edit, even though the predicted original text includes a comma that was not present in the ground truth original text. The essential edit\u2014adding or correcting punctuation to result in a period\u2014is correctly recognized and matches the ground truth's intention. Thus, both edit type and essential text correction align fully."
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_gpt_4o_mini",
        "date": "2025-04-07T01:02:28.085550",
        "annotator": "GPT-4o-mini",
        "annotation_date": "2025-04-05T22:52:38.177563",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "autumn",
            "corrected_text": "Autumn",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Saone.",
            "corrected_text": "Sa\u00f4ne.",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "hyphen",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "darkness,",
            "corrected_text": "darkness;",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "soddened",
            "corrected_text": "sodden",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_gpt_4o_mini",
        "date": "2025-04-07T01:03:05.234839",
        "annotator": "GPT-4o-mini",
        "annotation_date": "2025-04-05T23:22:47.371059",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "A",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "hyphen",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "soddened",
            "corrected_text": "sodden",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  },
  {
    "model_name": "Gemini 2.5 Pro Preview 3/25",
    "model_id": "or_gemini_2_5_pro_preview_03_25",
    "date": "2025-04-07T00:30:47.193219",
    "shots": 2,
    "config": {
      "model_id": "or_gemini_2_5_pro_preview_03_25",
      "display_name": "Gemini 2.5 Pro Preview 3/25",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-06",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "Gemini 2.5 Pro Preview 3/25",
    "annotation_date": "2025-04-05T02:58:21.966873",
    "file_results": [
      {
        "model_name": "or_gemini_2_5_pro_preview_03_25",
        "date": "2025-04-07T00:25:08.324864",
        "annotator": "Gemini 2.5 Pro Preview 3/25",
        "annotation_date": "2025-04-05T02:58:21.966873",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "down a",
            "corrected_text": "down, a",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sea and",
            "corrected_text": "sea, and",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "shore the",
            "corrected_text": "shore, the",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "city and",
            "corrected_text": "city, and",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "country rose",
            "corrected_text": "country, rose",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 17,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 18,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 19,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 20,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 21,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 22,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 23,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 24,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 25,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 26,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 27,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 28,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 29,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 30,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 31,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 32,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 33,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 34,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 35,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 36,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 37,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 38,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 39,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 39,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 40,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 41,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 42,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 42,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 43,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 43,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 44,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 44,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 45,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 45,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 46,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "rose,",
            "corrected_text": "rose, like",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_gemini_2_5_pro_preview_03_25",
        "date": "2025-04-07T00:25:29.578691",
        "annotator": "Gemini 2.5 Pro Preview 3/25",
        "annotation_date": "2025-04-06T02:16:35.200806",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "flies the",
            "corrected_text": "flies, the",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stung Left",
            "corrected_text": "stung! Left",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "creaked",
            "corrected_text": "creaked--",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Nan Nan",
            "corrected_text": "Nan! Nan",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Nan",
            "corrected_text": "Nan!",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "knew",
            "corrected_text": "knew.",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "claw",
            "corrected_text": "claw--",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "paw",
            "corrected_text": "paw!",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "\"Got it\"",
            "corrected_text": "\"Got it!\"",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "\"Got it!\" said",
            "corrected_text": "\"Got it!,\" said",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "monkey",
            "corrected_text": "monkey.",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "\"Got it\"",
            "corrected_text": "\"Got it!\"",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "\"Got it!\" said",
            "corrected_text": "\"Got it!,\" said",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Nan",
            "corrected_text": "Nan.",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "went zzzzzzzzzzzz",
            "corrected_text": "went--zzzzzzzzzzzz",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "zzzzzzzzzzzz",
            "corrected_text": "zzzzzzzzzzzz.",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "For",
            "corrected_text": "For--",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 17,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "parrot",
            "corrected_text": "parrot?",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 18,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "\"Kok-kok-kok-kok\" says",
            "corrected_text": "\"Kok-kok-kok-kok,\" says",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 19,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "parrot",
            "corrected_text": "parrot.",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 20,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "\"Pretty Poll Pretty Poll\"",
            "corrected_text": "\"Pretty Poll, Pretty Poll\"",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 21,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "\"Pretty Poll, Pretty Poll\" says",
            "corrected_text": "\"Pretty Poll, Pretty Poll,\" says",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 22,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "parrot",
            "corrected_text": "parrot.",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 23,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "thinking",
            "corrected_text": "thinking--",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 24,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "\"Pretty Poll Pretty Poll\"",
            "corrected_text": "\"Pretty Poll, Pretty Poll\"",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 25,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "\"Pretty Poll, Pretty Poll\" says",
            "corrected_text": "\"Pretty Poll, Pretty Poll,\" says",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 26,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "parrot",
            "corrected_text": "parrot.",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 27,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "thinking",
            "corrected_text": "thinking--",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 28,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "\"Pretty Poll Pretty Poll\"",
            "corrected_text": "\"Pretty Poll, Pretty Poll\"",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 29,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "\"Pretty Poll, Pretty Poll\" says",
            "corrected_text": "\"Pretty Poll, Pretty Poll,\" says",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 30,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "parrot",
            "corrected_text": "parrot.",
            "observed_line_number": 39,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 31,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "thinking",
            "corrected_text": "thinking--",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 32,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "\"Pretty Poll Pretty Poll\"",
            "corrected_text": "\"Pretty Poll, Pretty Poll\"",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 33,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "\"Pretty Poll, Pretty Poll\" says",
            "corrected_text": "\"Pretty Poll, Pretty Poll,\" says",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 34,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "parrot",
            "corrected_text": "parrot.",
            "observed_line_number": 42,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 35,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "thinking",
            "corrected_text": "thinking--",
            "observed_line_number": 43,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 36,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "\"Pretty Poll Pretty Poll\"",
            "corrected_text": "\"Pretty Poll, Pretty Poll\"",
            "observed_line_number": 44,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 37,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "\"Pretty Poll, Pretty Poll\" says",
            "corrected_text": "\"Pretty Poll, Pretty Poll,\" says",
            "observed_line_number": 44,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 38,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "parrot",
            "corrected_text": "parrot.",
            "observed_line_number": 45,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 39,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "thinking",
            "corrected_text": "thinking--",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 40,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "\"Pretty Poll Pretty Poll\"",
            "corrected_text": "\"Pretty Poll, Pretty Poll\"",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 41,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "\"Pretty Poll, Pretty Poll\" says",
            "corrected_text": "\"Pretty Poll, Pretty Poll,\" says",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 42,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "parrot",
            "corrected_text": "parrot.",
            "observed_line_number": 48,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 43,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "thinking",
            "corrected_text": "thinking--",
            "observed_line_number": 49,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_gemini_2_5_pro_preview_03_25",
        "date": "2025-04-07T00:25:51.492440",
        "annotator": "Gemini 2.5 Pro Preview 3/25",
        "annotation_date": "2025-04-05T03:00:44.648599",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 17,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 18,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 19,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 20,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 21,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 22,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 23,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 24,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 25,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 26,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 27,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 28,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 29,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 30,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 31,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 32,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 33,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 34,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 35,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 36,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 37,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 38,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 39,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 40,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 41,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 42,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 43,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 44,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 45,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 46,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 47,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 48,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 49,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 50,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 51,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 52,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 53,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 54,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 55,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 56,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 57,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 58,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 59,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 60,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 61,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 62,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 63,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 64,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 65,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 66,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 67,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 68,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 69,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 70,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 71,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 72,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 73,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 74,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 75,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 76,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 39,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 77,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 39,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 78,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 79,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 80,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 81,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 82,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 42,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 83,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 42,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 84,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 43,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 85,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 43,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 86,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 44,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 87,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 44,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 88,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 45,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 89,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 45,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 90,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 91,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 92,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 93,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_gemini_2_5_pro_preview_03_25",
        "date": "2025-04-07T00:26:13.218942",
        "annotator": "Gemini 2.5 Pro Preview 3/25",
        "annotation_date": "2025-04-06T02:05:20.372326",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "themselves and",
            "corrected_text": "themselves, and",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun and",
            "corrected_text": "sun, and",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "dust and",
            "corrected_text": "dust, and",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "smells and",
            "corrected_text": "smells, and",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "bells and",
            "corrected_text": "bells, and",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "beggars and",
            "corrected_text": "beggars, and",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "dogs and",
            "corrected_text": "dogs, and",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "posting bills",
            "corrected_text": "posting-bills",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "bills and",
            "corrected_text": "bills, and",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "fountains and",
            "corrected_text": "fountains, and",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "shops and",
            "corrected_text": "shops, and",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "houses and",
            "corrected_text": "houses, and",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "churches and",
            "corrected_text": "churches, and",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "monasteries and",
            "corrected_text": "monasteries, and",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prisons and",
            "corrected_text": "prisons, and",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "fortifications and",
            "corrected_text": "fortifications, and",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "streets and",
            "corrected_text": "streets, and",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 17,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "lanes and",
            "corrected_text": "lanes, and",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 18,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "barracks and",
            "corrected_text": "barracks, and",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 19,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alleys and",
            "corrected_text": "alleys, and",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 20,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "courts and",
            "corrected_text": "courts, and",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 21,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "passages and",
            "corrected_text": "passages, and",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 22,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "gateways and",
            "corrected_text": "gateways, and",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 23,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "archways and",
            "corrected_text": "archways, and",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 24,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "tumble down",
            "corrected_text": "tumble-down",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 25,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "hovels and",
            "corrected_text": "hovels, and",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 26,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "palaces and",
            "corrected_text": "palaces, and",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 27,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "wine shops",
            "corrected_text": "wine-shops",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 28,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "shops and",
            "corrected_text": "shops, and",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 29,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "fruit shops",
            "corrected_text": "fruit-shops",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 30,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "shops and",
            "corrected_text": "shops, and",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 31,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "tailors shops",
            "corrected_text": "tailors' shops",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 32,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "tailors' shops",
            "corrected_text": "tailors'-shops",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 33,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "shops and",
            "corrected_text": "shops, and",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 34,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "barbers shops",
            "corrected_text": "barbers' shops",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 35,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "barbers' shops",
            "corrected_text": "barbers'-shops",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 36,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "shops and",
            "corrected_text": "shops, and",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 37,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "coffee shops",
            "corrected_text": "coffee-shops",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 38,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "shops and",
            "corrected_text": "shops, and",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 39,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "coopers shops",
            "corrected_text": "coopers' shops",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 40,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "coopers' shops",
            "corrected_text": "coopers'-shops",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 41,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "shops and",
            "corrected_text": "shops, and",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 42,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "smiths shops",
            "corrected_text": "smiths' shops",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 43,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "smiths' shops",
            "corrected_text": "smiths'-shops",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 44,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "shops and",
            "corrected_text": "shops, and",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 45,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "wheelwrights shops",
            "corrected_text": "wheelwrights' shops",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 46,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "wheelwrights' shops",
            "corrected_text": "wheelwrights'-shops",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 47,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "shops and",
            "corrected_text": "shops, and",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 48,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "picture shops",
            "corrected_text": "picture-shops",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 49,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "shops and",
            "corrected_text": "shops, and",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 50,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "dumps and",
            "corrected_text": "dumps, and",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 51,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "refuse and",
            "corrected_text": "refuse, and",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 52,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "garden and",
            "corrected_text": "garden, and",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 53,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "pits and",
            "corrected_text": "pits, and",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 54,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water and",
            "corrected_text": "water, and",
            "observed_line_number": 39,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 55,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "cooking pots",
            "corrected_text": "cooking-pots",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 56,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "pots and",
            "corrected_text": "pots, and",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 57,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "braziers and",
            "corrected_text": "braziers, and",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 58,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "ashes and",
            "corrected_text": "ashes, and",
            "observed_line_number": 42,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 59,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "carts and",
            "corrected_text": "carts, and",
            "observed_line_number": 43,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 60,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "tumbrils and",
            "corrected_text": "tumbrils, and",
            "observed_line_number": 44,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 61,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "wheels and",
            "corrected_text": "wheels, and",
            "observed_line_number": 45,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 62,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "jumbled",
            "corrected_text": "",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 63,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "together",
            "corrected_text": "together,",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 64,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_gemini_2_5_pro_preview_03_25",
        "date": "2025-04-07T00:26:37.053713",
        "annotator": "Gemini 2.5 Pro Preview 3/25",
        "annotation_date": "2025-04-06T02:18:32.697578",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 17,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 18,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 19,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 20,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 21,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 22,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 23,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 24,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 25,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 26,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 27,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 28,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 29,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 30,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 31,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 32,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 33,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 34,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 35,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 36,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 37,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 38,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 39,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 40,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 41,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 42,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 43,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 44,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 45,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 46,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 47,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 48,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 43,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 49,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 43,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 50,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 44,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 51,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 44,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 52,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 53,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 54,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 55,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_gemini_2_5_pro_preview_03_25",
        "date": "2025-04-07T00:27:01.543998",
        "annotator": "Gemini 2.5 Pro Preview 3/25",
        "annotation_date": "2025-04-05T03:02:57.533229",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison and",
            "corrected_text": "prison, and",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison dress",
            "corrected_text": "prison-dress",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "dress and",
            "corrected_text": "dress, and",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison air",
            "corrected_text": "prison-air",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "air and",
            "corrected_text": "air, and",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison food",
            "corrected_text": "prison-food",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "food were",
            "corrected_text": "food, were",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun light",
            "corrected_text": "sun-light",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "light and",
            "corrected_text": "light, and",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "air and",
            "corrected_text": "air, and",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "food were",
            "corrected_text": "food, were",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 17,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 18,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 19,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 20,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 21,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 22,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 23,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 24,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 25,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 26,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 27,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 28,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 29,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 30,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 31,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 32,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 33,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 34,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 35,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 36,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 37,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 38,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 39,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 40,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 41,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 42,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 39,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 43,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 44,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 45,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 42,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 46,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 43,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 47,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 44,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 48,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 45,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 49,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "man who",
            "corrected_text": "man, who",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 50,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison was",
            "corrected_text": "prison, was",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_gemini_2_5_pro_preview_03_25",
        "date": "2025-04-07T00:27:23.142770",
        "annotator": "Gemini 2.5 Pro Preview 3/25",
        "annotation_date": "2025-04-06T02:06:48.185197",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sea and",
            "corrected_text": "sea, and",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "shore and",
            "corrected_text": "shore, and",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "ships and",
            "corrected_text": "ships, and",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "harbour and",
            "corrected_text": "harbour, and",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "forts and",
            "corrected_text": "forts, and",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "churches and",
            "corrected_text": "churches, and",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "buildings rising",
            "corrected_text": "buildings, rising",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "another among",
            "corrected_text": "another, among",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "gardens monasteries",
            "corrected_text": "gardens, monasteries",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "villas fathomed",
            "corrected_text": "villas, fathomed",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "depths were",
            "corrected_text": "depths, were",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun and",
            "corrected_text": "sun, and",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sky and",
            "corrected_text": "sky, and",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "everything was",
            "corrected_text": "everything, was",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Marseilles in",
            "corrected_text": "Marseilles, in",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "heat was",
            "corrected_text": "heat, was",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "blazing was",
            "corrected_text": "blazing, was",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 17,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "dusty was",
            "corrected_text": "dusty, was",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 18,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "dirty was",
            "corrected_text": "dirty, was",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 19,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stifling was",
            "corrected_text": "stifling, was",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 20,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "dry was",
            "corrected_text": "dry, was",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 21,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "airless was",
            "corrected_text": "airless, was",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 22,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "pestilential was",
            "corrected_text": "pestilential, was",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 23,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "hot was",
            "corrected_text": "hot, was",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 24,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Marseilles in",
            "corrected_text": "Marseilles, in",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 25,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun was",
            "corrected_text": "sun, was",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 26,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "glare was",
            "corrected_text": "glare, was",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 27,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "noise was",
            "corrected_text": "noise, was",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 28,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "wickedness was",
            "corrected_text": "wickedness, was",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 29,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stench was",
            "corrected_text": "stench, was",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 30,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "confusion was",
            "corrected_text": "confusion, was",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 31,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "cruelty was",
            "corrected_text": "cruelty, was",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 32,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Marseilles under",
            "corrected_text": "Marseilles, under",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 33,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun sending",
            "corrected_text": "sun, sending",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 34,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "rays blazing",
            "corrected_text": "rays, blazing",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 35,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "rays scorching",
            "corrected_text": "rays, scorching",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 36,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "rays piercing",
            "corrected_text": "rays, piercing",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 37,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "rays splitting",
            "corrected_text": "rays, splitting",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 38,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "rays striking",
            "corrected_text": "rays, striking",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 39,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "rays flashing",
            "corrected_text": "rays, flashing",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 40,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "rays blinding",
            "corrected_text": "rays, blinding",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 41,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "rays maddening",
            "corrected_text": "rays, maddening",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 42,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "rays into",
            "corrected_text": "rays, into",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 43,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "eyes and",
            "corrected_text": "eyes, and",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 44,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "brains of",
            "corrected_text": "brains, of",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 45,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "men and",
            "corrected_text": "men, and",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 46,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "women who",
            "corrected_text": "women, who",
            "observed_line_number": 39,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 47,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "were dredged",
            "corrected_text": "were, dredged",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 48,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "up to",
            "corrected_text": "up, to",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 49,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Marseilles with",
            "corrected_text": "Marseilles, with",
            "observed_line_number": 42,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 50,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "its, own",
            "corrected_text": "its, Own",
            "observed_line_number": 43,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 51,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "dirt, and",
            "corrected_text": "Dirt, and",
            "observed_line_number": 44,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 52,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "heat, and",
            "corrected_text": "Heat, and",
            "observed_line_number": 45,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 53,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "smell, and",
            "corrected_text": "Smell, and",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 54,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "poverty, and",
            "corrected_text": "Poverty, and",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 55,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "ignorance, and",
            "corrected_text": "Ignorance, and",
            "observed_line_number": 48,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 56,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "vice, and",
            "corrected_text": "Vice, and",
            "observed_line_number": 49,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_gemini_2_5_pro_preview_03_25",
        "date": "2025-04-07T00:27:46.739831",
        "annotator": "Gemini 2.5 Pro Preview 3/25",
        "annotation_date": "2025-04-06T02:19:11.369253",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "hotel",
            "corrected_text": "hotel,",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "people",
            "corrected_text": "people,",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "cab",
            "corrected_text": "cab,",
            "observed_line_number": 49,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_gemini_2_5_pro_preview_03_25",
        "date": "2025-04-07T00:28:07.626891",
        "annotator": "Gemini 2.5 Pro Preview 3/25",
        "annotation_date": "2025-04-05T03:05:37.466107",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 17,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 18,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 19,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 20,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 21,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 22,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 23,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 24,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 25,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 26,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 27,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 28,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 29,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 30,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 31,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 32,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 33,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 34,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 35,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 36,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 37,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 38,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 39,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 40,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 41,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 42,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 43,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 44,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 45,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 46,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 47,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 48,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 49,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 50,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 51,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 52,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 53,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 54,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 55,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 56,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 57,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 58,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 59,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 60,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 61,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 62,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 63,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 64,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 65,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 66,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 67,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 68,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 69,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 70,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 71,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 72,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 73,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 74,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 75,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 76,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 39,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 77,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 39,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 78,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 79,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 80,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 81,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 82,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 42,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 83,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 42,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 84,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 43,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 85,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 43,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 86,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 44,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 87,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 44,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 88,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 45,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 89,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 45,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 90,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 91,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 92,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "alight",
            "corrected_text": "a-light",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 93,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-light and",
            "corrected_text": "a-light, and",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_gemini_2_5_pro_preview_03_25",
        "date": "2025-04-07T00:28:31.700066",
        "annotator": "Gemini 2.5 Pro Preview 3/25",
        "annotation_date": "2025-04-06T02:08:36.163419",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun and",
            "corrected_text": "sun, and",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sea and",
            "corrected_text": "sea, and",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "river and",
            "corrected_text": "river, and",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "river shone",
            "corrected_text": "river, shone",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Marseilles lying",
            "corrected_text": "Marseilles, lying",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "heat was",
            "corrected_text": "heat, was",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 17,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 18,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 19,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 20,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 21,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 22,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 23,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 24,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 25,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 26,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 27,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 28,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 29,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 30,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 31,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 32,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 33,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 34,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 35,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 36,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 37,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 38,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 39,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 40,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 41,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 39,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 42,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 43,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 44,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 42,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 45,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 43,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 46,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 44,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 47,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 45,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 48,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 49,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water was",
            "corrected_text": "water, was",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_gemini_2_5_pro_preview_03_25",
        "date": "2025-04-07T00:28:55.239007",
        "annotator": "Gemini 2.5 Pro Preview 3/25",
        "annotation_date": "2025-04-05T03:07:37.322571",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "face who",
            "corrected_text": "face, who",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 17,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 18,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 19,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 20,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 21,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 22,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 23,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 24,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 25,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 26,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 27,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 28,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 29,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 30,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 31,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 32,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 33,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 34,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 35,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 36,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 37,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 38,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 39,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 39,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 40,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 41,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 42,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 42,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 43,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 43,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 44,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 44,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 45,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 45,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 46,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 47,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him and",
            "corrected_text": "him, and",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_gemini_2_5_pro_preview_03_25",
        "date": "2025-04-07T00:29:16.644085",
        "annotator": "Gemini 2.5 Pro Preview 3/25",
        "annotation_date": "2025-04-06T02:09:22.287838",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison keeper",
            "corrected_text": "prison-keeper",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "galleries internal",
            "corrected_text": "galleries; internal",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Now there",
            "corrected_text": "Now, there",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "bolts and",
            "corrected_text": "bolts; and",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "grating",
            "corrected_text": "grating:",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "bars",
            "corrected_text": "bars;",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "mud bespattered",
            "corrected_text": "mud-bespattered",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "court yard",
            "corrected_text": "court-yard",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stone",
            "corrected_text": "stone;",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_gemini_2_5_pro_preview_03_25",
        "date": "2025-04-07T00:29:39.245924",
        "annotator": "Gemini 2.5 Pro Preview 3/25",
        "annotation_date": "2025-04-06T02:21:50.111364",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "like flaming",
            "corrected_text": "like a flaming",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "gems. Saint",
            "corrected_text": "gems, Saint",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_gemini_2_5_pro_preview_03_25",
        "date": "2025-04-07T00:30:03.130463",
        "annotator": "Gemini 2.5 Pro Preview 3/25",
        "annotation_date": "2025-04-05T03:09:06.993283",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "the sun and",
            "corrected_text": "the sun, and",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "the sea and",
            "corrected_text": "the sea, and",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "the city and",
            "corrected_text": "the city, and",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "the free air in",
            "corrected_text": "the free air, in",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Marseilles on",
            "corrected_text": "Marseilles, on",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "september",
            "corrected_text": "September",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "September the",
            "corrected_text": "September, the",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sunburnt",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 17,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 18,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 19,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 20,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 21,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 22,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 23,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 24,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 25,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 26,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 27,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 28,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 29,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 30,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 31,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 32,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 33,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 34,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 35,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 36,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 37,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 38,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 39,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 39,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 40,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 41,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 42,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 42,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 43,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 43,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 44,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 44,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 45,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 45,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 46,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 47,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_gemini_2_5_pro_preview_03_25",
        "date": "2025-04-07T00:30:23.892867",
        "annotator": "Gemini 2.5 Pro Preview 3/25",
        "annotation_date": "2025-04-06T02:11:33.755877",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a bed",
            "corrected_text": "a-bed",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a-bed and",
            "corrected_text": "a-bed, and",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun dial",
            "corrected_text": "sun-dial",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun-dial and",
            "corrected_text": "sun-dial, and",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "church tower",
            "corrected_text": "church-tower",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "church-tower and",
            "corrected_text": "church-tower, and",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison wall",
            "corrected_text": "prison-wall",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison-wall and",
            "corrected_text": "prison-wall, and",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "clock face",
            "corrected_text": "clock-face",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "clock-face and",
            "corrected_text": "clock-face, and",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "weather cock",
            "corrected_text": "weather-cock",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "weather-cock and",
            "corrected_text": "weather-cock, and",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "court yard",
            "corrected_text": "court-yard",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "court-yard and",
            "corrected_text": "court-yard, and",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stable yard",
            "corrected_text": "stable-yard",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stable-yard and",
            "corrected_text": "stable-yard, and",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "market place",
            "corrected_text": "market-place",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 17,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "market-place and",
            "corrected_text": "market-place, and",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 18,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "guard house",
            "corrected_text": "guard-house",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 19,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "guard-house and",
            "corrected_text": "guard-house, and",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 20,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison gate",
            "corrected_text": "prison-gate",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 21,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison-gate and",
            "corrected_text": "prison-gate, and",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 22,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison window",
            "corrected_text": "prison-window",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 23,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison-window and",
            "corrected_text": "prison-window, and",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 24,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison governor",
            "corrected_text": "prison-governor",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 25,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison-governor and",
            "corrected_text": "prison-governor, and",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 26,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison doctor",
            "corrected_text": "prison-doctor",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 27,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison-doctor and",
            "corrected_text": "prison-doctor, and",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 28,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison chaplain",
            "corrected_text": "prison-chaplain",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 29,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison-chaplain in",
            "corrected_text": "prison-chaplain, in",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 30,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "turnkey,",
            "corrected_text": "",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 31,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "jailer,",
            "corrected_text": "",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 32,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "prisoner,",
            "corrected_text": "",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 33,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "watch dog",
            "corrected_text": "watch-dog",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 34,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "watch-dog and",
            "corrected_text": "watch-dog, and",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 35,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison visitor",
            "corrected_text": "prison-visitor",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 36,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison-visitor in",
            "corrected_text": "prison-visitor, in",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 37,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison matron",
            "corrected_text": "prison-matron",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 38,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison-matron and",
            "corrected_text": "prison-matron, and",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 39,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison cook",
            "corrected_text": "prison-cook",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 40,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison-cook and",
            "corrected_text": "prison-cook, and",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 41,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison cat",
            "corrected_text": "prison-cat",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 42,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison-cat and",
            "corrected_text": "prison-cat, and",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 43,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison mouse",
            "corrected_text": "prison-mouse",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 44,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "prison-mouse were",
            "corrected_text": "prison-mouse, were",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 45,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun burnt",
            "corrected_text": "sun-burnt",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 46,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun-burnt and",
            "corrected_text": "sun-burnt, and",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 47,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "dust covered",
            "corrected_text": "dust-covered",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 48,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "dust-covered and",
            "corrected_text": "dust-covered, and",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 49,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "mud stained",
            "corrected_text": "mud-stained",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 50,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "mud-stained and",
            "corrected_text": "mud-stained, and",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 51,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "foot sore",
            "corrected_text": "foot-sore",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 52,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "foot-sore and",
            "corrected_text": "foot-sore, and",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 53,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "travel tired",
            "corrected_text": "travel-tired",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 54,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "travel-tired and",
            "corrected_text": "travel-tired, and",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 55,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "dog tired",
            "corrected_text": "dog-tired",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 56,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "dog-tired and",
            "corrected_text": "dog-tired, and",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 57,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "heat oppressed",
            "corrected_text": "heat-oppressed",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 58,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "heat-oppressed and",
            "corrected_text": "heat-oppressed, and",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 59,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "plague smitten",
            "corrected_text": "plague-smitten",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 60,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "plague-smitten and",
            "corrected_text": "plague-smitten, and",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 61,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "fever stricken",
            "corrected_text": "fever-stricken",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 62,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "fever-stricken were",
            "corrected_text": "fever-stricken, were",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 63,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "alike,",
            "corrected_text": "",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 64,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 65,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Marseilles in",
            "corrected_text": "Marseilles, in",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 66,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "july",
            "corrected_text": "July",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 67,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "July",
            "corrected_text": "July.",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 68,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "sun",
            "corrected_text": "Sun",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 69,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Sun and",
            "corrected_text": "Sun, and",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 70,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "moon",
            "corrected_text": "Moon",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 71,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Moon and",
            "corrected_text": "Moon, and",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 72,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "stars",
            "corrected_text": "Stars",
            "observed_line_number": 39,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 73,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Stars and",
            "corrected_text": "Stars, and",
            "observed_line_number": 39,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 74,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "sky",
            "corrected_text": "Sky",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 75,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Sky and",
            "corrected_text": "Sky, and",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 76,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "earth",
            "corrected_text": "Earth",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 77,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Earth and",
            "corrected_text": "Earth, and",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 78,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "sea",
            "corrected_text": "Sea",
            "observed_line_number": 42,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 79,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Sea and",
            "corrected_text": "Sea, and",
            "observed_line_number": 42,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 80,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "river",
            "corrected_text": "River",
            "observed_line_number": 43,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 81,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "River were",
            "corrected_text": "River, were",
            "observed_line_number": 43,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 82,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "forgotten,",
            "corrected_text": "",
            "observed_line_number": 44,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 83,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "or were touched by the universal stare. The blazing heat.",
            "corrected_text": "",
            "observed_line_number": 45,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 84,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "The ",
            "corrected_text": "The blazing heat ",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_gemini_2_5_pro_preview_03_25",
        "date": "2025-04-07T00:30:47.193219",
        "annotator": "Gemini 2.5 Pro Preview 3/25",
        "annotation_date": "2025-04-06T02:23:29.156283",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun blinds",
            "corrected_text": "sun-blinds",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "blinds and",
            "corrected_text": "blinds, and",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "windows and",
            "corrected_text": "windows, and",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "doors were",
            "corrected_text": "doors, were",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "closed against",
            "corrected_text": "closed, against",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "heat of",
            "corrected_text": "heat, of",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "noon the",
            "corrected_text": "noon; the",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "town where",
            "corrected_text": "town, where",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "streets were",
            "corrected_text": "streets, were",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "shadow was",
            "corrected_text": "shadow, was",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "white hot",
            "corrected_text": "white, hot",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "glare a",
            "corrected_text": "glare; a",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "blinding oppression",
            "corrected_text": "blinding, oppression",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "air and",
            "corrected_text": "air, and",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sky and",
            "corrected_text": "sky, and",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sea oppressed",
            "corrected_text": "sea, oppressed",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "town too",
            "corrected_text": "town, too",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 17,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "oppressed under",
            "corrected_text": "oppressed, under",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 18,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "blaze Gallantly",
            "corrected_text": "blaze; Gallantly",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 19,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "struggling against",
            "corrected_text": "struggling, against",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 20,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "it the",
            "corrected_text": "it, the",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 21,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "bells from",
            "corrected_text": "bells, from",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 22,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "church towers",
            "corrected_text": "church-towers",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 23,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "towers attended",
            "corrected_text": "towers, attended",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 24,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "services were",
            "corrected_text": "services, were",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 25,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "jingle jingle",
            "corrected_text": "jingle, jingle",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 26,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "jingle through",
            "corrected_text": "jingle, through",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 27,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "air and",
            "corrected_text": "air, and",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 28,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "made the",
            "corrected_text": "made, the",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 29,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stiller by",
            "corrected_text": "stiller, by",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 30,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "contrast A",
            "corrected_text": "contrast; A",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 31,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "mule cart",
            "corrected_text": "mule-cart",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 32,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "cart maybe",
            "corrected_text": "cart, maybe",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 33,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "rattled on",
            "corrected_text": "rattled, on",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 34,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stones Some",
            "corrected_text": "stones; Some",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 35,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "eating house",
            "corrected_text": "eating-house",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 36,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "house keeper",
            "corrected_text": "house, keeper",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 37,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "doorway mumbled",
            "corrected_text": "doorway, mumbled",
            "observed_line_number": 32,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 38,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "drowsily in",
            "corrected_text": "drowsily, in",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 39,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "shade of",
            "corrected_text": "shade, of",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 40,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "awning or",
            "corrected_text": "awning; or",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 41,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "fountain nearby",
            "corrected_text": "fountain, nearby",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 42,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "tinkled as",
            "corrected_text": "tinkled, as",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 43,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "water dripped",
            "corrected_text": "water, dripped",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 44,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "basin All",
            "corrected_text": "basin; All",
            "observed_line_number": 39,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 45,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sounds were",
            "corrected_text": "sounds, were",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 46,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "oppressed by",
            "corrected_text": "oppressed, by",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 47,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "heat that",
            "corrected_text": "heat, that",
            "observed_line_number": 42,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 48,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "shimmered everywhere",
            "corrected_text": "shimmered, everywhere",
            "observed_line_number": 43,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 49,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "blaze Nothing",
            "corrected_text": "blaze; Nothing",
            "observed_line_number": 44,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 50,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stirred in",
            "corrected_text": "stirred, in",
            "observed_line_number": 45,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 51,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "streets save",
            "corrected_text": "streets; save",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 52,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "lizards darting",
            "corrected_text": "lizards, darting",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 53,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "walls save",
            "corrected_text": "walls; save",
            "observed_line_number": 48,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 54,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "flies settling",
            "corrected_text": "flies, settling",
            "observed_line_number": 49,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 55,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "mules save",
            "corrected_text": "mules; save",
            "observed_line_number": 50,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 56,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "dogs finding",
            "corrected_text": "dogs, finding",
            "observed_line_number": 51,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 57,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "shade as",
            "corrected_text": "shade, as",
            "observed_line_number": 52,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  },
  {
    "model_name": "Gemma 3 27B",
    "model_id": "or_gemma_3_27b_it",
    "date": "2025-04-07T00:33:47.311996",
    "shots": 2,
    "config": {
      "model_id": "google/gemma-3-27b-it",
      "display_name": "Gemma 3 27B",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-05",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "Gemma 3 27B",
    "annotation_date": "2025-04-05T02:59:22.800455",
    "file_results": [
      {
        "model_name": "or_gemma_3_27b_it",
        "date": "2025-04-07T00:31:33.122629",
        "annotator": "Gemma 3 27B",
        "annotation_date": "2025-04-05T02:59:22.800455",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "punctuation",
            "original_text": "o more of yesterday's howling over yonder to-day is there",
            "corrected_text": "o more of yesterday's howling over yonder, to-day, &c; is there?",
            "observed_line_number": 2,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The predicted edit correctly identifies the edit type as 'punctuation', matching exactly with the ground truth. Regarding text content, the essential punctuation change ('howling over' changed to 'howling, over') is accurately included within the predicted correction ('o more of yesterday's howling over yonder, to-day, &c; is there?'). Although the prediction provides additional context and introduces more punctuation marks and slight variations, the crucial comma insertion after 'howling' is explicitly captured. Thus, both the edit type and the core textual edit intended by the ground truth are correctly represented in the predicted edit."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": 17,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The predicted edit type exactly matches the ground truth edit type ('punctuation'), and the text content accurately captures the exact essential change from 'pockets and' to 'pockets, and'. Both type accuracy and text content accuracy criteria are fully satisfied."
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "wise",
            "corrected_text": "wise.",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "something victory",
            "corrected_text": "something\u2014victory",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "business instead",
            "corrected_text": "business, instead",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_gemma_3_27b_it",
        "date": "2025-04-07T00:32:20.274394",
        "annotator": "Gemma 3 27B",
        "annotation_date": "2025-04-05T03:00:31.590799",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "much accus-",
            "corrected_text": "much accustomed",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "in his discovery",
            "corrected_text": "in his discovery,",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "a lock-maker which",
            "corrected_text": "a lock-maker; which",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "years more",
            "corrected_text": "years more.",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "cumlocution Office,",
            "corrected_text": "cumlocution Office",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stillstalk",
            "corrected_text": "stillstalk-",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "whom",
            "corrected_text": "whom he",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_gemma_3_27b_it",
        "date": "2025-04-07T00:33:04.271591",
        "annotator": "Gemma 3 27B",
        "annotation_date": "2025-04-05T03:00:59.634360",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "eyes",
            "corrected_text": "eyes and",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "to",
            "corrected_text": "her to",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "",
            "corrected_text": "(comma)",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_gemma_3_27b_it",
        "date": "2025-04-07T00:33:26.867047",
        "annotator": "Gemma 3 27B",
        "annotation_date": "2025-04-05T03:01:25.310496",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Period here",
            "corrected_text": "Period here?",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "marseilles",
            "corrected_text": "Marseilles",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_gemma_3_27b_it",
        "date": "2025-04-07T00:33:47.311996",
        "annotator": "Gemma 3 27B",
        "annotation_date": "2025-04-05T03:01:53.897081",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Sa\u00f4ne hyphen",
            "corrected_text": "Sa\u00f4ne-hyphen",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "man slowly moving",
            "corrected_text": "slowly moving",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "with with wet",
            "corrected_text": "with wet",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  },
  {
    "model_name": "Google: Gemini 2.0 Flash",
    "model_id": "or_gemini_2_0_flash_001",
    "date": "2025-04-07T00:24:49.075230",
    "shots": 2,
    "config": {
      "model_id": "or_gemini_2_0_flash_001",
      "display_name": "Google: Gemini 2.0 Flash",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-05",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "Google: Gemini 2.0 Flash",
    "annotation_date": "2025-04-05T11:43:31.871161",
    "file_results": [
      {
        "model_name": "or_gemini_2_0_flash_001",
        "date": "2025-04-07T00:22:40.458479",
        "annotator": "Google: Gemini 2.0 Flash",
        "annotation_date": "2025-04-05T11:43:31.871161",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day sir",
            "corrected_text": "to-day, sir",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_gemini_2_0_flash_001",
        "date": "2025-04-07T00:23:03.457683",
        "annotator": "Google: Gemini 2.0 Flash",
        "annotation_date": "2025-04-05T11:43:59.618252",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "cap",
            "corrected_text": "CAP",
            "observed_line_number": 63,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "she",
            "corrected_text": "she?",
            "observed_line_number": 65,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_gemini_2_0_flash_001",
        "date": "2025-04-07T00:23:23.845858",
        "annotator": "Google: Gemini 2.0 Flash",
        "annotation_date": "2025-04-05T11:44:26.352096",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "if",
            "corrected_text": "If",
            "observed_line_number": 72,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "said",
            "corrected_text": "asked",
            "observed_line_number": 74,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_gemini_2_0_flash_001",
        "date": "2025-04-07T00:23:46.886673",
        "annotator": "Google: Gemini 2.0 Flash",
        "annotation_date": "2025-04-05T11:44:53.640722",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_gemini_2_0_flash_001",
        "date": "2025-04-07T00:24:08.077774",
        "annotator": "Google: Gemini 2.0 Flash",
        "annotation_date": "2025-04-05T11:45:20.795453",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "SHADOW",
            "corrected_text": "SHADOW,",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_gemini_2_0_flash_001",
        "date": "2025-04-07T00:24:49.075230",
        "annotator": "Google: Gemini 2.0 Flash",
        "annotation_date": "2025-04-05T11:45:46.705234",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  },
  {
    "model_name": "Grok 2 Vision 1212",
    "model_id": "or_grok_2_vision_1212",
    "date": "2025-04-07T01:05:23.400351",
    "shots": 2,
    "config": {
      "model_id": "grok_2_vision_1212",
      "display_name": "Grok 2 Vision 1212",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-06",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "Grok 2 Vision 1212",
    "annotation_date": "2025-04-06T09:01:53.473904",
    "file_results": [
      {
        "model_name": "or_grok_2_vision_1212",
        "date": "2025-04-07T01:03:26.466666",
        "annotator": "Grok 2 Vision 1212",
        "annotation_date": "2025-04-06T09:01:53.473904",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "Chapter II",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "FELLOW TRAVELLERS",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "*",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "No",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "more of yesterday's howling over yonder to-day Sir there",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "They",
            "corrected_text": "",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "they",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "may be sure there is none. When these people howl,",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "they howl to be heard.",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "\u201cAll",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "but these people are always howling. Never happy otherwise.",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "\u201cDo",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "you mean the Marseilles people?",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "\u201cI",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "mean the French people. They're always at it. To Marseilles,",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "from",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "Marseilles,",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 17,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "everywhere. It's the national howl. I couldn't settle into",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 18,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "and",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 19,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "amongst",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 20,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "them.",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 21,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "The",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 22,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "speaker, with a whimsical good humour upon him all the time,",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 23,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "locked over the parapet-wall with the greatest disparagement of Marseilles,",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 24,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "and taking up a determined position by putting his hands in",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 25,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "his",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 26,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "pockets,",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 27,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "and",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 28,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "rattling his money as it, apostrophized it with his short",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 29,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "laugh.",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 30,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "\u201cAlong",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 31,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "and",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 32,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "marabout, indeed. It would be more credible to you,",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 33,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "I",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 34,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "think, to let all along, and mumbling about their lawful",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 35,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "occasions. They're",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 36,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "a",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 37,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "rum lot.\u201d",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 38,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "\u201cTiresome",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 39,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "enough,\u201d said the other. \u201cBut we shall be out o' day -",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 40,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "or",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 41,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "to-day, to-day, repeated the first. \u201cIt's not an aggravation of the",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 42,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "for",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_grok_2_vision_1212",
        "date": "2025-04-07T01:03:48.927084",
        "annotator": "Grok 2 Vision 1212",
        "annotation_date": "2025-04-06T09:02:35.527684",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "the",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "the",
            "corrected_text": "",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "he",
            "corrected_text": "she",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "story",
            "corrected_text": "story.",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "the",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "the",
            "corrected_text": "",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "he",
            "corrected_text": "she",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "story",
            "corrected_text": "story.",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "the",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "the",
            "corrected_text": "",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "he",
            "corrected_text": "she",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "story",
            "corrected_text": "story.",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_grok_2_vision_1212",
        "date": "2025-04-07T01:04:38.175691",
        "annotator": "Grok 2 Vision 1212",
        "annotation_date": "2025-04-06T09:08:28.291258",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.09999999999999998,
            "fp": 0.45,
            "fn": 0.45,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": 26,
            "line_diff": 3,
            "line_number_penalty": 0.9,
            "judgement": "The predicted edit matches the ground truth in both edit type ('punctuation') and core textual intention. The ground truth corrects 'said when' to 'said, when', specifically adding a comma after the word 'said'. The predicted edit similarly captures this essential punctuation correction ('said' to 'said,'). Although the original text context slightly differs in length ('said when' versus just 'said'), the prediction accurately identifies the primary punctuation edit the ground truth intended. Hence, it successfully represents the core editorial intention."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 0.09999999999999998,
            "fp": 0.45,
            "fn": 0.45,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": 28,
            "line_diff": 3,
            "line_number_penalty": 0.9,
            "judgement": "The predicted edit correctly matches the ground truth on both criteria. Firstly, the edit type ('punctuation') is exactly the same. Secondly, the text content change ('said' \u2192 'said,') is also exactly captured in the prediction. The discrepancy in page numbers or line numbers was explicitly marked as irrelevant. Therefore, since the edit type and the essential text content change align exactly, the prediction is correct."
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "High-Flight",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "High-Flight",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "means",
            "corrected_text": "means.",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Torquay",
            "corrected_text": "Torquay\"",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Torquay",
            "corrected_text": "\"Torquay",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "say",
            "corrected_text": "say?",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "What",
            "corrected_text": "\"What",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "say",
            "corrected_text": "say\"",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "home",
            "corrected_text": "home.",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Torquay",
            "corrected_text": "\"Torquay",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Torquay",
            "corrected_text": "Torquay\"",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Torquay",
            "corrected_text": "\"Torquay",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Torquay",
            "corrected_text": "Torquay\"",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Bentille",
            "corrected_text": "Bentille\"",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Bentille",
            "corrected_text": "\"Bentille",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 17,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_grok_2_vision_1212",
        "date": "2025-04-07T01:04:59.965793",
        "annotator": "Grok 2 Vision 1212",
        "annotation_date": "2025-04-06T09:08:54.998952",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "Sun and Shadow, ",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "Marseilles",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_grok_2_vision_1212",
        "date": "2025-04-07T01:05:23.400351",
        "annotator": "Grok 2 Vision 1212",
        "annotation_date": "2025-04-06T09:09:37.967252",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "A",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "s",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "and",
            "corrected_text": "",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "long",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "depressing",
            "corrected_text": "",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "wearying",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "only",
            "corrected_text": "",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "sole",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "clouds",
            "corrected_text": "",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "mysterious",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "gathering",
            "corrected_text": "",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "darkening",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "were",
            "corrected_text": "",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "was",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "disturbed",
            "corrected_text": "",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "troubled",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "shell",
            "corrected_text": "shell;",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 17,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "you",
            "corrected_text": "you\"",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  },
  {
    "model_name": "Llama 3.2 90B Vision Instruct",
    "model_id": "or_llama_3_2_90b_vision_instruct",
    "date": "2025-04-07T01:10:34.935675",
    "shots": 2,
    "config": {
      "model_id": "or_llama_3_2_90b_vision_instruct",
      "display_name": "Llama 3.2 90B Vision Instruct",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-06",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "Llama 3.2 90B Vision Instruct",
    "annotation_date": "2025-04-05T20:02:16.291853",
    "file_results": [
      {
        "model_name": "or_llama_3_2_90b_vision_instruct",
        "date": "2025-04-07T01:05:44.045262",
        "annotator": "Llama 3.2 90B Vision Instruct",
        "annotation_date": "2025-04-05T20:02:16.291853",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_llama_3_2_90b_vision_instruct",
        "date": "2025-04-07T01:06:06.454481",
        "annotator": "Llama 3.2 90B Vision Instruct",
        "annotation_date": "2025-04-06T00:40:09.781762",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "I have heard none",
            "corrected_text": "I have heard none.",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "they howl to be heard",
            "corrected_text": "they howl to be heard.",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Never happy otherwise",
            "corrected_text": "Never happy otherwise.",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Do you mean the Marseilles people",
            "corrected_text": "Do you mean the Marseilles people?",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "As to Marseilles, we know what Marseilles is",
            "corrected_text": "As to Marseilles, we know what Marseilles is.",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "It couldn't exist without allonging and marshonging to something or other\u2014victory or death, or blazes, or something",
            "corrected_text": "It couldn't exist without allonging and marshonging to something or other\u2014victory or death, or blazes, or something.",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "The speaker, with a whimsical good humour upon him all the time, looked over the parapet-wall with the greatest disparagement of Marseilles; and taking up a determined position by putting his hands in his pockets, and rattling his money at it, apostrophised it with a short laugh",
            "corrected_text": "The speaker, with a whimsical good humour upon him all the time, looked over the parapet-wall with the greatest disparagement of Marseilles; and taking up a determined position by putting his hands in his pockets, and rattling his money at it, apostrophised it with a short laugh.",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Allong and marshong, indeed",
            "corrected_text": "Allong and marshong, indeed.",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "I think, to let other people allong and marshong about their lawful business, instead of shutting 'em up in quarantine",
            "corrected_text": "I think, to let other people allong and marshong about their lawful business, instead of shutting 'em up in quarantine!",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Tiresome enough",
            "corrected_text": "Tiresome enough,",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "said the other",
            "corrected_text": "said the other.",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "But we shall be out to-day",
            "corrected_text": "But we shall be out to-day.",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Out to-day",
            "corrected_text": "Out to-day!",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "repeated the first",
            "corrected_text": "repeated the first.",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "It's almost an aggravation of the enormity, that we shall be out to-day",
            "corrected_text": "It's almost an aggravation of the enormity, that we shall be out to-day.",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Out",
            "corrected_text": "Out!",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "What have we ever been in for",
            "corrected_text": "What have we ever been in for?",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_llama_3_2_90b_vision_instruct",
        "date": "2025-04-07T01:06:45.756420",
        "annotator": "Llama 3.2 90B Vision Instruct",
        "annotation_date": "2025-04-06T01:25:51.945584",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "I have heard none",
            "corrected_text": "I have heard none.",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "they howl to be heard",
            "corrected_text": "they howl to be heard.",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Never happy otherwise",
            "corrected_text": "Never happy otherwise.",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Do you mean the Marseilles people",
            "corrected_text": "Do you mean the Marseilles people?",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "As to Marseilles, we know what Marseilles is",
            "corrected_text": "As to Marseilles, we know what Marseilles is.",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "It couldn't exist without allonging and marshonging to something or other\u2014victory or death, or blazes, or something",
            "corrected_text": "It couldn't exist without allonging and marshonging to something or other\u2014victory or death, or blazes, or something.",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Allong and marshong, indeed",
            "corrected_text": "Allong and marshong, indeed.",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "I think, to let other people allong and marshong about their lawful business, instead of shutting 'em up in quarantine",
            "corrected_text": "I think, to let other people allong and marshong about their lawful business, instead of shutting 'em up in quarantine!",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Tiresome enough",
            "corrected_text": "Tiresome enough,",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "said the other",
            "corrected_text": "said the other.",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "But we shall be out to-day",
            "corrected_text": "But we shall be out to-day.",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Out to-day",
            "corrected_text": "Out to-day!",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "repeated the first",
            "corrected_text": "repeated the first.",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "It's almost an aggravation of the enormity, that we shall be out to-day",
            "corrected_text": "It's almost an aggravation of the enormity, that we shall be out to-day.",
            "observed_line_number": 35,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Out",
            "corrected_text": "Out!",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "What have we ever been in for",
            "corrected_text": "What have we ever been in for?",
            "observed_line_number": 39,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "The speaker, with a whimsical good humour upon him all the time, looked over the parapet-wall with the greatest disparagement of Marseilles; and taking up a determined position by putting his hands in his pockets, and rattling his money at it, apostrophised it with a short laugh",
            "corrected_text": "The speaker, with a whimsical good humour upon him all the time, looked over the parapet-wall with the greatest disparagement of Marseilles; and taking up a determined position by putting his hands in his pockets, and rattling his money at it, apostrophised it with a short laugh.",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_llama_3_2_90b_vision_instruct",
        "date": "2025-04-07T01:07:07.745375",
        "annotator": "Llama 3.2 90B Vision Instruct",
        "annotation_date": "2025-04-05T20:02:37.708140",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_llama_3_2_90b_vision_instruct",
        "date": "2025-04-07T01:07:27.142353",
        "annotator": "Llama 3.2 90B Vision Instruct",
        "annotation_date": "2025-04-06T01:26:08.767835",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_llama_3_2_90b_vision_instruct",
        "date": "2025-04-07T01:07:50.527110",
        "annotator": "Llama 3.2 90B Vision Instruct",
        "annotation_date": "2025-04-05T20:04:38.362814",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_llama_3_2_90b_vision_instruct",
        "date": "2025-04-07T01:08:12.325013",
        "annotator": "Llama 3.2 90B Vision Instruct",
        "annotation_date": "2025-04-06T00:51:56.757917",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "cap",
            "corrected_text": "cap",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "asked",
            "corrected_text": "asked",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_llama_3_2_90b_vision_instruct",
        "date": "2025-04-07T01:08:32.685244",
        "annotator": "Llama 3.2 90B Vision Instruct",
        "annotation_date": "2025-04-05T20:05:02.698298",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_llama_3_2_90b_vision_instruct",
        "date": "2025-04-07T01:08:55.451656",
        "annotator": "Llama 3.2 90B Vision Instruct",
        "annotation_date": "2025-04-06T00:52:18.153440",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_llama_3_2_90b_vision_instruct",
        "date": "2025-04-07T01:09:15.169742",
        "annotator": "Llama 3.2 90B Vision Instruct",
        "annotation_date": "2025-04-06T01:34:57.282696",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_llama_3_2_90b_vision_instruct",
        "date": "2025-04-07T01:09:36.453889",
        "annotator": "Llama 3.2 90B Vision Instruct",
        "annotation_date": "2025-04-05T20:06:53.021669",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_llama_3_2_90b_vision_instruct",
        "date": "2025-04-07T01:09:57.163768",
        "annotator": "Llama 3.2 90B Vision Instruct",
        "annotation_date": "2025-04-06T01:35:59.179462",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sun one",
            "corrected_text": "sun, one",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "blazing sun upon a",
            "corrected_text": "blazing sun upon",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "fierce August day was",
            "corrected_text": "fierce August day",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "no greater rarity in",
            "corrected_text": "no greater rarity",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "southern France then",
            "corrected_text": "southern France",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "than at any other",
            "corrected_text": "than at any",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "time, before or",
            "corrected_text": "time, before",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "since. Everything",
            "corrected_text": "since.",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "in Marseilles, and",
            "corrected_text": "in Marseilles",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "about Marseilles, had",
            "corrected_text": "about Marseilles",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "stared at the",
            "corrected_text": "stared at",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "fervid sky, and",
            "corrected_text": "fervid sky",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 12,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "been stared at",
            "corrected_text": "been stared",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 13,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "in return, until",
            "corrected_text": "in return",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 14,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "a staring habit",
            "corrected_text": "a staring",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 15,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "had become univer-",
            "corrected_text": "had become",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 16,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "sal there. Strangers",
            "corrected_text": "sal there.",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 17,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "were stared out",
            "corrected_text": "were stared",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 18,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "of countenance by",
            "corrected_text": "of countenance",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 19,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "staring white",
            "corrected_text": "staring white",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_llama_3_2_90b_vision_instruct",
        "date": "2025-04-07T01:10:14.502477",
        "annotator": "Llama 3.2 90B Vision Instruct",
        "annotation_date": "2025-04-05T20:07:16.381030",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_llama_3_2_90b_vision_instruct",
        "date": "2025-04-07T01:10:34.935675",
        "annotator": "Llama 3.2 90B Vision Instruct",
        "annotation_date": "2025-04-06T01:36:19.389658",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  },
  {
    "model_name": "Llama 4 Maverick",
    "model_id": "or_llama_4_maverick",
    "date": "2025-04-07T01:20:35.103109",
    "shots": 2,
    "config": {
      "model_id": "or_llama_4_maverick",
      "display_name": "Llama 4 Maverick",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-06",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "Llama 4 Maverick",
    "annotation_date": "2025-04-05T20:17:36.849612",
    "file_results": [
      {
        "model_name": "or_llama_4_maverick",
        "date": "2025-04-07T01:11:07.199327",
        "annotator": "Llama 4 Maverick",
        "annotation_date": "2025-04-05T20:17:36.849612",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": 18,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The predicted edit correctly identifies the type as 'punctuation', matching exactly with the ground truth type. The text content accuracy criterion is also satisfied; both the original and corrected text, 'pockets and' changed to 'pockets, and', are identical in the ground truth and predicted edits. Thus, the prediction fully captures the exact intent and type of the ground truth edit, regardless of discrepancies in line numbers or page identifiers, which were explicitly ignored as per instructions."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day sir",
            "corrected_text": "to-day, sir",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_llama_4_maverick",
        "date": "2025-04-07T01:11:36.966757",
        "annotator": "Llama 4 Maverick",
        "annotation_date": "2025-04-06T00:14:57.175573",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "punctuation",
            "original_text": "pockets",
            "corrected_text": "pockets,",
            "observed_line_number": 16,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The predicted edit correctly identifies the edit type as 'punctuation', matching the ground truth exactly. The fundamental punctuation correction from 'pockets' to 'pockets,' captured by the prediction accurately matches the correction described in the ground truth ('pockets and' \u2192 'pockets, and'), as the essential punctuation insertion after 'pockets' is correctly represented. Minor differences in additional context words ('and') do not affect correctness. Hence, all criteria for both edit type accuracy and core text content accuracy are fulfilled by the predicted edit."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day",
            "corrected_text": "to-day,",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "allonging",
            "corrected_text": "along",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "allong",
            "corrected_text": "along",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "allong",
            "corrected_text": "along",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day",
            "corrected_text": "to-day,",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day",
            "corrected_text": "to-day,",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day",
            "corrected_text": "to-day.",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_llama_4_maverick",
        "date": "2025-04-07T01:12:08.787996",
        "annotator": "Llama 4 Maverick",
        "annotation_date": "2025-04-06T00:25:30.261386",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sir",
            "corrected_text": "sir,",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "allonging",
            "corrected_text": "alongling",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "pockets",
            "corrected_text": "pockets,",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "allong",
            "corrected_text": "along",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "allong",
            "corrected_text": "along",
            "observed_line_number": 13,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day",
            "corrected_text": "to day",
            "observed_line_number": 15,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day",
            "corrected_text": "to day",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day",
            "corrected_text": "to day",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day",
            "corrected_text": "to day,",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_llama_4_maverick",
        "date": "2025-04-07T01:12:29.572972",
        "annotator": "Llama 4 Maverick",
        "annotation_date": "2025-04-05T20:17:56.615593",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "reordering",
            "original_text": "might blame her father",
            "corrected_text": "might blame her father, if he saw them",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "that he might think, 'why did he dine to-day",
            "corrected_text": "that he might think, why did he dine to-day",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_llama_4_maverick",
        "date": "2025-04-07T01:12:51.092189",
        "annotator": "Llama 4 Maverick",
        "annotation_date": "2025-04-06T00:15:15.735954",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "blame",
            "corrected_text": "cap",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "quotation mark",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_llama_4_maverick",
        "date": "2025-04-07T01:13:09.515613",
        "annotator": "Llama 4 Maverick",
        "annotation_date": "2025-04-06T00:25:52.521035",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "reordering",
            "original_text": "might blame her father",
            "corrected_text": "might blame her father, if he saw them",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "that he might think, 'why did he dine to-day",
            "corrected_text": "that he might think, why did he dine to-day",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_llama_4_maverick",
        "date": "2025-04-07T01:13:47.519980",
        "annotator": "Llama 4 Maverick",
        "annotation_date": "2025-04-05T20:18:20.121893",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "replacement",
            "original_text": "said",
            "corrected_text": "asked",
            "observed_line_number": 40,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The prediction accurately captures the edit type as 'replacement', matching exactly the ground truth type. The text content change from 'said Clennam' to 'asked Clennam' is correctly identified in the prediction as 'said' to 'asked'. Although the prediction includes less context ('said' versus 'said Clennam'), it still clearly captures the essential textual modification ('said' to 'asked'). According to the evaluation criterion allowing additional or lesser context if the core edit is retained, this prediction is correct."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "cap",
            "corrected_text": "Cap",
            "observed_line_number": 37,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_llama_4_maverick",
        "date": "2025-04-07T01:14:10.251973",
        "annotator": "Llama 4 Maverick",
        "annotation_date": "2025-04-06T00:15:36.723503",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "said",
            "corrected_text": "asked",
            "observed_line_number": 45,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_llama_4_maverick",
        "date": "2025-04-07T01:14:30.127330",
        "annotator": "Llama 4 Maverick",
        "annotation_date": "2025-04-06T00:26:11.084352",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "cap",
            "corrected_text": "Cap",
            "observed_line_number": 43,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "said",
            "corrected_text": "asked",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_llama_4_maverick",
        "date": "2025-04-07T01:15:06.512921",
        "annotator": "Llama 4 Maverick",
        "annotation_date": "2025-04-05T20:18:42.862789",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "about and came",
            "corrected_text": "about, and came",
            "observed_line_number": 13,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The edit type accurately matches the ground truth ('punctuation'). The ground truth edit adds a comma in the phrase 'about and' \u2192 'about, and'. The predicted edit correctly identifies the same essential punctuation correction within 'about and came' \u2192 'about, and came'. Including additional context ('came') does not negate the correctness, as the critical core edit ('about and' \u2192 'about, and') is precisely captured. Overall, both edit type and core textual content match correctly."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_llama_4_maverick",
        "date": "2025-04-07T01:16:02.788169",
        "annotator": "Llama 4 Maverick",
        "annotation_date": "2025-04-06T00:16:00.573116",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.6,
            "fp": 0.2,
            "fn": 0.2,
            "type": "punctuation",
            "original_text": "about,and",
            "corrected_text": "about, and",
            "observed_line_number": 11,
            "line_diff": 2,
            "line_number_penalty": 0.4,
            "judgement": "The predicted edit type, 'punctuation', exactly matches the ground truth edit type. Regarding text content accuracy, the core punctuation correction intended by the ground truth\u2014adding a comma after the word 'about' to yield 'about, and'\u2014is also correctly represented in the predicted edit. Even though the original text provided by the prediction ('about,and') omits the spacing present in the ground truth ('about and'), the essential punctuation correction (inserting a comma after 'about') correctly captures the editorial intention. Minor differences in spacing do not affect the essential accuracy of the intended punctuation edit."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 0.6,
            "fp": 0.2,
            "fn": 0.2,
            "type": "punctuation",
            "original_text": "and said",
            "corrected_text": "and said,",
            "observed_line_number": 23,
            "line_diff": 2,
            "line_number_penalty": 0.4,
            "judgement": "The predicted edit correctly matches the ground truth edit type ('punctuation'). Regarding text content, both the ground truth and the prediction identify the essential core correction from 'said' to 'said,'. The additional context ('and') in the predicted text does not alter or change the intended punctuation correction. Thus, since the essential punctuation change matches exactly, the prediction correctly captures the intention of the ground truth edit."
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "tioned",
            "corrected_text": "tioned,",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "always said",
            "corrected_text": "always said,",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "amazement. \"What",
            "corrected_text": "amazement. \"What do you mean?\"",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_llama_4_maverick",
        "date": "2025-04-07T01:16:57.454981",
        "annotator": "Llama 4 Maverick",
        "annotation_date": "2025-04-06T00:26:33.527014",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.6,
            "fp": 0.2,
            "fn": 0.2,
            "type": "punctuation",
            "original_text": "about,and",
            "corrected_text": "about, and",
            "observed_line_number": 11,
            "line_diff": 2,
            "line_number_penalty": 0.4,
            "judgement": "The predicted edit correctly identifies the edit type ('punctuation') which matches exactly with the ground truth. The core textual change intended by the ground truth edit ('about and' changed to 'about, and') is precisely captured by the prediction. The only discrepancy beyond line number (explicitly ignored in evaluation criteria) is the representation of the original text ('about,and') without a space between 'about' and 'and' in the prediction, as compared to the ground truth ('about and'). However, the essential punctuation insertion (adding a comma after 'about') remains the same, capturing the core intention clearly. Therefore, the edit is considered correct according to the specified evaluation criteria."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 0.6,
            "fp": 0.2,
            "fn": 0.2,
            "type": "punctuation",
            "original_text": "and said",
            "corrected_text": "and said,",
            "observed_line_number": 23,
            "line_diff": 2,
            "line_number_penalty": 0.4,
            "judgement": "The predicted edit type ('punctuation') exactly matches the ground truth edit type ('punctuation'). The core textual change captured in both the ground truth and prediction is the addition of a comma after the word 'said'. Although the prediction includes additional context ('and said' instead of just 'said'), this additional context does not change the essential punctuation edit. Therefore, the prediction correctly represents the core modification intended in the ground truth edit."
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "tioned",
            "corrected_text": "tioned,",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "always said",
            "corrected_text": "always said,",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "amazement. \"What",
            "corrected_text": "amazement. \"What do you mean?\"",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_llama_4_maverick",
        "date": "2025-04-07T01:17:15.578094",
        "annotator": "Llama 4 Maverick",
        "annotation_date": "2025-04-05T20:18:57.949312",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Chapter I",
            "corrected_text": "Chapter I.",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "SUN AND SHADOW",
            "corrected_text": "SUN AND SHADOW.",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_llama_4_maverick",
        "date": "2025-04-07T01:17:38.805438",
        "annotator": "Llama 4 Maverick",
        "annotation_date": "2025-04-06T00:16:18.434306",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Chapter I",
            "corrected_text": "Chapter I.",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_llama_4_maverick",
        "date": "2025-04-07T01:17:58.213081",
        "annotator": "Llama 4 Maverick",
        "annotation_date": "2025-04-06T00:26:54.736802",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Chapter I",
            "corrected_text": "Chapter I.",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_llama_4_maverick",
        "date": "2025-04-07T01:18:51.580962",
        "annotator": "Llama 4 Maverick",
        "annotation_date": "2025-04-05T20:19:26.341118",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "sulled",
            "corrected_text": "veiled",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "poplat trees",
            "corrected_text": "poplar-trees",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "soddenwith",
            "corrected_text": "sodden with",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_llama_4_maverick",
        "date": "2025-04-07T01:19:40.684633",
        "annotator": "Llama 4 Maverick",
        "annotation_date": "2025-04-06T00:16:40.850500",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": 1,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The predicted edit accurately matches the ground truth edit. Both specify a 'replacement' edit type, correctly changing 'Saone' to 'Sa\u00f4ne'. Textually, the core correction ('Saone' \u2192 'Sa\u00f4ne') is accurately identified, satisfying both criteria precisely. The slight discrepancy in the page identifier ('008.png' vs. 'page_137') is irrelevant based on the evaluation instructions, as only the edit type and text content accuracy are assessed."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "sodden with",
            "corrected_text": "soddenwith",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplartrees",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_llama_4_maverick",
        "date": "2025-04-07T01:20:35.103109",
        "annotator": "Llama 4 Maverick",
        "annotation_date": "2025-04-06T00:27:13.830590",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "sulled",
            "corrected_text": "veiled",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "poplat trees",
            "corrected_text": "poplar-trees",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "soddenwith",
            "corrected_text": "sodden with",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  },
  {
    "model_name": "Llama 4 Scout",
    "model_id": "or_llama_4_scout",
    "date": "2025-04-07T01:27:35.703220",
    "shots": 2,
    "config": {
      "model_id": "or_llama_4_scout",
      "display_name": "Llama 4 Scout",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-06",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "Llama 4 Scout",
    "annotation_date": "2025-04-05T20:26:38.055605",
    "file_results": [
      {
        "model_name": "or_llama_4_scout",
        "date": "2025-04-07T01:20:54.017341",
        "annotator": "Llama 4 Scout",
        "annotation_date": "2025-04-05T20:26:38.055605",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "people do, I suppose.",
            "corrected_text": "people do, I suppose",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "allong",
            "corrected_text": "all along",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Out!",
            "corrected_text": "Out",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_llama_4_scout",
        "date": "2025-04-07T01:21:14.878759",
        "annotator": "Llama 4 Scout",
        "annotation_date": "2025-04-06T00:18:03.189916",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "FELLOW TRAVELLERS.",
            "corrected_text": "FELLOW TRAVELLERS",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "his pocketsand",
            "corrected_text": "his pockets and",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "allonging",
            "corrected_text": "allonging",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "allong",
            "corrected_text": "allong",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_llama_4_scout",
        "date": "2025-04-07T01:21:45.003638",
        "annotator": "Llama 4 Scout",
        "annotation_date": "2025-04-06T00:21:40.130130",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": 16,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The predicted edit type ('punctuation') exactly matches the edit type from the ground truth ('punctuation'). Both the predicted and ground truth edits reflect the same core textual change ('pockets and' to 'pockets, and'), correctly introducing a comma after 'pockets'. Additional context does not impact correctness negatively. Thus, the prediction accurately captures the ground truth edit intention."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "allonging",
            "corrected_text": "allong and",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "allonging",
            "corrected_text": "allong and",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_llama_4_scout",
        "date": "2025-04-07T01:22:02.983657",
        "annotator": "Llama 4 Scout",
        "annotation_date": "2025-04-05T20:27:02.634200",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "cap",
            "corrected_text": "capped",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "delusions",
            "corrected_text": "delusions mask",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_llama_4_scout",
        "date": "2025-04-07T01:22:24.081207",
        "annotator": "Llama 4 Scout",
        "annotation_date": "2025-04-06T00:18:29.192305",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "cap",
            "corrected_text": "capped",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "mask",
            "corrected_text": "masks",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "say",
            "corrected_text": "say",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_llama_4_scout",
        "date": "2025-04-07T01:22:41.661900",
        "annotator": "Llama 4 Scout",
        "annotation_date": "2025-04-06T00:22:04.662047",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "little",
            "corrected_text": "Little",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "them",
            "corrected_text": "them;",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_llama_4_scout",
        "date": "2025-04-07T01:23:02.342513",
        "annotator": "Llama 4 Scout",
        "annotation_date": "2025-04-05T20:27:27.811054",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "asked",
            "corrected_text": "Asked",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "asked",
            "corrected_text": "asked?",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_llama_4_scout",
        "date": "2025-04-07T01:23:23.413539",
        "annotator": "Llama 4 Scout",
        "annotation_date": "2025-04-06T00:18:53.396182",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "that you ever turned",
            "corrected_text": "that you ever turned",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "your thoughts that way, Mr. Doyce.",
            "corrected_text": "your thoughts that way, Mr. Doyce.",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "asked",
            "corrected_text": "asked",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_llama_4_scout",
        "date": "2025-04-07T01:23:40.603834",
        "annotator": "Llama 4 Scout",
        "annotation_date": "2025-04-06T00:22:42.370264",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "asked",
            "corrected_text": "Asked",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "asked",
            "corrected_text": "Asked",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_llama_4_scout",
        "date": "2025-04-07T01:24:16.637781",
        "annotator": "Llama 4 Scout",
        "annotation_date": "2025-04-05T20:27:54.873366",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "and",
            "corrected_text": "and,",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "his room.",
            "corrected_text": "his room.",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "reordering",
            "original_text": "him not to be uneasy on her",
            "corrected_text": "him not to be uneasy on her",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "told him not",
            "corrected_text": "told him not",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "high-road",
            "corrected_text": "high-road",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_llama_4_scout",
        "date": "2025-04-07T01:25:05.500710",
        "annotator": "Llama 4 Scout",
        "annotation_date": "2025-04-06T00:19:18.052695",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "and",
            "corrected_text": "and,",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him.",
            "corrected_text": "him.",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "high-road",
            "corrected_text": "high-road",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "saidj",
            "corrected_text": "said,",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "and",
            "corrected_text": "and,",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "(comma)",
            "corrected_text": "",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_llama_4_scout",
        "date": "2025-04-07T01:25:24.853729",
        "annotator": "Llama 4 Scout",
        "annotation_date": "2025-04-06T00:23:26.352844",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "and",
            "corrected_text": "and,",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "his room",
            "corrected_text": "his room,",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "high-road",
            "corrected_text": "high road",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him.",
            "corrected_text": "him.",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him.",
            "corrected_text": "him.",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him.",
            "corrected_text": "him.",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him.",
            "corrected_text": "him.",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him.",
            "corrected_text": "him.",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him.",
            "corrected_text": "him.",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him.",
            "corrected_text": "him.",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 10,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him.",
            "corrected_text": "him.",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 11,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "him.",
            "corrected_text": "him.",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_llama_4_scout",
        "date": "2025-04-07T01:25:46.007915",
        "annotator": "Llama 4 Scout",
        "annotation_date": "2025-04-05T20:28:20.556546",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "thirty",
            "corrected_text": "Thirty",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Marseilles",
            "corrected_text": "Marseilles,",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_llama_4_scout",
        "date": "2025-04-07T01:26:04.792018",
        "annotator": "Llama 4 Scout",
        "annotation_date": "2025-04-06T00:19:43.320420",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "thirty",
            "corrected_text": "Thirty",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Marseilles",
            "corrected_text": "Marseilles,",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_llama_4_scout",
        "date": "2025-04-07T01:26:27.355559",
        "annotator": "Llama 4 Scout",
        "annotation_date": "2025-04-06T00:23:48.132133",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "thirty",
            "corrected_text": "Thirty",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Marseilles",
            "corrected_text": "Marseilles,",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_llama_4_scout",
        "date": "2025-04-07T01:26:50.539622",
        "annotator": "Llama 4 Scout",
        "annotation_date": "2025-04-05T20:28:47.960848",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "hyphen",
            "corrected_text": "",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "with",
            "corrected_text": "",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "sullenly",
            "corrected_text": "sullenly,",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "he",
            "corrected_text": "he,",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_llama_4_scout",
        "date": "2025-04-07T01:27:12.192306",
        "annotator": "Llama 4 Scout",
        "annotation_date": "2025-04-06T00:20:10.206986",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "plain",
            "corrected_text": "plain,",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "hyphen",
            "corrected_text": "hyphen",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_llama_4_scout",
        "date": "2025-04-07T01:27:35.703220",
        "annotator": "Llama 4 Scout",
        "annotation_date": "2025-04-06T00:24:18.268870",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "plain",
            "corrected_text": "plain,",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "with",
            "corrected_text": "",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "that",
            "corrected_text": "that he",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "he",
            "corrected_text": "he,",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "this",
            "corrected_text": "this,",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "you",
            "corrected_text": "you!",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  },
  {
    "model_name": "Mistral Small 3.1 24B",
    "model_id": "or_mistral_small_3_1_24b_instruct",
    "date": "2025-04-07T01:36:03.388465",
    "shots": 2,
    "config": {
      "model_id": "or_mistral_small_3_1_24b_instruct",
      "display_name": "Mistral Small 3.1 24B",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-06",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "Mistral Small 3.1 24B",
    "annotation_date": "2025-04-05T02:43:41.403706",
    "file_results": [
      {
        "model_name": "or_mistral_small_3_1_24b_instruct",
        "date": "2025-04-07T01:27:55.387604",
        "annotator": "Mistral Small 3.1 24B",
        "annotation_date": "2025-04-05T02:43:41.403706",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "why",
            "corrected_text": "Why",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to",
            "corrected_text": "to,",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stones",
            "corrected_text": "stones\"",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "question mark",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_mistral_small_3_1_24b_instruct",
        "date": "2025-04-07T01:28:17.661649",
        "annotator": "Mistral Small 3.1 24B",
        "annotation_date": "2025-04-06T01:05:38.401266",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "cold stones",
            "corrected_text": "cold stones?",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "question mark",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "why",
            "corrected_text": "Why",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_mistral_small_3_1_24b_instruct",
        "date": "2025-04-07T01:28:40.126049",
        "annotator": "Mistral Small 3.1 24B",
        "annotation_date": "2025-04-06T01:19:33.738007",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Why did he dine to",
            "corrected_text": "Why did he dine to-",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Question mark",
            "corrected_text": "Question mark",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "Cap",
            "corrected_text": "Cap",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_mistral_small_3_1_24b_instruct",
        "date": "2025-04-07T01:28:59.740291",
        "annotator": "Mistral Small 3.1 24B",
        "annotation_date": "2025-04-05T02:44:07.887190",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "said",
            "corrected_text": "called",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "said",
            "corrected_text": "asked",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_mistral_small_3_1_24b_instruct",
        "date": "2025-04-07T01:29:22.755150",
        "annotator": "Mistral Small 3.1 24B",
        "annotation_date": "2025-04-06T01:06:16.283054",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "said",
            "corrected_text": "Said",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "asked",
            "corrected_text": "Asked",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_mistral_small_3_1_24b_instruct",
        "date": "2025-04-07T01:29:42.082039",
        "annotator": "Mistral Small 3.1 24B",
        "annotation_date": "2025-04-06T01:20:20.146465",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "said Clennam",
            "corrected_text": "said Clennam.",
            "observed_line_number": 21,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "true to a certain extent",
            "corrected_text": "true to a certain extent.",
            "observed_line_number": 22,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "he must follow where it leads him",
            "corrected_text": "he must follow where it leads him.",
            "observed_line_number": 23,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam.",
            "observed_line_number": 24,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_mistral_small_3_1_24b_instruct",
        "date": "2025-04-07T01:30:44.967665",
        "annotator": "Mistral Small 3.1 24B",
        "annotation_date": "2025-04-06T01:07:54.085297",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.09999999999999998,
            "fp": 0.45,
            "fn": 0.45,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": 10,
            "line_diff": 3,
            "line_number_penalty": 0.9,
            "judgement": "The edit type matches exactly: both the ground truth and prediction categorize the edit as 'punctuation'. The text content is also accurately captured, as both explicitly correct 'about and' to 'about, and', clearly adding the comma at the same spot. Thus, ignoring line numbers as instructed, the predicted edit accurately reflects the intention of the ground truth edit."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": 28,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The predicted edit correctly matches the ground truth edit in terms of both edit type ('punctuation') and text content accuracy. The ground truth edit 'Clennam in' \u2192 'Clennam, in' is exactly replicated in the predicted edit, which captures the core punctuation change (a comma insertion after 'Clennam'). Although the line number and page differ, the evaluation explicitly instructs to ignore line numbers and page information and focus solely on the edit type and the core text content accuracy. Therefore, given that the edit type matches and the punctuation correction is exactly the same, the predicted edit correctly captures the intention of the ground truth edit."
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "association did",
            "corrected_text": "association, did",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "uneasy on",
            "corrected_text": "uneasy on",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "her behalf for",
            "corrected_text": "her behalf, for",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Clennam\u2014Tattycoram!",
            "corrected_text": "Clennam,\u2014Tattycoram!",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "five and twenty, sir;",
            "corrected_text": "five-and-twenty, sir;",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "girls passionate",
            "corrected_text": "girl's passionate",
            "observed_line_number": 38,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "highroad",
            "corrected_text": "high-road",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_mistral_small_3_1_24b_instruct",
        "date": "2025-04-07T01:31:23.807920",
        "annotator": "Mistral Small 3.1 24B",
        "annotation_date": "2025-04-05T02:45:35.517836",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": 0,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The predicted edit correctly matches the ground truth edit in both criteria. First, the edit type is correctly identified as 'punctuation' in both cases. Second, the text content accuracy is precisely matched; both the original and corrected texts ('Sun and Shadow' \u2192 'Sun and Shadow.') are identical, clearly capturing the core punctuation correction indicated by the ground truth. Although the predicted page reference ('003.png') differs from the ground truth ('007.png'), the instructions specifically state to ignore line numbers (and implicitly page references) in this evaluation. Therefore, this prediction meets both edit type and text content accuracy requirements."
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_mistral_small_3_1_24b_instruct",
        "date": "2025-04-07T01:31:59.531366",
        "annotator": "Mistral Small 3.1 24B",
        "annotation_date": "2025-04-06T01:08:17.004608",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Shadow",
            "corrected_text": "Shadow.",
            "observed_line_number": 0,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The predicted edit correctly identifies the intended punctuation edit. Both the ground truth and prediction indicate the addition of a period after the word 'Shadow'. Although the prediction provides less context ('Shadow' instead of the complete title 'Sun and Shadow'), it still accurately captures the core punctuation change. Therefore, considering the requirements\u2014exact match of edit type ('punctuation') and accurate capture of core textual edit (adding period after 'Shadow')\u2014the prediction is correct."
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_mistral_small_3_1_24b_instruct",
        "date": "2025-04-07T01:32:33.671023",
        "annotator": "Mistral Small 3.1 24B",
        "annotation_date": "2025-04-06T01:21:43.413124",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": 0,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The prediction matches the ground truth completely. The edit type ('punctuation') is identical in both cases. The text content also matches exactly, correctly capturing the insertion of the period at the end of the phrase 'Sun and Shadow'. Though the page numbering differs ('007.png' in ground truth vs. '003.png' in prediction), this criterion is not relevant to accuracy according to the given evaluation instructions, which explicitly mention to ignore line number differences for this evaluation. Therefore, both edit type and essential textual change are correctly captured, leading to a correct evaluation."
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_mistral_small_3_1_24b_instruct",
        "date": "2025-04-07T01:33:45.140990",
        "annotator": "Mistral Small 3.1 24B",
        "annotation_date": "2025-04-05T02:46:23.927284",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": 1,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The predicted edit type matches exactly ('replacement'). Additionally, the text content targeted by both ground truth and prediction is identical ('Saone' corrected to 'Sa\u00f4ne'). The prediction fully captures the intended textual correction. Although the predicted page differs ('003.png' instead of '008.png'), the evaluation criteria explicitly instructs to ignore line numbers (and implicitly suggests ignoring page numbers), thus ensuring the page number discrepancy does not affect the evaluation. Therefore, the prediction accurately captures both the edit type and the essential textual change intended by the ground truth."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 0.09999999999999998,
            "fp": 0.45,
            "fn": 0.45,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": 4,
            "line_diff": 3,
            "line_number_penalty": 0.9,
            "judgement": "The predicted edit accurately matches the ground truth edit type ('replacement'). It correctly captures the intended textual correction from 'Saone' to 'Sa\u00f4ne'. Although the predicted edit differs from the ground truth in terms of page and line number, these differences have been explicitly ignored per evaluation criteria. Therefore, since the edit type and the actual textual correction ('Saone' \u2192 'Sa\u00f4ne') are correctly identified, the prediction is correct."
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "late, dull autumn night was closing in upon the river Saone",
            "corrected_text": "late, dull autumn night",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Chalons, was the only visible",
            "corrected_text": "Chalons",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "Chalons",
            "corrected_text": "Chalons",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "ed",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_mistral_small_3_1_24b_instruct",
        "date": "2025-04-07T01:34:47.166385",
        "annotator": "Mistral Small 3.1 24B",
        "annotation_date": "2025-04-06T01:08:49.821862",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": 1,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The predicted edit matches exactly the edit type specified in the ground truth ('replacement'). The text change from 'Saone' to 'Sa\u00f4ne' is correctly captured by the prediction. The difference in the 'page' field ('008.png' vs '003.png') is irrelevant according to the evaluation criteria specified, as only the edit type and the text content accuracy were to be considered. Thus, the prediction is considered correct."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": 1,
            "tp": 0.09999999999999998,
            "fp": 0.45,
            "fn": 0.45,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": 4,
            "line_diff": 3,
            "line_number_penalty": 0.9,
            "judgement": "The predicted edit type matches exactly ('replacement'). The original text ('Saone') and corrected text ('Sa\u00f4ne') are accurately captured and match the ground truth edit exactly. Line numbers and pages are intentionally ignored in this evaluation, so the differences in those fields do not affect correctness. Therefore, both criteria (edit type and text content) are fully satisfied."
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "late, dull autumn night was",
            "corrected_text": "late, dull autumn night",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Chalons,",
            "corrected_text": "Chalons",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "cloak he carried over",
            "corrected_text": "cloak he carried",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sodden with wet;",
            "corrected_text": "sodden with wet",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_mistral_small_3_1_24b_instruct",
        "date": "2025-04-07T01:36:03.388465",
        "annotator": "Mistral Small 3.1 24B",
        "annotation_date": "2025-04-06T01:22:14.071983",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "river Saone",
            "corrected_text": "river Sa\u00f4ne",
            "observed_line_number": 1,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The edit type matches exactly: both ground truth and prediction indicate 'replacement'. The essential text correction from 'Saone' to 'Sa\u00f4ne' is also accurately captured. Although the prediction includes extra context ('river'), this is acceptable according to the evaluation criteria since the core edit ('Saone' to 'Sa\u00f4ne') remains correctly identified. Therefore, both criteria (edit type accuracy and text content accuracy) are fulfilled."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Chalons, was",
            "corrected_text": "Chalons was",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "sodden with wet",
            "corrected_text": "sodden with wet",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "late dull autumn night",
            "corrected_text": "late, dull autumn night",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar trees",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  },
  {
    "model_name": "Phi 4 Multimodal Instruct",
    "model_id": "or_phi_4_multimodal_instruct",
    "date": "2025-04-07T01:40:36.604240",
    "shots": 2,
    "config": {
      "model_id": "or_phi_4_multimodal_instruct",
      "display_name": "Phi 4 Multimodal Instruct",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-06",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "Phi 4 Multimodal Instruct",
    "annotation_date": "2025-04-05T19:59:07.615828",
    "file_results": [
      {
        "model_name": "or_phi_4_multimodal_instruct",
        "date": "2025-04-07T01:36:28.008368",
        "annotator": "Phi 4 Multimodal Instruct",
        "annotation_date": "2025-04-05T19:59:07.615828",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_phi_4_multimodal_instruct",
        "date": "2025-04-07T01:36:48.683092",
        "annotator": "Phi 4 Multimodal Instruct",
        "annotation_date": "2025-04-06T01:28:00.606731",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_phi_4_multimodal_instruct",
        "date": "2025-04-07T01:37:07.277024",
        "annotator": "Phi 4 Multimodal Instruct",
        "annotation_date": "2025-04-06T01:42:58.075595",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_phi_4_multimodal_instruct",
        "date": "2025-04-07T01:37:29.080453",
        "annotator": "Phi 4 Multimodal Instruct",
        "annotation_date": "2025-04-05T20:00:12.647593",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "church bells",
            "corrected_text": "church bells,",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "wine bottles",
            "corrected_text": "wine-bottles",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "got through",
            "corrected_text": "got, through",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "iron bars fashioned",
            "corrected_text": "iron bars, fashioned",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "grating where",
            "corrected_text": "grating, where",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "outside and",
            "corrected_text": "outside; and",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "intact in",
            "corrected_text": "intact, in",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "indian ocean",
            "corrected_text": "Indian Ocean",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "bars that",
            "corrected_text": "bars, that",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_phi_4_multimodal_instruct",
        "date": "2025-04-07T01:37:48.349896",
        "annotator": "Phi 4 Multimodal Instruct",
        "annotation_date": "2025-04-06T01:28:35.535554",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "church bells",
            "corrected_text": "church bells,",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "wine bottles",
            "corrected_text": "wine-bottles",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "got through",
            "corrected_text": "got, through",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "iron bars fashioned",
            "corrected_text": "iron bars, fashioned",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "grating where",
            "corrected_text": "grating, where",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "outside and",
            "corrected_text": "outside; and",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "intact in",
            "corrected_text": "intact, in",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "indian ocean",
            "corrected_text": "Indian Ocean",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "bars that",
            "corrected_text": "bars, that",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_phi_4_multimodal_instruct",
        "date": "2025-04-07T01:38:10.753010",
        "annotator": "Phi 4 Multimodal Instruct",
        "annotation_date": "2025-04-05T20:00:36.340363",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "asked",
            "corrected_text": "asked",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_phi_4_multimodal_instruct",
        "date": "2025-04-07T01:38:32.694005",
        "annotator": "Phi 4 Multimodal Instruct",
        "annotation_date": "2025-04-06T01:28:57.249189",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "asked",
            "corrected_text": "asked",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_phi_4_multimodal_instruct",
        "date": "2025-04-07T01:38:52.500419",
        "annotator": "Phi 4 Multimodal Instruct",
        "annotation_date": "2025-04-06T01:47:41.146821",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "asked",
            "corrected_text": "asked",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_phi_4_multimodal_instruct",
        "date": "2025-04-07T01:39:14.524931",
        "annotator": "Phi 4 Multimodal Instruct",
        "annotation_date": "2025-04-05T20:07:23.965639",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "church bells",
            "corrected_text": "church bells,",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "wine bottles",
            "corrected_text": "wine-bottles",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "got through",
            "corrected_text": "got, through",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "iron bars fashioned",
            "corrected_text": "iron bars, fashioned",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "grating where",
            "corrected_text": "grating, where",
            "observed_line_number": 17,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "outside and",
            "corrected_text": "outside; and",
            "observed_line_number": 29,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "intact in",
            "corrected_text": "intact, in",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "was waiting to be fed looking",
            "corrected_text": "was waiting to be fed; looking",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "bars that",
            "corrected_text": "bars, that",
            "observed_line_number": 36,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_phi_4_multimodal_instruct",
        "date": "2025-04-07T01:39:33.400572",
        "annotator": "Phi 4 Multimodal Instruct",
        "annotation_date": "2025-04-06T01:34:55.211318",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Marseilles lay burning in the sun, one day.",
            "corrected_text": "Marseilles lay burning in the sun, one day.",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "A blazing sun upon a fierce August day was no greater rarity in southern France then,",
            "corrected_text": "A blazing sun upon a fierce August day was no greater rarity in southern France then,",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Everything in Marseilles, and about Marseilles, had stared at the fiery sky,",
            "corrected_text": "Everything in Marseilles, and about Marseilles, had stared at the fiery sky,",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "and been stared at in return, until a staring habit had become universal there.",
            "corrected_text": "and been stared at in return, until a staring habit had become universal there.",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Strangers were stared out of counter-",
            "corrected_text": "Strangers were stared out of counter-",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "counter-stance by staring white-",
            "corrected_text": "counter-stance by staring white-",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "white-",
            "corrected_text": "white-",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_phi_4_multimodal_instruct",
        "date": "2025-04-07T01:39:56.120035",
        "annotator": "Phi 4 Multimodal Instruct",
        "annotation_date": "2025-04-06T01:52:37.712108",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_phi_4_multimodal_instruct",
        "date": "2025-04-07T01:40:18.450434",
        "annotator": "Phi 4 Multimodal Instruct",
        "annotation_date": "2025-04-05T20:08:09.116958",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_phi_4_multimodal_instruct",
        "date": "2025-04-07T01:40:36.604240",
        "annotator": "Phi 4 Multimodal Instruct",
        "annotation_date": "2025-04-06T01:35:32.265130",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  },
  {
    "model_name": "Qwen VL Max",
    "model_id": "or_qwen_vl_max",
    "date": "2025-04-07T01:56:21.112043",
    "shots": 2,
    "config": {
      "model_id": "or_qwen_vl_max",
      "display_name": "Qwen VL Max",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-06",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "Qwen VL Max",
    "annotation_date": "2025-04-05T02:45:19.409062",
    "file_results": [
      {
        "model_name": "or_qwen_vl_max",
        "date": "2025-04-07T01:47:22.346385",
        "annotator": "Qwen VL Max",
        "annotation_date": "2025-04-05T02:45:19.409062",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.9,
            "fp": 0.04999999999999999,
            "fn": 0.04999999999999999,
            "type": "punctuation",
            "original_text": "over yonder to-day",
            "corrected_text": "over yonder, to-day",
            "observed_line_number": 2,
            "line_diff": 1,
            "line_number_penalty": 0.1,
            "judgement": "The predicted edit type exactly matches the ground truth ('punctuation'). The original text in the ground truth ('yonder to-day') is correctly represented in the prediction, though with added context ('over yonder to-day'). The predicted edit ('yonder' \u2192 'yonder,') precisely matches the ground truth's intention ('yonder' \u2192 'yonder,'). Additional words before the corrected text ('over') do not alter the essential edit itself, meeting the requirement for text content accuracy. Hence, both criteria (edit type accuracy and essential edit accuracy) are satisfied."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Sir; is there?",
            "corrected_text": "Sir; is there?",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day",
            "corrected_text": "to-day!",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day",
            "corrected_text": "to-day!",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_qwen_vl_max",
        "date": "2025-04-07T01:47:40.932618",
        "annotator": "Qwen VL Max",
        "annotation_date": "2025-04-06T00:45:06.007106",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day",
            "corrected_text": "to-day,",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "sir",
            "corrected_text": "Sir",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day",
            "corrected_text": "to-day.",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day",
            "corrected_text": "to-day!",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_qwen_vl_max",
        "date": "2025-04-07T01:48:18.107309",
        "annotator": "Qwen VL Max",
        "annotation_date": "2025-04-06T00:48:52.221200",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "sir",
            "corrected_text": "Sir",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day",
            "corrected_text": "to-day?",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "to-day",
            "corrected_text": "to-day,",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_qwen_vl_max",
        "date": "2025-04-07T01:48:39.646478",
        "annotator": "Qwen VL Max",
        "annotation_date": "2025-04-05T02:45:49.494641",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "why did he dine",
            "corrected_text": "why did he dine",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "CAP",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "exaggeration",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "mask",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_qwen_vl_max",
        "date": "2025-04-07T01:48:59.010847",
        "annotator": "Qwen VL Max",
        "annotation_date": "2025-04-06T00:45:33.250394",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "why did he dine",
            "corrected_text": "why did he dine",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "examination mark",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_qwen_vl_max",
        "date": "2025-04-07T01:49:20.565409",
        "annotator": "Qwen VL Max",
        "annotation_date": "2025-04-06T00:49:16.600004",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "Why did he dine to-day, and leave this little creature to the mercy of the cold stones?",
            "corrected_text": "Why did he dine to-day, and leave this little creature to the mercy of the cold stones?",
            "observed_line_number": 25,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "It was a part of her father\u2019s misfortunes that they did.",
            "corrected_text": "It was a part of her father\u2019s misfortunes that they did.",
            "observed_line_number": 26,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_qwen_vl_max",
        "date": "2025-04-07T01:49:43.065898",
        "annotator": "Qwen VL Max",
        "annotation_date": "2025-04-05T02:46:12.026375",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "if he",
            "corrected_text": "if he car",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "if he car",
            "corrected_text": "if he",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "said Clennam.",
            "corrected_text": "asked Clennam.",
            "observed_line_number": 41,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_qwen_vl_max",
        "date": "2025-04-07T01:50:11.435704",
        "annotator": "Qwen VL Max",
        "annotation_date": "2025-04-06T00:45:59.584257",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.6,
            "fp": 0.2,
            "fn": 0.2,
            "type": "replacement",
            "original_text": "said Clennam.",
            "corrected_text": "asked Clennam.",
            "observed_line_number": 41,
            "line_diff": 2,
            "line_number_penalty": 0.4,
            "judgement": "The predicted edit matches exactly with the ground truth in terms of edit type ('replacement'), correctly identifying the replacement from 'said Clennam' to 'asked Clennam'. The presence of a period at the end of the predicted text ('said Clennam.' \u2192 'asked Clennam.') does not change the core meaning or the precise intention of the correction noted by the ground truth. Since additional punctuation or context beyond the primary change is allowed, the prediction accurately captures the essential textual edit intended by the ground truth."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "if",
            "corrected_text": "if he",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "if he",
            "observed_line_number": 40,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_qwen_vl_max",
        "date": "2025-04-07T01:50:33.748724",
        "annotator": "Qwen VL Max",
        "annotation_date": "2025-04-06T00:49:44.588489",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "if he",
            "corrected_text": "if he car",
            "observed_line_number": 46,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "he must follow where it leads him.",
            "corrected_text": "",
            "observed_line_number": 47,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "asked",
            "observed_line_number": 48,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_qwen_vl_max",
        "date": "2025-04-07T01:51:22.723875",
        "annotator": "Qwen VL Max",
        "annotation_date": "2025-04-05T02:46:39.336530",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "high-road",
            "corrected_text": "high-road",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "and",
            "corrected_text": "and,",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": 20,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_qwen_vl_max",
        "date": "2025-04-07T01:52:03.187419",
        "annotator": "Qwen VL Max",
        "annotation_date": "2025-04-06T00:46:25.266271",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.6,
            "fp": 0.2,
            "fn": 0.2,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": 25,
            "line_diff": 2,
            "line_number_penalty": 0.4,
            "judgement": "The predicted edit correctly matches the ground truth edit in terms of edit type ('punctuation') and content accuracy. Both the ground truth and prediction involve adding a comma after the word 'said'. The prediction ('said' \u2192 'said,') accurately captures the core essence of the ground truth edit ('said when' \u2192 'said, when'), even though it omits the following context word. Since the instructions allow extra or fewer context words as long as the essential edit is accurately captured, this prediction is considered correct."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "high-road",
            "corrected_text": "high-road",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "and",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_qwen_vl_max",
        "date": "2025-04-07T01:53:16.038412",
        "annotator": "Qwen VL Max",
        "annotation_date": "2025-04-06T00:50:13.544268",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.09999999999999998,
            "fp": 0.45,
            "fn": 0.45,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": 20,
            "line_diff": 3,
            "line_number_penalty": 0.9,
            "judgement": "The predicted edit has the correct type ('punctuation'), matching the ground truth. The core edit identified by the ground truth is adding a comma after the word 'said', changing 'said when' to 'said, when'. The prediction correctly captures this punctuation insertion\u2014adding a comma after 'said.' Even though the prediction provides less context ('said' \u2192 'said,') compared to the ground truth ('said when' \u2192 'said, when'), the critical essence of the change (addition of a comma after 'said') is accurately captured. Therefore, both edit type and text content align with the ground truth's intended correction."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "high-road",
            "corrected_text": "high-road",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "costing",
            "corrected_text": "costing",
            "observed_line_number": 1,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "and",
            "corrected_text": "and,",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_qwen_vl_max",
        "date": "2025-04-07T01:53:58.140765",
        "annotator": "Qwen VL Max",
        "annotation_date": "2025-04-05T02:47:07.462861",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": 0,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The predicted edit type ('punctuation') exactly matches the ground truth edit type. Additionally, the predicted text change ('Sun and Shadow' \u2192 'Sun and Shadow.') precisely mirrors the ground truth correction. Although the 'page' information differs ('Chapter 1' instead of '007.png'), the evaluation criteria explicitly exclude line numbers and do not mention 'page' accuracy as a condition. Consequently, the edit type and textual content change are exactly correct according to the provided criteria, making the prediction correct."
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_qwen_vl_max",
        "date": "2025-04-07T01:54:38.816838",
        "annotator": "Qwen VL Max",
        "annotation_date": "2025-04-06T00:46:51.292542",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": 0,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The predicted edit type 'punctuation' matches exactly with the ground truth edit type ('punctuation'). The original text ('Sun and Shadow') and the corrected text ('Sun and Shadow.') also match explicitly, capturing precisely the punctuation insertion intended by the ground truth edit. While the predicted edit references 'Chapter 1' instead of '007.png', the instructions specify only to evaluate edit type and text accuracy, explicitly ignoring line numbers and implicitly disregarding page labels that do not affect the actual edit content. Thus, the core change (addition of a period at the end of 'Sun and Shadow') is correctly captured by the prediction."
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_qwen_vl_max",
        "date": "2025-04-07T01:55:17.227944",
        "annotator": "Qwen VL Max",
        "annotation_date": "2025-04-06T00:50:36.591792",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 1.0,
            "fp": 0.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": 0,
            "line_diff": 0,
            "line_number_penalty": 0.0,
            "judgement": "The edit type 'punctuation' in the prediction exactly matches the ground truth edit type. Additionally, the fundamental text correction matches precisely, as both the ground truth and the prediction involve adding a period '.' to 'Sun and Shadow'. Although the page label differs ('007.png' vs. 'Chapter I'), this evaluation explicitly focuses only on edit type accuracy and text content accuracy, completely ignoring line numbers and other metadata discrepancies. Thus, the predicted edit correctly captures the core intention of the ground truth edit."
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_qwen_vl_max",
        "date": "2025-04-07T01:55:39.318085",
        "annotator": "Qwen VL Max",
        "annotation_date": "2025-04-05T02:47:34.939017",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "poplar-trees",
            "corrected_text": "poplar trees",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Chalons,was",
            "corrected_text": "Chalons was",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "ed",
            "corrected_text": "ed.",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_qwen_vl_max",
        "date": "2025-04-07T01:55:58.536811",
        "annotator": "Qwen VL Max",
        "annotation_date": "2025-04-06T00:47:21.893250",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "poplar-trees",
            "corrected_text": "poplar trees",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Chalons,was",
            "corrected_text": "Chalons was",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "footsores,",
            "corrected_text": "footsores, ed",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_qwen_vl_max",
        "date": "2025-04-07T01:56:21.112043",
        "annotator": "Qwen VL Max",
        "annotation_date": "2025-04-06T00:51:05.109193",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "poplar-trees",
            "corrected_text": "poplar trees",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Chalons,was",
            "corrected_text": "Chalons was",
            "observed_line_number": 14,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "ed",
            "corrected_text": "ed.",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  },
  {
    "model_name": "Qwen VL Plus",
    "model_id": "or_qwen_vl_plus",
    "date": "2025-04-07T02:02:15.092385",
    "shots": 2,
    "config": {
      "model_id": "or_qwen_vl_plus",
      "display_name": "Qwen VL Plus",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-06",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "Qwen VL Plus",
    "annotation_date": "2025-04-06T00:36:18.024484",
    "file_results": [
      {
        "model_name": "or_qwen_vl_plus",
        "date": "2025-04-07T01:56:41.847869",
        "annotator": "Qwen VL Plus",
        "annotation_date": "2025-04-06T00:36:18.024484",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_qwen_vl_plus",
        "date": "2025-04-07T01:57:05.156904",
        "annotator": "Qwen VL Plus",
        "annotation_date": "2025-04-06T00:40:42.178714",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_qwen_vl_plus",
        "date": "2025-04-07T01:57:28.224421",
        "annotator": "Qwen VL Plus",
        "annotation_date": "2025-04-06T00:36:57.805266",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_qwen_vl_plus",
        "date": "2025-04-07T01:57:47.944863",
        "annotator": "Qwen VL Plus",
        "annotation_date": "2025-04-06T00:41:21.669994",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_qwen_vl_plus",
        "date": "2025-04-07T01:58:11.075426",
        "annotator": "Qwen VL Plus",
        "annotation_date": "2025-04-06T00:37:24.470119",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_qwen_vl_plus",
        "date": "2025-04-07T01:58:33.182738",
        "annotator": "Qwen VL Plus",
        "annotation_date": "2025-04-06T00:41:51.050721",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_qwen_vl_plus",
        "date": "2025-04-07T01:58:53.197960",
        "annotator": "Qwen VL Plus",
        "annotation_date": "2025-04-06T00:38:01.989559",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_qwen_vl_plus",
        "date": "2025-04-07T01:59:16.139131",
        "annotator": "Qwen VL Plus",
        "annotation_date": "2025-04-06T00:42:27.028626",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_qwen_vl_plus",
        "date": "2025-04-07T01:59:34.725717",
        "annotator": "Qwen VL Plus",
        "annotation_date": "2025-04-05T02:56:16.851844",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "capitalization",
            "original_text": "SUN AND SHADOW",
            "corrected_text": "SUN AND SHADOW.",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Period here",
            "corrected_text": "Period here?",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_qwen_vl_plus",
        "date": "2025-04-07T01:59:55.362776",
        "annotator": "Qwen VL Plus",
        "annotation_date": "2025-04-06T00:38:38.450746",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_qwen_vl_plus",
        "date": "2025-04-07T02:00:17.015822",
        "annotator": "Qwen VL Plus",
        "annotation_date": "2025-04-06T00:43:03.144148",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_qwen_vl_plus",
        "date": "2025-04-07T02:00:53.200643",
        "annotator": "Qwen VL Plus",
        "annotation_date": "2025-04-05T02:56:53.922709",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.09999999999999998,
            "fp": 0.45,
            "fn": 0.45,
            "type": "punctuation",
            "original_text": "One man, slowly moving on towards Chalons, was the only visible figure in the landscape",
            "corrected_text": "One man, slowly moving on towards Chalons, was the only visible figure in the landscape",
            "observed_line_number": 6,
            "line_diff": 3,
            "line_number_penalty": 0.9,
            "judgement": "The predicted edit type matches exactly ('punctuation'). The core punctuation edit from the ground truth ('man slowly' \u2192 'man, slowly') is accurately captured within the longer context presented by the prediction ('One man, slowly moving on towards Chalons, was...'). Although the prediction provides additional context, the essential punctuation correction is correctly identified and applied, thus accurately capturing the intent of the ground truth edit."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stream, like a sullied looking-glass in a gloomy place, reflected the clouds heavily",
            "corrected_text": "stream, like a sullied looking-glass in a gloomy place, reflected the clouds heavily",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "the low banks leaned over here and there, as if they were half curious, and half afraid, to see their darkening pictures in the water",
            "corrected_text": "the low banks leaned over here and there, as if they were half curious, and half afraid, to see their darkening pictures in the water",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "the flat expanse of country about Chalons lay a long heavy streak, occasionally made a little ragged by a row of poplar-trees against the wrathful sunset",
            "corrected_text": "the flat expanse of country about Chalons lay a long heavy streak, occasionally made a little ragged by a row of poplar-trees against the wrathful sunset",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "On the banks of the river Saone it was wet, depressing, solitary; and the night deepened fast",
            "corrected_text": "On the banks of the river Saone it was wet, depressing, solitary; and the night deepened fast",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Cain might have looked as lonely and avoided",
            "corrected_text": "Cain might have looked as lonely and avoided",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "with an old sheepskin knapsack at his back, and a rough, unbarred stick cut out of some wood in his hand; miry, footsore, his shoes and gaiters trodden out, his hair and beard untrimmed; the cloak he carried over his shoulder, and the clothes he wore, sodden with wet; limping along in pain and difficulty; he looked as if the clouds were hurrying from him, as if the wail of the wind and the shuddering of the grass were directed against him, as if the low mysterious splashing of the water were murmured at him, as if the fitful autumn night were disturbed by him",
            "corrected_text": "with an old sheepskin knapsack at his back, and a rough, unbarred stick cut out of some wood in his hand; miry, footsore, his shoes and gaiters trodden out, his hair and beard untrimmed; the cloak he carried over his shoulder, and the clothes he wore, sodden with wet; limping along in pain and difficulty; he looked as if the clouds were hurrying from him, as if the wail of the wind and the shuddering of the grass were directed against him, as if the low mysterious splashing of the water were murmured at him, as if the fitful autumn night were disturbed by him",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "He glanced here, and he glanced there, sullenly but shrinkingly; and sometimes stopped and turned about, and looked all round him",
            "corrected_text": "He glanced here, and he glanced there, sullenly but shrinkingly; and sometimes stopped and turned about, and looked all round him",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Then he limped on again, toiling and muttering",
            "corrected_text": "Then he limped on again, toiling and muttering",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "To the devil with this plain that has no end! To the devil with these stones that cut like knives! To the devil with this dismal darkness, wrapping itself about one with a chill! I hate you!",
            "corrected_text": "To the devil with this plain that has no end! To the devil with these stones that cut like knives! To the devil with this dismal darkness, wrapping itself about one with a chill! I hate you!",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_qwen_vl_plus",
        "date": "2025-04-07T02:01:30.777471",
        "annotator": "Qwen VL Plus",
        "annotation_date": "2025-04-06T00:39:12.824484",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stream, like a sullied looking-glass in a gloomy place, reflected the clouds heavily",
            "corrected_text": "stream, like a sullied looking-glass in a gloomy place, reflected the clouds heavily",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "the low banks leaned over here and there, as if they were half curious, and half afraid, to see their darkening pictures in the water",
            "corrected_text": "the low banks leaned over here and there, as if they were half curious, and half afraid, to see their darkening pictures in the water",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "the flat expanse of country about Chalons lay a long heavy streak, occasionally made a little ragged by a row of poplar-trees against the wrathful sunset",
            "corrected_text": "the flat expanse of country about Chalons lay a long heavy streak, occasionally made a little ragged by a row of poplar-trees against the wrathful sunset",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "On the banks of the river Saone it was wet, depressing, solitary; and the night deepened fast",
            "corrected_text": "On the banks of the river Saone it was wet, depressing, solitary; and the night deepened fast",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Cain might have looked as lonely and avoided",
            "corrected_text": "Cain might have looked as lonely and avoided",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "with an old sheepskin knapsack at his back, and a rough, unbarred stick cut out of some wood in his hand; miry, footsore, his shoes and gaiters trodden out, his hair and beard untrimmed; the cloak he carried over his shoulder, and the clothes he wore, sodden with wet; limping along in pain and difficulty; he looked as if the clouds were hurrying from him, as if the wail of the wind and the shuddering of the grass were directed against him, as if the low mysterious splashing of the water were directed against him, as if the fitful autumn night were disturbed by him",
            "corrected_text": "with an old sheepskin knapsack at his back, and a rough, unbarred stick cut out of some wood in his hand; miry, footsore, his shoes and gaiters trodden out, his hair and beard untrimmed; the cloak he carried over his shoulder, and the clothes he wore, sodden with wet; limping along in pain and difficulty; he looked as if the clouds were hurrying from him, as if the wail of the wind and the shuddering of the grass were directed against him, as if the low mysterious splashing of the water were directed against him, as if the fitful autumn night were disturbed by him",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "He glanced here, and he glanced there, sullenly but shrinkingly; and sometimes stopped and turned about, and looked all round him",
            "corrected_text": "He glanced here, and he glanced there, sullenly but shrinkingly; and sometimes stopped and turned about, and looked all round him",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Then he limped on again, toiling and muttering",
            "corrected_text": "Then he limped on again, toiling and muttering",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "To the devil with this plain that has no end! To the devil with these stones that cut like knives! To the devil with this dismal darkness, wrapping itself about one with a chill! I hate you!",
            "corrected_text": "To the devil with this plain that has no end! To the devil with these stones that cut like knives! To the devil with this dismal darkness, wrapping itself about one with a chill! I hate you!",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "One man slowly moving on towards Chalons, was the only visible figure in the landscape",
            "corrected_text": "One man slowly moving on towards Chalons, was the only visible figure in the landscape",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_qwen_vl_plus",
        "date": "2025-04-07T02:02:15.092385",
        "annotator": "Qwen VL Plus",
        "annotation_date": "2025-04-06T00:43:37.956430",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "stream, like a sullied looking-glass in a gloomy place, reflected the clouds heavily",
            "corrected_text": "stream, like a sullied looking-glass in a gloomy place, reflected the clouds heavily",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "the low banks leaned over here and there, as if they were half curious, and half afraid, to see their darkening pictures in the water",
            "corrected_text": "the low banks leaned over here and there, as if they were half curious, and half afraid, to see their darkening pictures in the water",
            "observed_line_number": 3,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "the flat expanse of country about Chalons lay a long heavy streak, occasionally made a little ragged by a row of poplar-trees against the wrathful sunset",
            "corrected_text": "the flat expanse of country about Chalons lay a long heavy streak, occasionally made a little ragged by a row of poplar-trees against the wrathful sunset",
            "observed_line_number": 4,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "On the banks of the river Saone it was wet, depressing, solitary; and the night deepened fast",
            "corrected_text": "On the banks of the river Saone it was wet, depressing, solitary; and the night deepened fast",
            "observed_line_number": 5,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 4,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Cain might have looked as lonely and avoided",
            "corrected_text": "Cain might have looked as lonely and avoided",
            "observed_line_number": 7,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 5,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "with an old sheepskin knapsack at his back, and a rough, unbarred stick cut out of some wood in his hand; miry, footsore, his shoes and gaiters trodden out, his hair and beard untrimmed; the cloak he carried over his shoulder, and the clothes he wore, sodden with wet; limping along in pain and difficulty; he looked as if the clouds were hurrying from him, as if the wail of the wind and the shuddering of the grass were directed against him, as if the low mysterious splashing of the water were directed against him, as if the fitful autumn night were disturbed by him",
            "corrected_text": "with an old sheepskin knapsack at his back, and a rough, unbarred stick cut out of some wood in his hand; miry, footsore, his shoes and gaiters trodden out, his hair and beard untrimmed; the cloak he carried over his shoulder, and the clothes he wore, sodden with wet; limping along in pain and difficulty; he looked as if the clouds were hurrying from him, as if the wail of the wind and the shuddering of the grass were directed against him, as if the low mysterious splashing of the water were directed against him, as if the fitful autumn night were disturbed by him",
            "observed_line_number": 8,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 6,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "He glanced here, and he glanced there, sullenly but shrinkingly; and sometimes stopped and turned about, and looked all round him",
            "corrected_text": "He glanced here, and he glanced there, sullenly but shrinkingly; and sometimes stopped and turned about, and looked all round him",
            "observed_line_number": 9,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 7,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Then he limped on again, toiling and muttering",
            "corrected_text": "Then he limped on again, toiling and muttering",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 8,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "To the devil with this plain that has no end! To the devil with these stones that cut like knives! To the devil with this dismal darkness, wrapping itself about one with a chill! I hate you!",
            "corrected_text": "To the devil with this plain that has no end! To the devil with these stones that cut like knives! To the devil with this dismal darkness, wrapping itself about one with a chill! I hate you!",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 9,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "One man slowly moving on towards Chalons, was the only visible figure in the landscape",
            "corrected_text": "One man slowly moving on towards Chalons, was the only visible figure in the landscape",
            "observed_line_number": 6,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  },
  {
    "model_name": "Qwen2.5 VL 72B Instruct",
    "model_id": "or_qwen2_5_vl_72b_instruct",
    "date": "2025-04-07T01:46:13.712950",
    "shots": 2,
    "config": {
      "model_id": "or_qwen2_5_vl_72b_instruct",
      "display_name": "Qwen2.5 VL 72B Instruct",
      "shots": 2,
      "temperature": 0.0,
      "date": "2025-04-06",
      "notes": "Benchmark run with 2-shot learning"
    },
    "annotator": "Qwen2.5 VL 72B Instruct",
    "annotation_date": "2025-04-06T00:30:45.198387",
    "file_results": [
      {
        "model_name": "or_qwen2_5_vl_72b_instruct",
        "date": "2025-04-07T01:41:00.025760",
        "annotator": "Qwen2.5 VL 72B Instruct",
        "annotation_date": "2025-04-06T00:30:45.198387",
        "details": [
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Fellow Travellers",
            "corrected_text": "Fellow Travellers.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "howling over",
            "corrected_text": "howling, over",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "yonder to-day",
            "corrected_text": "yonder, to-day",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "Sir",
            "corrected_text": "sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "pockets and",
            "corrected_text": "pockets, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "003"
      },
      {
        "model_name": "or_qwen2_5_vl_72b_instruct",
        "date": "2025-04-07T01:41:18.860499",
        "annotator": "Qwen2.5 VL 72B Instruct",
        "annotation_date": "2025-04-06T00:25:41.042792",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "Why",
            "corrected_text": "why",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "cap",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "question mark",
            "observed_line_number": 27,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_qwen2_5_vl_72b_instruct",
        "date": "2025-04-07T01:41:40.704158",
        "annotator": "Qwen2.5 VL 72B Instruct",
        "annotation_date": "2025-04-06T00:31:14.224527",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "replacement",
            "original_text": "Why",
            "corrected_text": "why",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "cap",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "question mark",
            "observed_line_number": 28,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "No sir",
            "corrected_text": "No, sir",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "why did he dine",
            "corrected_text": "Why did he dine",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "cold stones!",
            "corrected_text": "cold stones?",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "004"
      },
      {
        "model_name": "or_qwen2_5_vl_72b_instruct",
        "date": "2025-04-07T01:41:59.258845",
        "annotator": "Qwen2.5 VL 72B Instruct",
        "annotation_date": "2025-04-05T02:43:01.892593",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "said",
            "corrected_text": "",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "asked",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "I",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "can",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_qwen2_5_vl_72b_instruct",
        "date": "2025-04-07T01:42:20.176333",
        "annotator": "Qwen2.5 VL 72B Instruct",
        "annotation_date": "2025-04-06T00:26:50.694787",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "said",
            "corrected_text": "",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "asked",
            "observed_line_number": 34,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "I",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "can",
            "observed_line_number": 33,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_qwen2_5_vl_72b_instruct",
        "date": "2025-04-07T01:42:43.194318",
        "annotator": "Qwen2.5 VL 72B Instruct",
        "annotation_date": "2025-04-06T00:32:24.564011",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "said",
            "corrected_text": "",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "asked",
            "observed_line_number": 31,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "I",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "can",
            "observed_line_number": 30,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "capitalization",
            "original_text": "if he",
            "corrected_text": "If he",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "said Clennam",
            "corrected_text": "asked Clennam",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "005"
      },
      {
        "model_name": "or_qwen2_5_vl_72b_instruct",
        "date": "2025-04-07T01:43:02.056023",
        "annotator": "Qwen2.5 VL 72B Instruct",
        "annotation_date": "2025-04-05T02:44:00.583253",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "high-road",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "X",
            "corrected_text": "",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Clennam",
            "corrected_text": "Clennam,",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_qwen2_5_vl_72b_instruct",
        "date": "2025-04-07T01:43:24.424855",
        "annotator": "Qwen2.5 VL 72B Instruct",
        "annotation_date": "2025-04-06T00:27:21.994176",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "high-road",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "X",
            "corrected_text": "",
            "observed_line_number": 12,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Clennam",
            "corrected_text": "Clennam,",
            "observed_line_number": 19,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_qwen2_5_vl_72b_instruct",
        "date": "2025-04-07T01:43:43.975986",
        "annotator": "Qwen2.5 VL 72B Instruct",
        "annotation_date": "2025-04-06T00:33:00.639129",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "high-road",
            "observed_line_number": 2,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "deletion",
            "original_text": "X",
            "corrected_text": "",
            "observed_line_number": 11,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 2,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 3,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "Clennam",
            "corrected_text": "Clennam,",
            "observed_line_number": 18,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "high road",
            "corrected_text": "high-road",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "materials costing",
            "corrected_text": "materials, costing",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "about and",
            "corrected_text": "about, and",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "association, did",
            "corrected_text": "association did",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "earnestly telling",
            "corrected_text": "earnestly, telling",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said when",
            "corrected_text": "said, when",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "said",
            "corrected_text": "said,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Clennam in",
            "corrected_text": "Clennam, in",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "006"
      },
      {
        "model_name": "or_qwen2_5_vl_72b_instruct",
        "date": "2025-04-07T01:44:06.384376",
        "annotator": "Qwen2.5 VL 72B Instruct",
        "annotation_date": "2025-04-05T02:44:32.650843",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "SUN AND SHADOW",
            "corrected_text": "SUN AND SHADOW.",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_qwen2_5_vl_72b_instruct",
        "date": "2025-04-07T01:44:27.936053",
        "annotator": "Qwen2.5 VL 72B Instruct",
        "annotation_date": "2025-04-06T00:28:15.467703",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "SUN AND SHADOW",
            "corrected_text": "SUN AND SHADOW.",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_qwen2_5_vl_72b_instruct",
        "date": "2025-04-07T01:44:45.335234",
        "annotator": "Qwen2.5 VL 72B Instruct",
        "annotation_date": "2025-04-06T00:33:56.150196",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "punctuation",
            "original_text": "SUN AND SHADOW",
            "corrected_text": "SUN AND SHADOW.",
            "observed_line_number": 0,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Sun and Shadow",
            "corrected_text": "Sun and Shadow.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "007"
      },
      {
        "model_name": "or_qwen2_5_vl_72b_instruct",
        "date": "2025-04-07T01:45:06.638653",
        "annotator": "Qwen2.5 VL 72B Instruct",
        "annotation_date": "2025-04-05T02:45:25.251193",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "hyphen",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "ed",
            "observed_line_number": 16,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 0,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_qwen2_5_vl_72b_instruct",
        "date": "2025-04-07T01:45:38.571345",
        "annotator": "Qwen2.5 VL 72B Instruct",
        "annotation_date": "2025-04-06T00:28:44.176385",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.6,
            "fp": 0.2,
            "fn": 0.2,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": 16,
            "line_diff": 2,
            "line_number_penalty": 0.4,
            "judgement": "The predicted edit accurately matches the edit type ('replacement') and correctly identifies the intended core textual change from 'sodden' to 'soddened.' Line numbers and page numbers were explicitly ignored per instructions. Hence, the essential edit content and edit type match perfectly with ground truth."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "hyphen",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      },
      {
        "model_name": "or_qwen2_5_vl_72b_instruct",
        "date": "2025-04-07T01:46:13.712950",
        "annotator": "Qwen2.5 VL 72B Instruct",
        "annotation_date": "2025-04-06T00:34:42.710533",
        "details": [
          {
            "observed_edit_num": 0,
            "expected_edit_num": 0,
            "tp": 0.6,
            "fp": 0.2,
            "fn": 0.2,
            "type": "replacement",
            "original_text": "sodden",
            "corrected_text": "soddened",
            "observed_line_number": 16,
            "line_diff": 2,
            "line_number_penalty": 0.4,
            "judgement": "The predicted edit type ('replacement') exactly matches the ground truth edit type ('replacement'). The original and corrected text also match precisely ('sodden' to 'soddened'), indicating the model has accurately captured the core content of the edit. Line numbers and page information discrepancies were explicitly ignored per the instructions. Therefore, both edit type and text content are correctly captured, making the prediction correct."
          },
          {
            "observed_edit_num": 1,
            "expected_edit_num": null,
            "tp": 0.0,
            "fp": 1.0,
            "fn": 0.0,
            "type": "insertion",
            "original_text": "",
            "corrected_text": "hyphen",
            "observed_line_number": 10,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False positive: no matching ground truth edit found"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 1,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Let Loose",
            "corrected_text": "Let Loose.",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 2,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "dull autumn",
            "corrected_text": "dull, autumn",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 3,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 4,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "poplar trees",
            "corrected_text": "poplar-trees,",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 5,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "replacement",
            "original_text": "Saone",
            "corrected_text": "Sa\u00f4ne",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 6,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "man slowly",
            "corrected_text": "man, slowly",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          },
          {
            "observed_edit_num": null,
            "expected_edit_num": 7,
            "tp": 0.0,
            "fp": 0.0,
            "fn": 1.0,
            "type": "punctuation",
            "original_text": "Chalons was",
            "corrected_text": "Chalons, was",
            "observed_line_number": null,
            "line_diff": null,
            "line_number_penalty": 0.0,
            "judgement": "False negative: ground truth edit not found in prediction"
          }
        ],
        "file_id": "008"
      }
    ]
  }
]